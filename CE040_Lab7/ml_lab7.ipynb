{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "kWBMu_eS0QQF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import io\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "data = pd.read_csv(io.BytesIO(uploaded['BuyComputer.csv']))\n",
        "data.drop(columns=['User ID',],axis=1,inplace=True)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "RqVbHt0U0mum",
        "outputId": "f94777e8-bc5d-48a3-a77e-2a302916b1a4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bd0c056e-be20-42cd-8ef2-4346495c2368\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bd0c056e-be20-42cd-8ef2-4346495c2368\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving BuyComputer.csv to BuyComputer (1).csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age  EstimatedSalary  Purchased\n",
              "0   19            19000          0\n",
              "1   35            20000          0\n",
              "2   26            43000          0\n",
              "3   27            57000          0\n",
              "4   19            76000          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-838e3ddc-f84a-46e2-9a68-57a9bbcc2a2d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>19000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>20000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19</td>\n",
              "      <td>76000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-838e3ddc-f84a-46e2-9a68-57a9bbcc2a2d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-838e3ddc-f84a-46e2-9a68-57a9bbcc2a2d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-838e3ddc-f84a-46e2-9a68-57a9bbcc2a2d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Aya3h_O70yRL",
        "outputId": "48f6f9aa-e0ae-480e-baf0-91baf2a2b30a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Age  EstimatedSalary  Purchased\n",
              "0     19            19000          0\n",
              "1     35            20000          0\n",
              "2     26            43000          0\n",
              "3     27            57000          0\n",
              "4     19            76000          0\n",
              "..   ...              ...        ...\n",
              "395   46            41000          1\n",
              "396   51            23000          1\n",
              "397   50            20000          1\n",
              "398   36            33000          0\n",
              "399   49            36000          1\n",
              "\n",
              "[400 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2f4681b-122f-4fd7-8e32-ae6acbdbfec2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>19000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>20000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19</td>\n",
              "      <td>76000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>46</td>\n",
              "      <td>41000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>51</td>\n",
              "      <td>23000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>50</td>\n",
              "      <td>20000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>36</td>\n",
              "      <td>33000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>49</td>\n",
              "      <td>36000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2f4681b-122f-4fd7-8e32-ae6acbdbfec2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2f4681b-122f-4fd7-8e32-ae6acbdbfec2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2f4681b-122f-4fd7-8e32-ae6acbdbfec2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Declare label as last column in the source file"
      ],
      "metadata": {
        "id": "N8WUANVP1cy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Declaring X as all columns excluding last\n",
        "X = data.iloc[:,:-1].values\n",
        "\n",
        "#Declare label as last column in the source file\n",
        "Y = data.iloc[:,-1].values\n"
      ],
      "metadata": {
        "id": "au9edz251fJ_"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mHxqdcw2RRJ",
        "outputId": "c7ed496a-8411-45fa-f7a0-29d81b18cfe0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    19,  19000],\n",
              "       [    35,  20000],\n",
              "       [    26,  43000],\n",
              "       [    27,  57000],\n",
              "       [    19,  76000],\n",
              "       [    27,  58000],\n",
              "       [    27,  84000],\n",
              "       [    32, 150000],\n",
              "       [    25,  33000],\n",
              "       [    35,  65000],\n",
              "       [    26,  80000],\n",
              "       [    26,  52000],\n",
              "       [    20,  86000],\n",
              "       [    32,  18000],\n",
              "       [    18,  82000],\n",
              "       [    29,  80000],\n",
              "       [    47,  25000],\n",
              "       [    45,  26000],\n",
              "       [    46,  28000],\n",
              "       [    48,  29000],\n",
              "       [    45,  22000],\n",
              "       [    47,  49000],\n",
              "       [    48,  41000],\n",
              "       [    45,  22000],\n",
              "       [    46,  23000],\n",
              "       [    47,  20000],\n",
              "       [    49,  28000],\n",
              "       [    47,  30000],\n",
              "       [    29,  43000],\n",
              "       [    31,  18000],\n",
              "       [    31,  74000],\n",
              "       [    27, 137000],\n",
              "       [    21,  16000],\n",
              "       [    28,  44000],\n",
              "       [    27,  90000],\n",
              "       [    35,  27000],\n",
              "       [    33,  28000],\n",
              "       [    30,  49000],\n",
              "       [    26,  72000],\n",
              "       [    27,  31000],\n",
              "       [    27,  17000],\n",
              "       [    33,  51000],\n",
              "       [    35, 108000],\n",
              "       [    30,  15000],\n",
              "       [    28,  84000],\n",
              "       [    23,  20000],\n",
              "       [    25,  79000],\n",
              "       [    27,  54000],\n",
              "       [    30, 135000],\n",
              "       [    31,  89000],\n",
              "       [    24,  32000],\n",
              "       [    18,  44000],\n",
              "       [    29,  83000],\n",
              "       [    35,  23000],\n",
              "       [    27,  58000],\n",
              "       [    24,  55000],\n",
              "       [    23,  48000],\n",
              "       [    28,  79000],\n",
              "       [    22,  18000],\n",
              "       [    32, 117000],\n",
              "       [    27,  20000],\n",
              "       [    25,  87000],\n",
              "       [    23,  66000],\n",
              "       [    32, 120000],\n",
              "       [    59,  83000],\n",
              "       [    24,  58000],\n",
              "       [    24,  19000],\n",
              "       [    23,  82000],\n",
              "       [    22,  63000],\n",
              "       [    31,  68000],\n",
              "       [    25,  80000],\n",
              "       [    24,  27000],\n",
              "       [    20,  23000],\n",
              "       [    33, 113000],\n",
              "       [    32,  18000],\n",
              "       [    34, 112000],\n",
              "       [    18,  52000],\n",
              "       [    22,  27000],\n",
              "       [    28,  87000],\n",
              "       [    26,  17000],\n",
              "       [    30,  80000],\n",
              "       [    39,  42000],\n",
              "       [    20,  49000],\n",
              "       [    35,  88000],\n",
              "       [    30,  62000],\n",
              "       [    31, 118000],\n",
              "       [    24,  55000],\n",
              "       [    28,  85000],\n",
              "       [    26,  81000],\n",
              "       [    35,  50000],\n",
              "       [    22,  81000],\n",
              "       [    30, 116000],\n",
              "       [    26,  15000],\n",
              "       [    29,  28000],\n",
              "       [    29,  83000],\n",
              "       [    35,  44000],\n",
              "       [    35,  25000],\n",
              "       [    28, 123000],\n",
              "       [    35,  73000],\n",
              "       [    28,  37000],\n",
              "       [    27,  88000],\n",
              "       [    28,  59000],\n",
              "       [    32,  86000],\n",
              "       [    33, 149000],\n",
              "       [    19,  21000],\n",
              "       [    21,  72000],\n",
              "       [    26,  35000],\n",
              "       [    27,  89000],\n",
              "       [    26,  86000],\n",
              "       [    38,  80000],\n",
              "       [    39,  71000],\n",
              "       [    37,  71000],\n",
              "       [    38,  61000],\n",
              "       [    37,  55000],\n",
              "       [    42,  80000],\n",
              "       [    40,  57000],\n",
              "       [    35,  75000],\n",
              "       [    36,  52000],\n",
              "       [    40,  59000],\n",
              "       [    41,  59000],\n",
              "       [    36,  75000],\n",
              "       [    37,  72000],\n",
              "       [    40,  75000],\n",
              "       [    35,  53000],\n",
              "       [    41,  51000],\n",
              "       [    39,  61000],\n",
              "       [    42,  65000],\n",
              "       [    26,  32000],\n",
              "       [    30,  17000],\n",
              "       [    26,  84000],\n",
              "       [    31,  58000],\n",
              "       [    33,  31000],\n",
              "       [    30,  87000],\n",
              "       [    21,  68000],\n",
              "       [    28,  55000],\n",
              "       [    23,  63000],\n",
              "       [    20,  82000],\n",
              "       [    30, 107000],\n",
              "       [    28,  59000],\n",
              "       [    19,  25000],\n",
              "       [    19,  85000],\n",
              "       [    18,  68000],\n",
              "       [    35,  59000],\n",
              "       [    30,  89000],\n",
              "       [    34,  25000],\n",
              "       [    24,  89000],\n",
              "       [    27,  96000],\n",
              "       [    41,  30000],\n",
              "       [    29,  61000],\n",
              "       [    20,  74000],\n",
              "       [    26,  15000],\n",
              "       [    41,  45000],\n",
              "       [    31,  76000],\n",
              "       [    36,  50000],\n",
              "       [    40,  47000],\n",
              "       [    31,  15000],\n",
              "       [    46,  59000],\n",
              "       [    29,  75000],\n",
              "       [    26,  30000],\n",
              "       [    32, 135000],\n",
              "       [    32, 100000],\n",
              "       [    25,  90000],\n",
              "       [    37,  33000],\n",
              "       [    35,  38000],\n",
              "       [    33,  69000],\n",
              "       [    18,  86000],\n",
              "       [    22,  55000],\n",
              "       [    35,  71000],\n",
              "       [    29, 148000],\n",
              "       [    29,  47000],\n",
              "       [    21,  88000],\n",
              "       [    34, 115000],\n",
              "       [    26, 118000],\n",
              "       [    34,  43000],\n",
              "       [    34,  72000],\n",
              "       [    23,  28000],\n",
              "       [    35,  47000],\n",
              "       [    25,  22000],\n",
              "       [    24,  23000],\n",
              "       [    31,  34000],\n",
              "       [    26,  16000],\n",
              "       [    31,  71000],\n",
              "       [    32, 117000],\n",
              "       [    33,  43000],\n",
              "       [    33,  60000],\n",
              "       [    31,  66000],\n",
              "       [    20,  82000],\n",
              "       [    33,  41000],\n",
              "       [    35,  72000],\n",
              "       [    28,  32000],\n",
              "       [    24,  84000],\n",
              "       [    19,  26000],\n",
              "       [    29,  43000],\n",
              "       [    19,  70000],\n",
              "       [    28,  89000],\n",
              "       [    34,  43000],\n",
              "       [    30,  79000],\n",
              "       [    20,  36000],\n",
              "       [    26,  80000],\n",
              "       [    35,  22000],\n",
              "       [    35,  39000],\n",
              "       [    49,  74000],\n",
              "       [    39, 134000],\n",
              "       [    41,  71000],\n",
              "       [    58, 101000],\n",
              "       [    47,  47000],\n",
              "       [    55, 130000],\n",
              "       [    52, 114000],\n",
              "       [    40, 142000],\n",
              "       [    46,  22000],\n",
              "       [    48,  96000],\n",
              "       [    52, 150000],\n",
              "       [    59,  42000],\n",
              "       [    35,  58000],\n",
              "       [    47,  43000],\n",
              "       [    60, 108000],\n",
              "       [    49,  65000],\n",
              "       [    40,  78000],\n",
              "       [    46,  96000],\n",
              "       [    59, 143000],\n",
              "       [    41,  80000],\n",
              "       [    35,  91000],\n",
              "       [    37, 144000],\n",
              "       [    60, 102000],\n",
              "       [    35,  60000],\n",
              "       [    37,  53000],\n",
              "       [    36, 126000],\n",
              "       [    56, 133000],\n",
              "       [    40,  72000],\n",
              "       [    42,  80000],\n",
              "       [    35, 147000],\n",
              "       [    39,  42000],\n",
              "       [    40, 107000],\n",
              "       [    49,  86000],\n",
              "       [    38, 112000],\n",
              "       [    46,  79000],\n",
              "       [    40,  57000],\n",
              "       [    37,  80000],\n",
              "       [    46,  82000],\n",
              "       [    53, 143000],\n",
              "       [    42, 149000],\n",
              "       [    38,  59000],\n",
              "       [    50,  88000],\n",
              "       [    56, 104000],\n",
              "       [    41,  72000],\n",
              "       [    51, 146000],\n",
              "       [    35,  50000],\n",
              "       [    57, 122000],\n",
              "       [    41,  52000],\n",
              "       [    35,  97000],\n",
              "       [    44,  39000],\n",
              "       [    37,  52000],\n",
              "       [    48, 134000],\n",
              "       [    37, 146000],\n",
              "       [    50,  44000],\n",
              "       [    52,  90000],\n",
              "       [    41,  72000],\n",
              "       [    40,  57000],\n",
              "       [    58,  95000],\n",
              "       [    45, 131000],\n",
              "       [    35,  77000],\n",
              "       [    36, 144000],\n",
              "       [    55, 125000],\n",
              "       [    35,  72000],\n",
              "       [    48,  90000],\n",
              "       [    42, 108000],\n",
              "       [    40,  75000],\n",
              "       [    37,  74000],\n",
              "       [    47, 144000],\n",
              "       [    40,  61000],\n",
              "       [    43, 133000],\n",
              "       [    59,  76000],\n",
              "       [    60,  42000],\n",
              "       [    39, 106000],\n",
              "       [    57,  26000],\n",
              "       [    57,  74000],\n",
              "       [    38,  71000],\n",
              "       [    49,  88000],\n",
              "       [    52,  38000],\n",
              "       [    50,  36000],\n",
              "       [    59,  88000],\n",
              "       [    35,  61000],\n",
              "       [    37,  70000],\n",
              "       [    52,  21000],\n",
              "       [    48, 141000],\n",
              "       [    37,  93000],\n",
              "       [    37,  62000],\n",
              "       [    48, 138000],\n",
              "       [    41,  79000],\n",
              "       [    37,  78000],\n",
              "       [    39, 134000],\n",
              "       [    49,  89000],\n",
              "       [    55,  39000],\n",
              "       [    37,  77000],\n",
              "       [    35,  57000],\n",
              "       [    36,  63000],\n",
              "       [    42,  73000],\n",
              "       [    43, 112000],\n",
              "       [    45,  79000],\n",
              "       [    46, 117000],\n",
              "       [    58,  38000],\n",
              "       [    48,  74000],\n",
              "       [    37, 137000],\n",
              "       [    37,  79000],\n",
              "       [    40,  60000],\n",
              "       [    42,  54000],\n",
              "       [    51, 134000],\n",
              "       [    47, 113000],\n",
              "       [    36, 125000],\n",
              "       [    38,  50000],\n",
              "       [    42,  70000],\n",
              "       [    39,  96000],\n",
              "       [    38,  50000],\n",
              "       [    49, 141000],\n",
              "       [    39,  79000],\n",
              "       [    39,  75000],\n",
              "       [    54, 104000],\n",
              "       [    35,  55000],\n",
              "       [    45,  32000],\n",
              "       [    36,  60000],\n",
              "       [    52, 138000],\n",
              "       [    53,  82000],\n",
              "       [    41,  52000],\n",
              "       [    48,  30000],\n",
              "       [    48, 131000],\n",
              "       [    41,  60000],\n",
              "       [    41,  72000],\n",
              "       [    42,  75000],\n",
              "       [    36, 118000],\n",
              "       [    47, 107000],\n",
              "       [    38,  51000],\n",
              "       [    48, 119000],\n",
              "       [    42,  65000],\n",
              "       [    40,  65000],\n",
              "       [    57,  60000],\n",
              "       [    36,  54000],\n",
              "       [    58, 144000],\n",
              "       [    35,  79000],\n",
              "       [    38,  55000],\n",
              "       [    39, 122000],\n",
              "       [    53, 104000],\n",
              "       [    35,  75000],\n",
              "       [    38,  65000],\n",
              "       [    47,  51000],\n",
              "       [    47, 105000],\n",
              "       [    41,  63000],\n",
              "       [    53,  72000],\n",
              "       [    54, 108000],\n",
              "       [    39,  77000],\n",
              "       [    38,  61000],\n",
              "       [    38, 113000],\n",
              "       [    37,  75000],\n",
              "       [    42,  90000],\n",
              "       [    37,  57000],\n",
              "       [    36,  99000],\n",
              "       [    60,  34000],\n",
              "       [    54,  70000],\n",
              "       [    41,  72000],\n",
              "       [    40,  71000],\n",
              "       [    42,  54000],\n",
              "       [    43, 129000],\n",
              "       [    53,  34000],\n",
              "       [    47,  50000],\n",
              "       [    42,  79000],\n",
              "       [    42, 104000],\n",
              "       [    59,  29000],\n",
              "       [    58,  47000],\n",
              "       [    46,  88000],\n",
              "       [    38,  71000],\n",
              "       [    54,  26000],\n",
              "       [    60,  46000],\n",
              "       [    60,  83000],\n",
              "       [    39,  73000],\n",
              "       [    59, 130000],\n",
              "       [    37,  80000],\n",
              "       [    46,  32000],\n",
              "       [    46,  74000],\n",
              "       [    42,  53000],\n",
              "       [    41,  87000],\n",
              "       [    58,  23000],\n",
              "       [    42,  64000],\n",
              "       [    48,  33000],\n",
              "       [    44, 139000],\n",
              "       [    49,  28000],\n",
              "       [    57,  33000],\n",
              "       [    56,  60000],\n",
              "       [    49,  39000],\n",
              "       [    39,  71000],\n",
              "       [    47,  34000],\n",
              "       [    48,  35000],\n",
              "       [    48,  33000],\n",
              "       [    47,  23000],\n",
              "       [    45,  45000],\n",
              "       [    60,  42000],\n",
              "       [    39,  59000],\n",
              "       [    46,  41000],\n",
              "       [    51,  23000],\n",
              "       [    50,  20000],\n",
              "       [    36,  33000],\n",
              "       [    49,  36000]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test =  train_test_split(X,Y ,\n",
        "                                   random_state=40, \n",
        "                                   test_size=0.25, \n",
        "                                   shuffle=True)"
      ],
      "metadata": {
        "id": "8gWGWHET2Sp-"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import XATTR_SIZE_MAX\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "CQ2LkhvM2fNq"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-es2TR82y5F",
        "outputId": "da23e196-38e3-4a4d-af7f-6a89509a515b"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.98334377, -1.1271988 ],\n",
              "       [ 1.23762906, -1.39076827],\n",
              "       [ 0.75480888,  1.36206849],\n",
              "       [ 1.52732117,  1.09849901],\n",
              "       [-0.11426744, -0.01434989],\n",
              "       [-0.40395955,  0.0442211 ],\n",
              "       [ 1.3341931 , -0.95148581],\n",
              "       [ 1.91357732,  0.89350053],\n",
              "       [-0.69365166, -0.13149188],\n",
              "       [ 0.17542467, -0.16077738],\n",
              "       [-1.07990781,  0.51278906],\n",
              "       [ 0.07886063,  0.0735066 ],\n",
              "       [-1.8524201 , -1.33219728],\n",
              "       [-0.50052359, -0.86362932],\n",
              "       [-0.40395955, -0.80505833],\n",
              "       [ 0.94793696, -1.0979133 ],\n",
              "       [-0.30739552, -1.39076827],\n",
              "       [ 0.36855274,  0.27850508],\n",
              "       [-0.11426744,  0.24921958],\n",
              "       [-0.7902157 , -0.62934534],\n",
              "       [ 0.94793696, -1.03934231],\n",
              "       [ 0.85137292, -0.62934534],\n",
              "       [-0.30739552, -0.33649037],\n",
              "       [-0.30739552, -0.95148581],\n",
              "       [ 0.56168081,  2.00634943],\n",
              "       [-1.17647184,  0.30779058],\n",
              "       [-1.56272799,  0.30779058],\n",
              "       [ 2.10670539,  1.09849901],\n",
              "       [ 0.07886063,  0.24921958],\n",
              "       [ 0.65824485,  1.77206545],\n",
              "       [-0.69365166,  0.54207456],\n",
              "       [ 1.72044925,  1.83063645],\n",
              "       [ 0.07886063,  1.85992194],\n",
              "       [ 1.91357732,  2.15277692],\n",
              "       [ 2.01014135, -0.83434382],\n",
              "       [ 0.36855274,  0.0735066 ],\n",
              "       [-1.17647184,  0.27850508],\n",
              "       [ 1.81701328,  0.1027921 ],\n",
              "       [-0.88677973, -0.80505833],\n",
              "       [ 0.94793696,  0.1027921 ],\n",
              "       [-1.07990781, -1.1564843 ],\n",
              "       [ 0.2719887 ,  0.0442211 ],\n",
              "       [ 0.94793696,  1.85992194],\n",
              "       [-1.17647184, -0.54148885],\n",
              "       [ 1.3341931 ,  1.97706393],\n",
              "       [ 0.17542467,  0.13207759],\n",
              "       [-0.11426744,  0.1027921 ],\n",
              "       [ 0.2719887 , -0.74648733],\n",
              "       [-0.21083148, -0.21934838],\n",
              "       [-0.30739552,  0.60064555],\n",
              "       [ 0.75480888,  0.1027921 ],\n",
              "       [-0.88677973,  0.36636157],\n",
              "       [ 0.65824485, -1.1271988 ],\n",
              "       [-0.59708762,  1.36206849],\n",
              "       [-0.50052359,  2.29920441],\n",
              "       [ 0.2719887 ,  0.24921958],\n",
              "       [ 0.36855274,  0.24921958],\n",
              "       [-1.07990781, -1.56648126],\n",
              "       [-1.07990781, -0.48291785],\n",
              "       [-0.59708762,  1.36206849],\n",
              "       [ 0.85137292, -1.33219728],\n",
              "       [ 1.3341931 ,  0.57136006],\n",
              "       [ 1.72044925,  0.98135702],\n",
              "       [-0.01770341, -0.60005984],\n",
              "       [ 1.52732117,  0.98135702],\n",
              "       [-0.30739552, -0.92220032],\n",
              "       [-0.40395955, -0.80505833],\n",
              "       [-1.36959991, -0.45363236],\n",
              "       [-0.69365166, -1.53719576],\n",
              "       [-0.21083148, -0.48291785],\n",
              "       [-0.11426744, -0.51220335],\n",
              "       [-1.27303588,  0.24921958],\n",
              "       [ 1.72044925, -0.30720487],\n",
              "       [ 0.17542467,  2.09420592],\n",
              "       [ 0.17542467, -0.39506136],\n",
              "       [-0.40395955, -1.33219728],\n",
              "       [-1.94898413,  0.33707608],\n",
              "       [-0.11426744,  0.65921655],\n",
              "       [-1.17647184, -1.62505225],\n",
              "       [ 0.85137292, -1.0686278 ],\n",
              "       [-1.65929202,  0.51278906],\n",
              "       [-0.11426744,  2.21134791],\n",
              "       [ 0.65824485, -1.30291178],\n",
              "       [-0.21083148,  0.13207759],\n",
              "       [-0.21083148, -0.30720487],\n",
              "       [ 1.43075714,  0.33707608],\n",
              "       [-0.98334377,  0.39564707],\n",
              "       [ 2.10670539, -0.83434382],\n",
              "       [-1.75585606,  0.33707608],\n",
              "       [ 0.17542467, -0.27791937],\n",
              "       [-1.17647184,  0.27850508],\n",
              "       [-1.36959991, -1.1271988 ],\n",
              "       [-0.30739552, -1.27362628],\n",
              "       [-0.11426744,  0.27850508],\n",
              "       [-1.36959991,  0.39564707],\n",
              "       [ 1.52732117, -1.30291178],\n",
              "       [ 1.62388521,  1.59635247],\n",
              "       [-1.07990781, -0.36577586],\n",
              "       [-0.98334377, -0.77577283],\n",
              "       [-0.11426744,  0.21993409],\n",
              "       [ 0.07886063, -0.27791937],\n",
              "       [ 0.75480888, -1.39076827],\n",
              "       [ 1.43075714,  0.98135702],\n",
              "       [-0.50052359, -0.57077435],\n",
              "       [ 0.17542467, -0.30720487],\n",
              "       [-0.11426744,  0.0149356 ],\n",
              "       [-1.27303588,  0.27850508],\n",
              "       [ 0.17542467,  0.13207759],\n",
              "       [-0.11426744, -0.45363236],\n",
              "       [-0.98334377,  0.42493257],\n",
              "       [ 0.36855274, -0.48291785],\n",
              "       [ 1.81701328, -0.30720487],\n",
              "       [ 0.17542467, -0.68791634],\n",
              "       [-1.17647184, -1.1271988 ],\n",
              "       [-1.17647184, -1.62505225],\n",
              "       [ 0.75480888,  0.51278906],\n",
              "       [-1.8524201 , -1.30291178],\n",
              "       [ 0.65824485,  0.24921958],\n",
              "       [ 0.2719887 , -0.30720487],\n",
              "       [ 0.07886063,  1.03992802],\n",
              "       [ 0.85137292, -0.60005984],\n",
              "       [-0.30739552, -0.36577586],\n",
              "       [-1.17647184,  0.0442211 ],\n",
              "       [-0.88677973,  0.27850508],\n",
              "       [ 0.75480888, -1.42005377],\n",
              "       [ 2.10670539, -0.71720183],\n",
              "       [ 0.65824485, -0.74648733],\n",
              "       [-0.69365166, -1.62505225],\n",
              "       [-1.75585606,  0.1027921 ],\n",
              "       [ 1.04450099,  0.45421807],\n",
              "       [ 0.75480888, -0.33649037],\n",
              "       [ 0.07886063, -0.83434382],\n",
              "       [-1.75585606, -0.62934534],\n",
              "       [-0.30739552,  0.24921958],\n",
              "       [-0.88677973, -0.27791937],\n",
              "       [-0.98334377,  1.53778147],\n",
              "       [-0.7902157 ,  0.54207456],\n",
              "       [ 0.94793696,  0.57136006],\n",
              "       [ 2.01014135,  0.51278906],\n",
              "       [-1.17647184, -1.56648126],\n",
              "       [-0.40395955,  1.215641  ],\n",
              "       [ 1.04450099,  2.06492043],\n",
              "       [-1.17647184, -0.80505833],\n",
              "       [-0.30739552, -1.33219728],\n",
              "       [ 0.94793696,  1.77206545],\n",
              "       [-0.50052359, -0.04363539],\n",
              "       [-0.30739552, -0.45363236],\n",
              "       [-0.01770341, -0.60005984],\n",
              "       [-1.36959991, -1.27362628],\n",
              "       [ 2.01014135,  0.36636157],\n",
              "       [-0.11426744,  1.94777844],\n",
              "       [-0.21083148,  1.39135398],\n",
              "       [-0.01770341,  1.215641  ],\n",
              "       [-0.30739552, -0.60005984],\n",
              "       [-0.59708762, -1.53719576],\n",
              "       [-0.88677973, -1.24434079],\n",
              "       [-0.01770341, -0.16077738],\n",
              "       [-1.17647184, -1.59576676],\n",
              "       [ 0.36855274, -0.16077738],\n",
              "       [-0.01770341,  0.27850508],\n",
              "       [ 1.91357732, -0.68791634],\n",
              "       [-0.01770341, -0.27791937],\n",
              "       [ 0.07886063,  0.13207759],\n",
              "       [-0.11426744,  0.0442211 ],\n",
              "       [-0.98334377, -0.33649037],\n",
              "       [ 1.04450099, -1.24434079],\n",
              "       [-0.21083148,  1.59635247],\n",
              "       [-1.46616395,  0.33707608],\n",
              "       [-0.30739552, -0.68791634],\n",
              "       [-0.7902157 , -1.56648126],\n",
              "       [ 1.81701328, -1.0979133 ],\n",
              "       [-1.36959991, -1.39076827],\n",
              "       [-0.30739552,  0.0442211 ],\n",
              "       [-1.36959991,  0.54207456],\n",
              "       [ 0.85137292, -1.47862477],\n",
              "       [ 1.14106503,  0.51278906],\n",
              "       [-0.30739552, -0.51220335],\n",
              "       [-0.30739552, -0.27791937],\n",
              "       [-0.69365166, -0.36577586],\n",
              "       [ 0.46511677,  1.71349446],\n",
              "       [ 0.07886063,  0.74707304],\n",
              "       [-0.98334377, -0.45363236],\n",
              "       [-1.65929202,  0.0442211 ],\n",
              "       [-0.30739552,  0.19064859],\n",
              "       [-0.11426744, -0.54148885],\n",
              "       [ 0.36855274,  0.98135702],\n",
              "       [ 2.01014135,  0.16136309],\n",
              "       [-1.56272799, -0.21934838],\n",
              "       [ 0.07886063, -0.83434382],\n",
              "       [ 0.17542467,  0.0149356 ],\n",
              "       [-0.98334377, -0.33649037],\n",
              "       [-1.07990781,  0.54207456],\n",
              "       [-0.69365166, -1.0686278 ],\n",
              "       [ 1.81701328,  1.50849597],\n",
              "       [-0.30739552,  0.13207759],\n",
              "       [ 0.85137292,  1.01064252],\n",
              "       [-0.7902157 ,  0.24921958],\n",
              "       [-1.27303588,  0.48350356],\n",
              "       [ 1.14106503, -1.47862477],\n",
              "       [-1.46616395, -1.47862477],\n",
              "       [-1.94898413, -0.54148885],\n",
              "       [ 0.2719887 , -0.57077435],\n",
              "       [-0.40395955,  1.30349749],\n",
              "       [-0.98334377,  0.48350356],\n",
              "       [-0.30739552,  2.24063341],\n",
              "       [ 0.36855274,  0.57136006],\n",
              "       [-0.01770341,  0.0149356 ],\n",
              "       [ 0.75480888, -0.86362932],\n",
              "       [ 0.85137292,  1.2449265 ],\n",
              "       [-1.65929202, -1.59576676],\n",
              "       [ 1.43075714,  0.0442211 ],\n",
              "       [-0.88677973,  0.36636157],\n",
              "       [ 1.04450099,  0.51278906],\n",
              "       [-0.30739552,  0.77635854],\n",
              "       [ 1.3341931 , -1.44933927],\n",
              "       [ 0.17542467, -0.39506136],\n",
              "       [ 0.2719887 , -0.33649037],\n",
              "       [ 0.56168081, -0.92220032],\n",
              "       [ 1.04450099,  0.1027921 ],\n",
              "       [ 0.75480888,  0.74707304],\n",
              "       [ 2.10670539, -0.83434382],\n",
              "       [ 1.04450099, -0.92220032],\n",
              "       [-0.7902157 , -0.24863387],\n",
              "       [ 0.85137292, -0.80505833],\n",
              "       [ 0.85137292, -0.68791634],\n",
              "       [-0.50052359, -0.30720487],\n",
              "       [ 1.62388521,  1.74277995],\n",
              "       [ 1.23762906,  2.21134791],\n",
              "       [ 0.36855274, -0.51220335],\n",
              "       [-1.07990781,  0.57136006],\n",
              "       [-0.01770341, -0.45363236],\n",
              "       [-1.75585606, -1.39076827],\n",
              "       [-0.30739552, -1.47862477],\n",
              "       [ 2.01014135,  1.74277995],\n",
              "       [-0.59708762,  1.44992498],\n",
              "       [ 0.17542467, -0.39506136],\n",
              "       [-0.50052359, -1.24434079],\n",
              "       [-0.30739552,  0.51278906],\n",
              "       [ 0.07886063,  1.50849597],\n",
              "       [-0.98334377,  0.24921958],\n",
              "       [ 1.04450099, -1.01005681],\n",
              "       [-0.30739552,  0.0735066 ],\n",
              "       [-0.11426744,  0.27850508],\n",
              "       [ 1.3341931 ,  2.3284899 ],\n",
              "       [-0.21083148, -0.60005984],\n",
              "       [ 0.07886063,  0.0149356 ],\n",
              "       [-0.21083148, -0.54148885],\n",
              "       [ 1.43075714,  2.12349142],\n",
              "       [ 1.04450099, -0.16077738],\n",
              "       [ 0.75480888,  0.24921958],\n",
              "       [-0.30739552, -0.77577283],\n",
              "       [-0.98334377, -0.98077131],\n",
              "       [ 0.46511677,  1.215641  ],\n",
              "       [ 0.2719887 ,  0.27850508],\n",
              "       [ 0.07886063, -0.33649037],\n",
              "       [-0.7902157 ,  0.27850508],\n",
              "       [-1.17647184,  0.45421807],\n",
              "       [ 2.01014135, -1.21505529],\n",
              "       [-1.07990781,  1.94777844],\n",
              "       [-0.21083148,  1.62563796],\n",
              "       [ 0.85137292, -0.57077435],\n",
              "       [ 1.91357732, -0.95148581],\n",
              "       [-1.07990781, -1.47862477],\n",
              "       [-0.69365166,  0.1027921 ],\n",
              "       [ 0.2719887 ,  0.48350356],\n",
              "       [ 0.94793696,  0.74707304],\n",
              "       [-0.01770341, -0.33649037],\n",
              "       [ 0.07886063,  0.0149356 ],\n",
              "       [-0.30739552, -1.42005377],\n",
              "       [ 2.10670539, -1.0686278 ],\n",
              "       [-0.21083148, -1.0979133 ],\n",
              "       [-0.50052359, -1.1564843 ],\n",
              "       [ 0.94793696, -0.86362932],\n",
              "       [ 0.07886063,  1.85992194],\n",
              "       [-1.75585606,  0.33707608],\n",
              "       [-1.8524201 , -1.44933927],\n",
              "       [ 0.07886063,  0.19064859],\n",
              "       [ 0.46511677,  1.83063645],\n",
              "       [ 1.3341931 ,  1.27421199],\n",
              "       [-1.17647184, -1.18576979],\n",
              "       [-1.27303588, -1.0979133 ],\n",
              "       [ 0.85137292,  1.06921351],\n",
              "       [-0.69365166,  0.0149356 ],\n",
              "       [ 0.36855274, -0.48291785],\n",
              "       [-0.30739552, -0.30720487],\n",
              "       [-0.50052359,  1.2449265 ],\n",
              "       [-0.7902157 ,  1.33278299],\n",
              "       [-1.36959991, -0.45363236],\n",
              "       [-0.01770341, -0.57077435],\n",
              "       [-0.59708762,  1.88920744],\n",
              "       [ 0.94793696, -1.21505529],\n",
              "       [ 0.36855274,  0.27850508],\n",
              "       [ 0.36855274,  0.13207759],\n",
              "       [ 0.85137292,  2.15277692],\n",
              "       [-1.8524201 , -0.01434989],\n",
              "       [ 1.23762906,  1.85992194],\n",
              "       [-1.94898413,  0.45421807],\n",
              "       [-0.59708762,  2.3284899 ],\n",
              "       [ 2.01014135,  2.12349142],\n",
              "       [ 0.2719887 ,  0.0442211 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikD0Sbcg3frX",
        "outputId": "33d04825-ba01-438c-96c1-26b3bec80cb9"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.57004704,  0.57903794],\n",
              "       [ 1.12037252, -1.02445174],\n",
              "       [ 0.55689934,  0.07423563],\n",
              "       [-0.85178364, -0.31178966],\n",
              "       [ 0.46298714, -0.46026093],\n",
              "       [ 0.46298714,  0.13362414],\n",
              "       [ 1.30819692, -0.69781495],\n",
              "       [-0.10048605,  1.20261726],\n",
              "       [ 2.2473189 ,  0.46026093],\n",
              "       [ 1.77775791, -0.84628622],\n",
              "       [ 0.46298714, -0.13362414],\n",
              "       [-0.38222265,  0.96506323],\n",
              "       [ 0.08733834, -0.16331839],\n",
              "       [ 1.21428472,  0.63842645],\n",
              "       [ 0.46298714, -1.1135345 ],\n",
              "       [-0.57004704,  2.0043621 ],\n",
              "       [-1.22743243, -0.13362414],\n",
              "       [ 0.36907494, -0.25240115],\n",
              "       [-0.10048605, -0.07423563],\n",
              "       [-0.00657385,  0.93536898],\n",
              "       [ 0.55689934, -0.10392989],\n",
              "       [-1.03960803, -1.35108853],\n",
              "       [ 0.55689934,  2.42008165],\n",
              "       [-0.94569584,  1.4995598 ],\n",
              "       [-0.57004704, -1.5589483 ],\n",
              "       [-1.13352023, -0.28209541],\n",
              "       [ 1.21428472, -1.17292301],\n",
              "       [-1.60308122,  0.25240115],\n",
              "       [ 0.55689934, -0.07423563],\n",
              "       [ 0.36907494,  1.17292301],\n",
              "       [ 0.93254813, -1.17292301],\n",
              "       [ 0.93254813,  0.43056667],\n",
              "       [-0.66395924, -0.60873219],\n",
              "       [-0.75787144,  0.63842645],\n",
              "       [ 1.68384571,  0.07423563],\n",
              "       [-1.22743243, -0.57903794],\n",
              "       [ 0.46298714, -0.46026093],\n",
              "       [-1.69699342,  0.01484713],\n",
              "       [-1.60308122,  0.51964943],\n",
              "       [ 1.96558231, -1.23231152],\n",
              "       [-1.32134463, -0.37117817],\n",
              "       [-0.85178364,  0.84628622],\n",
              "       [-1.03960803,  0.6681207 ],\n",
              "       [-1.13352023, -1.44017129],\n",
              "       [-0.38222265,  0.54934369],\n",
              "       [-0.10048605, -0.51964943],\n",
              "       [-1.41525683,  0.01484713],\n",
              "       [-0.85178364,  0.48995518],\n",
              "       [-0.57004704,  1.17292301],\n",
              "       [ 0.08733834,  2.27161038],\n",
              "       [-0.94569584, -0.96506323],\n",
              "       [ 0.93254813, -1.054146  ],\n",
              "       [ 0.08733834, -0.31178966],\n",
              "       [-0.66395924, -0.72750921],\n",
              "       [ 0.36907494,  0.13362414],\n",
              "       [ 0.18125054,  0.10392989],\n",
              "       [ 0.08733834,  0.2227069 ],\n",
              "       [-0.10048605,  0.10392989],\n",
              "       [ 2.05949451,  0.81659197],\n",
              "       [-1.22743243, -0.04454138],\n",
              "       [-1.50916903,  0.54934369],\n",
              "       [ 2.2473189 ,  1.02445174],\n",
              "       [ 0.46298714,  0.13362414],\n",
              "       [-0.66395924,  2.3903874 ],\n",
              "       [-1.69699342, -0.69781495],\n",
              "       [-0.47613484,  0.25240115],\n",
              "       [ 0.18125054, -0.19301265],\n",
              "       [ 0.08733834, -1.02445174],\n",
              "       [ 1.02646033, -1.32139428],\n",
              "       [-0.38222265, -1.46986554],\n",
              "       [-1.32134463, -1.20261726],\n",
              "       [ 0.18125054,  1.35108853],\n",
              "       [-0.10048605,  0.2227069 ],\n",
              "       [-1.22743243, -1.17292301],\n",
              "       [-0.10048605,  0.13362414],\n",
              "       [ 1.58993352, -0.99475749],\n",
              "       [-1.50916903, -0.93536898],\n",
              "       [ 0.83863593, -1.35108853],\n",
              "       [-0.85178364, -0.28209541],\n",
              "       [-1.32134463, -1.46986554],\n",
              "       [-0.47613484,  1.4995598 ],\n",
              "       [-0.47613484,  0.01484713],\n",
              "       [ 0.46298714,  0.10392989],\n",
              "       [ 2.05949451, -1.32139428],\n",
              "       [-0.00657385,  2.27161038],\n",
              "       [ 1.12037252,  2.09344486],\n",
              "       [ 0.08733834,  0.28209541],\n",
              "       [ 0.36907494,  0.31178966],\n",
              "       [-1.60308122, -1.44017129],\n",
              "       [ 1.12037252, -1.1135345 ],\n",
              "       [ 1.12037252,  2.18252762],\n",
              "       [ 0.55689934,  1.20261726],\n",
              "       [-0.10048605, -0.31178966],\n",
              "       [ 1.12037252,  1.52925405],\n",
              "       [ 0.83863593, -1.35108853],\n",
              "       [ 1.02646033, -1.1135345 ],\n",
              "       [-0.28831045, -0.72750921],\n",
              "       [-0.66395924,  0.2227069 ],\n",
              "       [-0.94569584,  0.48995518],\n",
              "       [ 1.30819692, -0.93536898]])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Variabes to calculate sigmoid function\n",
        "y_pred = []\n",
        "len_x = len(X_train[0])\n",
        "w = []\n",
        "b = 0.2\n",
        "print(len_x)"
      ],
      "metadata": {
        "id": "Vgt9hkf038gR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e29b97-3247-48c2-c754-271092a204c6"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entries = len(X_train[:,0])\n"
      ],
      "metadata": {
        "id": "5LL2j3pe7ByI"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_0YceD67P7_",
        "outputId": "063941f4-8285-4991-d130-fd6f51f2646b"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for weights in range(len_x):\n",
        "  w.append(0)"
      ],
      "metadata": {
        "id": "0Vqv4ouK7SFH"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF2UitfL7cCn",
        "outputId": "d1f0dfc9-883d-47db-faf8-0f77dd6a3d83"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  return (1/(1+np.exp(-z)))\n"
      ],
      "metadata": {
        "id": "ZViyyMee7fRn"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(inputs):\n",
        "  z=np.dot(inputs,w)+b\n",
        "  h=sigmoid(z)\n",
        "  for i in range((len(h))):\n",
        "    if(h[i]>=0.5):\n",
        "      h[i]=1\n",
        "    else:\n",
        "      h[i]=0\n",
        "  return h\n",
        "  \n"
      ],
      "metadata": {
        "id": "Pm4tu11X7x4f"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y"
      ],
      "metadata": {
        "id": "S5SLUCTi8jrI"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize.minpack import shape\n",
        "def loss_func(y,y1):\n",
        "  total_loss=np.sum(-y*np.log(y1)-(1-y)*np.log(1-y1))\n",
        "  m=y.shape[0]\n",
        "  j=total_loss/m\n",
        "  return j"
      ],
      "metadata": {
        "id": "2s1PF2K38mgP"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dw = []\n",
        "db = 0\n",
        "J = 0\n",
        "alpha = 0.1\n",
        "for x in range(len_x):\n",
        "  dw.append(0)"
      ],
      "metadata": {
        "id": "y7XMMhLCAGR3"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l1=[]\n",
        "for i in range(3000):\n",
        "    z = np.dot(X_train, w) + b\n",
        "    y_pred = sigmoid(z)\n",
        "    l = loss_func(y_train, y_pred)\n",
        "    l1.append(l)\n",
        "    dw = np.dot((y_pred-y_train).T, X_train)/X_train.shape[0]\n",
        "    db = np.mean(y_pred-y_train)\n",
        "    w = w - alpha * dw\n",
        "    b = b - alpha* db\n",
        "    print(\"Round:\",i,\"Weight:\",w,\"Bias:\",b,\"loss:\",l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-bGRoimALtW",
        "outputId": "a4a31eee-2ff1-4bda-f1e6-429940c12347"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round: 0 Weight: [0.03061134 0.01936347] Bias: 0.18134993360208554 loss: 0.7254722027149253\n",
            "Round: 1 Weight: [0.06036728 0.03809424] Bias: 0.16316367412488786 loss: 0.709109288181606\n",
            "Round: 2 Weight: [0.08929161 0.05621233] Bias: 0.14543326545305885 loss: 0.6936618389924295\n",
            "Round: 3 Weight: [0.11740912 0.07373843] Bias: 0.1281497827926154 loss: 0.6790793234465888\n",
            "Round: 4 Weight: [0.1447453  0.09069364] Bias: 0.11130350211925721 loss: 0.6653123100308653\n",
            "Round: 5 Weight: [0.17132607 0.10709921] Bias: 0.09488406171050523 loss: 0.6523128292207487\n",
            "Round: 6 Weight: [0.19717752 0.12297639] Bias: 0.07888061256200088 loss: 0.6400346544353539\n",
            "Round: 7 Weight: [0.22232566 0.13834625] Bias: 0.0632819555659879 loss: 0.6284335088016048\n",
            "Round: 8 Weight: [0.24679627 0.15322952] Bias: 0.04807666427323434 loss: 0.6174672059456463\n",
            "Round: 9 Weight: [0.27061473 0.16764648] Bias: 0.03325319283902331 loss: 0.6070957337814449\n",
            "Round: 10 Weight: [0.29380586 0.18161689] Bias: 0.018799969362375095 loss: 0.5972812903749466\n",
            "Round: 11 Weight: [0.31639389 0.19515989] Bias: 0.004705475274297514 loss: 0.5879882805976822\n",
            "Round: 12 Weight: [0.33840232 0.20829399] Bias: -0.00904168826567694 loss: 0.5791832816026093\n",
            "Round: 13 Weight: [0.35985389 0.22103699] Bias: -0.022452745821630524 loss: 0.5708349842891881\n",
            "Round: 14 Weight: [0.38077054 0.23340598] Bias: -0.03553870375041049 loss: 0.5629141169778199\n",
            "Round: 15 Weight: [0.40117339 0.24541734] Bias: -0.04831031563950518 loss: 0.5553933565619678\n",
            "Round: 16 Weight: [0.42108271 0.25708672] Bias: -0.06077805590040321 loss: 0.5482472315012413\n",
            "Round: 17 Weight: [0.44051796 0.26842906] Bias: -0.0729521003739389 loss: 0.5414520201922858\n",
            "Round: 18 Weight: [0.45949773 0.27945859] Bias: -0.08484231289507417 loss: 0.534985647522913\n",
            "Round: 19 Weight: [0.47803984 0.29018886] Bias: -0.09645823686640732 loss: 0.5288275817839218\n",
            "Round: 20 Weight: [0.49616129 0.30063278] Bias: -0.1078090909948898 loss: 0.5229587335803577\n",
            "Round: 21 Weight: [0.5138783  0.31080259] Bias: -0.11890376844951005 loss: 0.5173613579427065\n",
            "Round: 22 Weight: [0.53120635 0.32070993] Bias: -0.1297508387956085 loss: 0.5120189604793605\n",
            "Round: 23 Weight: [0.54816021 0.33036585] Bias: -0.14035855215193754 loss: 0.5069162081241817\n",
            "Round: 24 Weight: [0.56475394 0.33978084] Bias: -0.15073484509850174 loss: 0.5020388448066434\n",
            "Round: 25 Weight: [0.58100096 0.34896485] Bias: -0.16088734793625925 loss: 0.4973736121969267\n",
            "Round: 26 Weight: [0.59691403 0.35792734] Bias: -0.1708233929640676 loss: 0.4929081755455316\n",
            "Round: 27 Weight: [0.61250531 0.36667727] Bias: -0.1805500234942698 loss: 0.488631054538472\n",
            "Round: 28 Weight: [0.62778642 0.37522314] Bias: -0.19007400337667119 loss: 0.48453155901821476\n",
            "Round: 29 Weight: [0.64276839 0.38357304] Bias: -0.19940182684208038 loss: 0.48059972937142353\n",
            "Round: 30 Weight: [0.65746174 0.39173462] Bias: -0.20853972851183264 loss: 0.4768262813525301\n",
            "Round: 31 Weight: [0.67187653 0.39971517] Bias: -0.21749369344951985 loss: 0.47320255509327297\n",
            "Round: 32 Weight: [0.6860223 0.4075216] Bias: -0.22626946715621774 loss: 0.46972046803945033\n",
            "Round: 33 Weight: [0.69990818 0.41516049] Bias: -0.2348725654314709 loss: 0.4663724715546918\n",
            "Round: 34 Weight: [0.71354288 0.42263807] Bias: -0.2433082840397509 loss: 0.46315151093506274\n",
            "Round: 35 Weight: [0.72693469 0.42996028] Bias: -0.251581708136559 loss: 0.46005098858617355\n",
            "Round: 36 Weight: [0.74009155 0.43713277] Bias: -0.25969772142025516 loss: 0.4570647301249732\n",
            "Round: 37 Weight: [0.75302102 0.44416091] Bias: -0.26766101498545863 loss: 0.4541869531805872\n",
            "Round: 38 Weight: [0.76573033 0.45104981] Bias: -0.2754760958618177 loss: 0.45141223868172736\n",
            "Round: 39 Weight: [0.77822639 0.45780435] Bias: -0.28314729522838544 loss: 0.44873550443178145\n",
            "Round: 40 Weight: [0.79051581 0.46442917] Bias: -0.2906787762990134 loss: 0.44615198078633067\n",
            "Round: 41 Weight: [0.8026049  0.47092869] Bias: -0.2980745418782945 loss: 0.44365718826121037\n",
            "Round: 42 Weight: [0.81449971 0.47730713] Bias: -0.3053384415908381 loss: 0.4412469169121696\n",
            "Round: 43 Weight: [0.82620602 0.48356852] Bias: -0.31247417878918515 loss: 0.4389172073395256\n",
            "Round: 44 Weight: [0.83772938 0.48971668] Bias: -0.31948531714760847 loss: 0.4366643331828978\n",
            "Round: 45 Weight: [0.84907508 0.4957553 ] Bias: -0.32637528695048845 loss: 0.4344847849820752\n",
            "Round: 46 Weight: [0.86024823 0.50168788] Bias: -0.3331473910850059 loss: 0.4323752552903122\n",
            "Round: 47 Weight: [0.87125371 0.50751777] Bias: -0.33980481074862023 loss: 0.43033262493586366\n",
            "Round: 48 Weight: [0.88209618 0.51324817] Bias: -0.3463506108822675 loss: 0.4283539503363764\n",
            "Round: 49 Weight: [0.89278014 0.51888214] Bias: -0.352787745340468 loss: 0.42643645177887113\n",
            "Round: 50 Weight: [0.90330991 0.52442263] Bias: -0.35911906180962466 loss: 0.42457750258552324\n",
            "Round: 51 Weight: [0.91368963 0.52987243] Bias: -0.3653473064857478 loss: 0.4227746190923066\n",
            "Round: 52 Weight: [0.92392328 0.53523424] Bias: -0.37147512852269887 loss: 0.4210254513738484\n",
            "Round: 53 Weight: [0.93401469 0.54051064] Bias: -0.3775050842618188 loss: 0.4193277746535906\n",
            "Round: 54 Weight: [0.94396753 0.54570411] Bias: -0.38343964125352387 loss: 0.4176794813436099\n",
            "Round: 55 Weight: [0.95378536 0.550817  ] Bias: -0.3892811820811222 loss: 0.41607857366324275\n",
            "Round: 56 Weight: [0.96347157 0.55585161] Bias: -0.395032007996745 loss: 0.41452315679003965\n",
            "Round: 57 Weight: [0.97302945 0.56081012] Bias: -0.40069434237890683 loss: 0.41301143250056505\n",
            "Round: 58 Weight: [0.98246216 0.56569462] Bias: -0.4062703340208183 loss: 0.4115416932621942\n",
            "Round: 59 Weight: [0.99177276 0.57050714] Bias: -0.4117620602581743 loss: 0.4101123167403766\n",
            "Round: 60 Weight: [1.00096417 0.57524961] Bias: -0.417171529944746 loss: 0.4087217606888535\n",
            "Round: 61 Weight: [1.01003924 0.57992391] Bias: -0.42250068628370946 loss: 0.40736855819307116\n",
            "Round: 62 Weight: [1.01900069 0.58453181] Bias: -0.4277514095222579 loss: 0.40605131323953536\n",
            "Round: 63 Weight: [1.02785116 0.58907506] Bias: -0.43292551951666675 loss: 0.40476869658614156\n",
            "Round: 64 Weight: [1.03659321 0.59355532] Bias: -0.4380247781746158 loss: 0.40351944191059363\n",
            "Round: 65 Weight: [1.04522929 0.59797418] Bias: -0.4430508917812196 loss: 0.4023023422159218\n",
            "Round: 66 Weight: [1.05376179 0.60233319] Bias: -0.4480055132148764 loss: 0.4011162464738451\n",
            "Round: 67 Weight: [1.06219299 0.60663384] Bias: -0.4528902440587233 loss: 0.39996005648829497\n",
            "Round: 68 Weight: [1.07052512 0.61087757] Bias: -0.45770663661317074 loss: 0.3988327239628642\n",
            "Round: 69 Weight: [1.07876034 0.61506575] Bias: -0.4624561958146953 loss: 0.39773324775725305\n",
            "Round: 70 Weight: [1.08690072 0.61919973] Bias: -0.4671403810657864 loss: 0.39666067131898985\n",
            "Round: 71 Weight: [1.09494827 0.62328079] Bias: -0.4717606079806735 loss: 0.3956140802777954\n",
            "Round: 72 Weight: [1.10290495 0.62731018] Bias: -0.47631825005120687 loss: 0.3945926001909672\n",
            "Round: 73 Weight: [1.11077264 0.63128909] Bias: -0.4808146402370234 loss: 0.39359539442907104\n",
            "Round: 74 Weight: [1.11855317 0.63521871] Bias: -0.48525107248389915 loss: 0.3926216621920698\n",
            "Round: 75 Weight: [1.12624832 0.63910014] Bias: -0.4896288031739763 loss: 0.39167063664678403\n",
            "Round: 76 Weight: [1.13385979 0.64293447] Bias: -0.49394905251134663 loss: 0.39074158317728336\n",
            "Round: 77 Weight: [1.14138927 0.64672276] Bias: -0.4982130058462811 loss: 0.38983379774044935\n",
            "Round: 78 Weight: [1.14883837 0.65046602] Bias: -0.5024218149412127 loss: 0.3889466053195444\n",
            "Round: 79 Weight: [1.15620865 0.65416523] Bias: -0.5065765991814092 loss: 0.38807935846915875\n",
            "Round: 80 Weight: [1.16350164 0.65782135] Bias: -0.5106784467331086 loss: 0.38723143594540704\n",
            "Round: 81 Weight: [1.17071881 0.66143531] Bias: -0.5147284156517393 loss: 0.3864022414157025\n",
            "Round: 82 Weight: [1.17786161 0.66500799] Bias: -0.5187275349427011 loss: 0.3855912022428541\n",
            "Round: 83 Weight: [1.18493142 0.66854025] Bias: -0.5226768055770487 loss: 0.3847977683386203\n",
            "Round: 84 Weight: [1.1919296  0.67203295] Bias: -0.5265772014642918 loss: 0.384021411082205\n",
            "Round: 85 Weight: [1.19885747 0.6754869 ] Bias: -0.5304296703844038 loss: 0.38326162229950905\n",
            "Round: 86 Weight: [1.20571631 0.67890288] Bias: -0.5342351348810197 loss: 0.3825179132992526\n",
            "Round: 87 Weight: [1.21250737 0.68228166] Bias: -0.5379944931176939 loss: 0.3817898139623567\n",
            "Round: 88 Weight: [1.21923185 0.68562398] Bias: -0.5417086196989921 loss: 0.3810768718812323\n",
            "Round: 89 Weight: [1.22589094 0.68893057] Bias: -0.5453783664580922 loss: 0.38037865154585787\n",
            "Round: 90 Weight: [1.23248578 0.69220212] Bias: -0.5490045632124825 loss: 0.37969473357374384\n",
            "Round: 91 Weight: [1.23901749 0.69543932] Bias: -0.5525880184892589 loss: 0.37902471398108517\n",
            "Round: 92 Weight: [1.24548715 0.69864282] Bias: -0.5561295202214468 loss: 0.3783682034925869\n",
            "Round: 93 Weight: [1.25189583 0.70181328] Bias: -0.5596298364166946 loss: 0.3777248268876196\n",
            "Round: 94 Weight: [1.25824455 0.70495131] Bias: -0.5630897157996165 loss: 0.37709422238052054\n",
            "Round: 95 Weight: [1.26453432 0.70805751] Bias: -0.5665098884289979 loss: 0.37647604103300336\n",
            "Round: 96 Weight: [1.27076613 0.71113249] Bias: -0.5698910662910092 loss: 0.37586994619677494\n",
            "Round: 97 Weight: [1.27694091 0.7141768 ] Bias: -0.5732339438695205 loss: 0.37527561298458345\n",
            "Round: 98 Weight: [1.28305962 0.71719102] Bias: -0.5765391986945476 loss: 0.3746927277680395\n",
            "Round: 99 Weight: [1.28912315 0.72017568] Bias: -0.5798074918698113 loss: 0.3741209877006603\n",
            "Round: 100 Weight: [1.29513238 0.72313132] Bias: -0.5830394685803413 loss: 0.37356010026468717\n",
            "Round: 101 Weight: [1.30108819 0.72605844] Bias: -0.5862357585810075 loss: 0.37300978284031916\n",
            "Round: 102 Weight: [1.30699142 0.72895755] Bias: -0.5893969766668186 loss: 0.37246976229609496\n",
            "Round: 103 Weight: [1.31284289 0.73182913] Bias: -0.5925237231257853 loss: 0.3719397745992331\n",
            "Round: 104 Weight: [1.3186434  0.73467367] Bias: -0.595616584175106 loss: 0.3714195644448162\n",
            "Round: 105 Weight: [1.32439373 0.73749161] Bias: -0.5986761323813958 loss: 0.3709088849027763\n",
            "Round: 106 Weight: [1.33009466 0.74028343] Bias: -0.6017029270656425 loss: 0.37040749708170084\n",
            "Round: 107 Weight: [1.33574693 0.74304954] Bias: -0.604697514693543 loss: 0.3699151698085413\n",
            "Round: 108 Weight: [1.34135127 0.7457904 ] Bias: -0.607660429251838 loss: 0.36943167932336185\n",
            "Round: 109 Weight: [1.3469084 0.7485064] Bias: -0.6105921926112368 loss: 0.368956808988318\n",
            "Round: 110 Weight: [1.35241901 0.75119796] Bias: -0.6134933148764915 loss: 0.3684903490101046\n",
            "Round: 111 Weight: [1.35788379 0.75386548] Bias: -0.6163642947241581 loss: 0.3680320961751574\n",
            "Round: 112 Weight: [1.3633034  0.75650934] Bias: -0.6192056197285511 loss: 0.3675818535969375\n",
            "Round: 113 Weight: [1.36867851 0.75912993] Bias: -0.6220177666763788 loss: 0.3671394304746629\n",
            "Round: 114 Weight: [1.37400973 0.76172761] Bias: -0.6248012018705201 loss: 0.3667046418628953\n",
            "Round: 115 Weight: [1.37929771 0.76430274] Bias: -0.6275563814233862 loss: 0.36627730845141876\n",
            "Round: 116 Weight: [1.38454304 0.76685568] Bias: -0.6302837515402845 loss: 0.36585725635488436\n",
            "Round: 117 Weight: [1.38974634 0.76938677] Bias: -0.6329837487931875 loss: 0.3654443169117215\n",
            "Round: 118 Weight: [1.39490818 0.77189635] Bias: -0.6356568003852896 loss: 0.3650383264918482\n",
            "Round: 119 Weight: [1.40002913 0.77438474] Bias: -0.6383033244067153 loss: 0.36463912631273776\n",
            "Round: 120 Weight: [1.40510976 0.77685226] Bias: -0.6409237300817292 loss: 0.3642465622634243\n",
            "Round: 121 Weight: [1.41015061 0.77929924] Bias: -0.6435184180077788 loss: 0.36386048473605315\n",
            "Round: 122 Weight: [1.41515223 0.78172597] Bias: -0.6460877803866889 loss: 0.36348074846460526\n",
            "Round: 123 Weight: [1.42011513 0.78413275] Bias: -0.6486322012483122 loss: 0.3631072123704437\n",
            "Round: 124 Weight: [1.42503984 0.78651988] Bias: -0.6511520566669239 loss: 0.3627397394143504\n",
            "Round: 125 Weight: [1.42992686 0.78888765] Bias: -0.6536477149706398 loss: 0.36237819645474\n",
            "Round: 126 Weight: [1.43477669 0.79123633] Bias: -0.6561195369441224 loss: 0.3620224541117537\n",
            "Round: 127 Weight: [1.4395898 0.7935662] Bias: -0.6585678760248284 loss: 0.36167238663695334\n",
            "Round: 128 Weight: [1.44436669 0.79587752] Bias: -0.6609930784930405 loss: 0.36132787178834985\n",
            "Round: 129 Weight: [1.4491078  0.79817056] Bias: -0.6633954836559157 loss: 0.36098879071051454\n",
            "Round: 130 Weight: [1.45381361 0.80044558] Bias: -0.6657754240257724 loss: 0.3606550278195359\n",
            "Round: 131 Weight: [1.45848455 0.80270282] Bias: -0.6681332254928283 loss: 0.3603264706925962\n",
            "Round: 132 Weight: [1.46312107 0.80494254] Bias: -0.670469207492594 loss: 0.3600030099619551\n",
            "Round: 133 Weight: [1.4677236  0.80716497] Bias: -0.6727836831681167 loss: 0.3596845392131364\n",
            "Round: 134 Weight: [1.47229257 0.80937034] Bias: -0.6750769595272604 loss: 0.3593709548871278\n",
            "Round: 135 Weight: [1.47682838 0.8115589 ] Bias: -0.6773493375952031 loss: 0.3590621561864101\n",
            "Round: 136 Weight: [1.48133144 0.81373086] Bias: -0.679601112562321 loss: 0.35875804498464414\n",
            "Round: 137 Weight: [1.48580216 0.81588644] Bias: -0.6818325739276262 loss: 0.3584585257398516\n",
            "Round: 138 Weight: [1.49024093 0.81802588] Bias: -0.6840440056379136 loss: 0.3581635054109331\n",
            "Round: 139 Weight: [1.49464813 0.82014937] Bias: -0.6862356862227702 loss: 0.3578728933773764\n",
            "Round: 140 Weight: [1.49902414 0.82225712] Bias: -0.6884078889255916 loss: 0.35758660136201503\n",
            "Round: 141 Weight: [1.50336933 0.82434934] Bias: -0.6905608818307436 loss: 0.3573045433567023\n",
            "Round: 142 Weight: [1.50768406 0.82642624] Bias: -0.6926949279870053 loss: 0.3570266355507754\n",
            "Round: 143 Weight: [1.5119687 0.828488 ] Bias: -0.6948102855274195 loss: 0.35675279626218753\n",
            "Round: 144 Weight: [1.5162236  0.83053482] Bias: -0.6969072077856758 loss: 0.3564829458711951\n",
            "Round: 145 Weight: [1.5204491  0.83256689] Bias: -0.6989859434091433 loss: 0.35621700675648904\n",
            "Round: 146 Weight: [1.52464554 0.83458439] Bias: -0.701046736468668 loss: 0.3559549032336675\n",
            "Round: 147 Weight: [1.52881325 0.8365875 ] Bias: -0.7030898265652429 loss: 0.35569656149595064\n",
            "Round: 148 Weight: [1.53295256 0.83857641] Bias: -0.7051154489336571 loss: 0.3554419095570433\n",
            "Round: 149 Weight: [1.5370638  0.84055129] Bias: -0.707123834543224 loss: 0.3551908771960563\n",
            "Round: 150 Weight: [1.54114728 0.8425123 ] Bias: -0.7091152101956864 loss: 0.3549433959044\n",
            "Round: 151 Weight: [1.54520331 0.84445963] Bias: -0.711089798620391 loss: 0.3546993988345695\n",
            "Round: 152 Weight: [1.5492322  0.84639342] Bias: -0.713047818566824 loss: 0.3544588207507436\n",
            "Round: 153 Weight: [1.55323424 0.84831386] Bias: -0.7149894848945909 loss: 0.35422159798112274\n",
            "Round: 154 Weight: [1.55720974 0.85022109] Bias: -0.716915008660928 loss: 0.35398766837193707\n",
            "Round: 155 Weight: [1.56115898 0.85211527] Bias: -0.7188245972058217 loss: 0.3537569712430548\n",
            "Round: 156 Weight: [1.56508226 0.85399655] Bias: -0.7207184542348146 loss: 0.35352944734512876\n",
            "Round: 157 Weight: [1.56897984 0.85586509] Bias: -0.7225967798995734 loss: 0.3533050388182181\n",
            "Round: 158 Weight: [1.57285201 0.85772103] Bias: -0.7244597708762874 loss: 0.3530836891518281\n",
            "Round: 159 Weight: [1.57669905 0.85956453] Bias: -0.7263076204419694 loss: 0.35286534314630996\n",
            "Round: 160 Weight: [1.58052121 0.86139571] Bias: -0.7281405185487224 loss: 0.35264994687556966\n",
            "Round: 161 Weight: [1.58431876 0.86321473] Bias: -0.7299586518960391 loss: 0.35243744765103246\n",
            "Round: 162 Weight: [1.58809196 0.86502172] Bias: -0.7317622040011932 loss: 0.35222779398681575\n",
            "Round: 163 Weight: [1.59184107 0.86681682] Bias: -0.7335513552677824 loss: 0.3520209355660627\n",
            "Round: 164 Weight: [1.59556634 0.86860016] Bias: -0.735326283052482 loss: 0.3518168232083919\n",
            "Round: 165 Weight: [1.59926801 0.87037186] Bias: -0.7370871617300622 loss: 0.3516154088384221\n",
            "Round: 166 Weight: [1.60294633 0.87213207] Bias: -0.7388341627567224 loss: 0.351416645455328\n",
            "Round: 167 Weight: [1.60660154 0.8738809 ] Bias: -0.7405674547317966 loss: 0.35122048710339066\n",
            "Round: 168 Weight: [1.61023387 0.87561849] Bias: -0.7422872034578755 loss: 0.3510268888435043\n",
            "Round: 169 Weight: [1.61384355 0.87734494] Bias: -0.7439935719993953 loss: 0.3508358067256032\n",
            "Round: 170 Weight: [1.61743082 0.8790604 ] Bias: -0.7456867207397404 loss: 0.35064719776197467\n",
            "Round: 171 Weight: [1.6209959  0.88076496] Bias: -0.747366807436901 loss: 0.3504610199014253\n",
            "Round: 172 Weight: [1.62453901 0.88245875] Bias: -0.7490339872777326 loss: 0.35027723200426936\n",
            "Round: 173 Weight: [1.62806037 0.88414188] Bias: -0.7506884129308561 loss: 0.35009579381810835\n",
            "Round: 174 Weight: [1.63156019 0.88581447] Bias: -0.7523302345982394 loss: 0.34991666595437265\n",
            "Round: 175 Weight: [1.6350387  0.88747663] Bias: -0.7539596000655002 loss: 0.3497398098655997\n",
            "Round: 176 Weight: [1.63849608 0.88912846] Bias: -0.7555766547509658 loss: 0.34956518782341894\n",
            "Round: 177 Weight: [1.64193256 0.89077008] Bias: -0.7571815417535271 loss: 0.3493927628972202\n",
            "Round: 178 Weight: [1.64534834 0.89240158] Bias: -0.7587744018993218 loss: 0.3492224989334808\n",
            "Round: 179 Weight: [1.64874361 0.89402308] Bias: -0.7603553737872796 loss: 0.3490543605357268\n",
            "Round: 180 Weight: [1.65211857 0.89563467] Bias: -0.7619245938335633 loss: 0.3488883130451075\n",
            "Round: 181 Weight: [1.65547342 0.89723646] Bias: -0.7634821963149366 loss: 0.34872432252156005\n",
            "Round: 182 Weight: [1.65880834 0.89882854] Bias: -0.7650283134110895 loss: 0.3485623557255444\n",
            "Round: 183 Weight: [1.66212353 0.90041101] Bias: -0.7665630752459495 loss: 0.3484023801003285\n",
            "Round: 184 Weight: [1.66541917 0.90198397] Bias: -0.7680866099280103 loss: 0.3482443637548038\n",
            "Round: 185 Weight: [1.66869545 0.90354752] Bias: -0.769599043589702 loss: 0.34808827544681464\n",
            "Round: 186 Weight: [1.67195255 0.90510174] Bias: -0.7711005004258317 loss: 0.3479340845669809\n",
            "Round: 187 Weight: [1.67519064 0.90664673] Bias: -0.77259110273112 loss: 0.3477817611230002\n",
            "Round: 188 Weight: [1.6784099  0.90818258] Bias: -0.7740709709368581 loss: 0.3476312757244107\n",
            "Round: 189 Weight: [1.6816105  0.90970938] Bias: -0.7755402236467099 loss: 0.3474825995678\n",
            "Round: 190 Weight: [1.68479262 0.91122722] Bias: -0.7769989776716832 loss: 0.3473357044224455\n",
            "Round: 191 Weight: [1.68795642 0.91273617] Bias: -0.778447348064291 loss: 0.3471905626163704\n",
            "Round: 192 Weight: [1.69110207 0.91423633] Bias: -0.779885448151927 loss: 0.34704714702280276\n",
            "Round: 193 Weight: [1.69422974 0.91572779] Bias: -0.7813133895694756 loss: 0.3469054310470231\n",
            "Round: 194 Weight: [1.69733958 0.91721062] Bias: -0.782731282291177 loss: 0.3467653886135885\n",
            "Round: 195 Weight: [1.70043176 0.9186849 ] Bias: -0.7841392346617676 loss: 0.3466269941539199\n",
            "Round: 196 Weight: [1.70350643 0.92015072] Bias: -0.7855373534269146 loss: 0.3464902225942415\n",
            "Round: 197 Weight: [1.70656375 0.92160816] Bias: -0.7869257437629649 loss: 0.3463550493438605\n",
            "Round: 198 Weight: [1.70960387 0.92305729] Bias: -0.7883045093060252 loss: 0.3462214502837751\n",
            "Round: 199 Weight: [1.71262695 0.92449818] Bias: -0.7896737521803918 loss: 0.34608940175560204\n",
            "Round: 200 Weight: [1.71563313 0.92593093] Bias: -0.7910335730263459 loss: 0.3459588805508116\n",
            "Round: 201 Weight: [1.71862256 0.92735559] Bias: -0.7923840710273332 loss: 0.34582986390026094\n",
            "Round: 202 Weight: [1.72159539 0.92877225] Bias: -0.7937253439365421 loss: 0.345702329464016\n",
            "Round: 203 Weight: [1.72455176 0.93018098] Bias: -0.7950574881028968 loss: 0.3455762553214536\n",
            "Round: 204 Weight: [1.7274918  0.93158185] Bias: -0.7963805984964797 loss: 0.3454516199616329\n",
            "Round: 205 Weight: [1.73041568 0.93297492] Bias: -0.7976947687333997 loss: 0.34532840227393014\n",
            "Round: 206 Weight: [1.73332351 0.93436028] Bias: -0.7990000911001186 loss: 0.3452065815389266\n",
            "Round: 207 Weight: [1.73621544 0.93573798] Bias: -0.8002966565772501 loss: 0.34508613741954197\n",
            "Round: 208 Weight: [1.7390916 0.9371081] Bias: -0.8015845548628455 loss: 0.34496704995240757\n",
            "Round: 209 Weight: [1.74195213 0.93847071] Bias: -0.8028638743951784 loss: 0.34484929953946825\n",
            "Round: 210 Weight: [1.74479715 0.93982586] Bias: -0.8041347023750407 loss: 0.344732866939809\n",
            "Round: 211 Weight: [1.7476268  0.94117362] Bias: -0.8053971247875641 loss: 0.344617733261699\n",
            "Round: 212 Weight: [1.7504412  0.94251407] Bias: -0.8066512264235762 loss: 0.34450387995484466\n",
            "Round: 213 Weight: [1.75324049 0.94384726] Bias: -0.8078970909005057 loss: 0.3443912888028466\n",
            "Round: 214 Weight: [1.75602478 0.94517325] Bias: -0.8091348006828446 loss: 0.3442799419158548\n",
            "Round: 215 Weight: [1.7587942  0.94649211] Bias: -0.8103644371021829 loss: 0.3441698217234146\n",
            "Round: 216 Weight: [1.76154888 0.9478039 ] Bias: -0.811586080376821 loss: 0.3440609109674986\n",
            "Round: 217 Weight: [1.76428892 0.94910867] Bias: -0.8127998096309752 loss: 0.3439531926957193\n",
            "Round: 218 Weight: [1.76701446 0.95040649] Bias: -0.8140057029135824 loss: 0.3438466502547157\n",
            "Round: 219 Weight: [1.76972561 0.95169742] Bias: -0.8152038372167163 loss: 0.3437412672837103\n",
            "Round: 220 Weight: [1.77242248 0.95298151] Bias: -0.8163942884936233 loss: 0.34363702770822974\n",
            "Round: 221 Weight: [1.77510519 0.95425883] Bias: -0.8175771316763873 loss: 0.34353391573398634\n",
            "Round: 222 Weight: [1.77777386 0.95552942] Bias: -0.8187524406932337 loss: 0.34343191584091354\n",
            "Round: 223 Weight: [1.78042859 0.95679334] Bias: -0.8199202884854789 loss: 0.3433310127773525\n",
            "Round: 224 Weight: [1.7830695  0.95805065] Bias: -0.8210807470241365 loss: 0.3432311915543844\n",
            "Round: 225 Weight: [1.7856967  0.95930141] Bias: -0.8222338873261856 loss: 0.34313243744030514\n",
            "Round: 226 Weight: [1.78831029 0.96054566] Bias: -0.8233797794705123 loss: 0.3430347359552369\n",
            "Round: 227 Weight: [1.79091038 0.96178346] Bias: -0.824518492613529 loss: 0.34293807286587413\n",
            "Round: 228 Weight: [1.79349708 0.96301486] Bias: -0.8256500950044817 loss: 0.3428424341803594\n",
            "Round: 229 Weight: [1.79607049 0.96423991] Bias: -0.8267746540004508 loss: 0.34274780614328515\n",
            "Round: 230 Weight: [1.79863072 0.96545867] Bias: -0.8278922360810539 loss: 0.34265417523081854\n",
            "Round: 231 Weight: [1.80117787 0.96667118] Bias: -0.8290029068628566 loss: 0.3425615281459446\n",
            "Round: 232 Weight: [1.80371204 0.9678775 ] Bias: -0.8301067311134989 loss: 0.3424698518138262\n",
            "Round: 233 Weight: [1.80623332 0.96907767] Bias: -0.8312037727655425 loss: 0.342379133377276\n",
            "Round: 234 Weight: [1.80874182 0.97027174] Bias: -0.8322940949300476 loss: 0.34228936019233747\n",
            "Round: 235 Weight: [1.81123764 0.97145977] Bias: -0.8333777599098828 loss: 0.34220051982397254\n",
            "Round: 236 Weight: [1.81372087 0.97264179] Bias: -0.8344548292127768 loss: 0.342112600041853\n",
            "Round: 237 Weight: [1.81619161 0.97381785] Bias: -0.8355253635641152 loss: 0.34202558881625145\n",
            "Round: 238 Weight: [1.81864995 0.97498801] Bias: -0.8365894229194911 loss: 0.3419394743140308\n",
            "Round: 239 Weight: [1.82109598 0.97615231] Bias: -0.837647066477012 loss: 0.3418542448947284\n",
            "Round: 240 Weight: [1.8235298  0.97731078] Bias: -0.8386983526893713 loss: 0.3417698891067322\n",
            "Round: 241 Weight: [1.8259515  0.97846349] Bias: -0.8397433392756877 loss: 0.34168639568354814\n",
            "Round: 242 Weight: [1.82836117 0.97961046] Bias: -0.8407820832331185 loss: 0.34160375354015327\n",
            "Round: 243 Weight: [1.8307589  0.98075175] Bias: -0.8418146408482526 loss: 0.34152195176943506\n",
            "Round: 244 Weight: [1.83314477 0.9818874 ] Bias: -0.8428410677082863 loss: 0.3414409796387133\n",
            "Round: 245 Weight: [1.83551888 0.98301745] Bias: -0.843861418711988 loss: 0.3413608265863423\n",
            "Round: 246 Weight: [1.83788131 0.98414194] Bias: -0.8448757480804573 loss: 0.341281482218392\n",
            "Round: 247 Weight: [1.84023215 0.98526092] Bias: -0.84588410936768 loss: 0.3412029363054044\n",
            "Round: 248 Weight: [1.84257147 0.98637443] Bias: -0.8468865554708875 loss: 0.3411251787792255\n",
            "Round: 249 Weight: [1.84489938 0.9874825 ] Bias: -0.8478831386407214 loss: 0.34104819972990874\n",
            "Round: 250 Weight: [1.84721594 0.98858518] Bias: -0.8488739104912096 loss: 0.3409719894026891\n",
            "Round: 251 Weight: [1.84952124 0.9896825 ] Bias: -0.8498589220095577 loss: 0.34089653819502563\n",
            "Round: 252 Weight: [1.85181535 0.99077451] Bias: -0.8508382235657584 loss: 0.34082183665371113\n",
            "Round: 253 Weight: [1.85409838 0.99186125] Bias: -0.8518118649220251 loss: 0.34074787547204594\n",
            "Round: 254 Weight: [1.85637038 0.99294275] Bias: -0.8527798952420513 loss: 0.34067464548707627\n",
            "Round: 255 Weight: [1.85863144 0.99401906] Bias: -0.853742363100101 loss: 0.34060213767689324\n",
            "Round: 256 Weight: [1.86088163 0.9950902 ] Bias: -0.8546993164899329 loss: 0.3405303431579926\n",
            "Round: 257 Weight: [1.86312105 0.99615623] Bias: -0.8556508028335624 loss: 0.3404592531826921\n",
            "Round: 258 Weight: [1.86534975 0.99721716] Bias: -0.8565968689898651 loss: 0.3403888591366077\n",
            "Round: 259 Weight: [1.86756781 0.99827305] Bias: -0.8575375612630235 loss: 0.3403191525361831\n",
            "Round: 260 Weight: [1.86977532 0.99932393] Bias: -0.8584729254108233 loss: 0.3402501250262752\n",
            "Round: 261 Weight: [1.87197234 1.00036983] Bias: -0.8594030066527991 loss: 0.34018176837779135\n",
            "Round: 262 Weight: [1.87415895 1.00141079] Bias: -0.860327849678235 loss: 0.34011407448537834\n",
            "Round: 263 Weight: [1.87633521 1.00244684] Bias: -0.861247498654022 loss: 0.3400470353651623\n",
            "Round: 264 Weight: [1.87850121 1.00347801] Bias: -0.862161997232376 loss: 0.3399806431525359\n",
            "Round: 265 Weight: [1.88065701 1.00450436] Bias: -0.8630713885584183 loss: 0.3399148900999948\n",
            "Round: 266 Weight: [1.88280269 1.00552589] Bias: -0.8639757152776224 loss: 0.33984976857501953\n",
            "Round: 267 Weight: [1.8849383  1.00654266] Bias: -0.8648750195431294 loss: 0.3397852710580035\n",
            "Round: 268 Weight: [1.88706392 1.00755469] Bias: -0.8657693430229342 loss: 0.3397213901402244\n",
            "Round: 269 Weight: [1.88917963 1.00856202] Bias: -0.8666587269069467 loss: 0.3396581185218596\n",
            "Round: 270 Weight: [1.89128548 1.00956467] Bias: -0.8675432119139288 loss: 0.33959544901004274\n",
            "Round: 271 Weight: [1.89338154 1.01056269] Bias: -0.8684228382983109 loss: 0.33953337451696197\n",
            "Round: 272 Weight: [1.89546788 1.01155609] Bias: -0.8692976458568898 loss: 0.33947188805799844\n",
            "Round: 273 Weight: [1.89754457 1.01254492] Bias: -0.870167673935411 loss: 0.33941098274990233\n",
            "Round: 274 Weight: [1.89961167 1.01352921] Bias: -0.8710329614350361 loss: 0.3393506518090093\n",
            "Round: 275 Weight: [1.90166924 1.01450898] Bias: -0.8718935468187008 loss: 0.3392908885494923\n",
            "Round: 276 Weight: [1.90371735 1.01548427] Bias: -0.8727494681173618 loss: 0.33923168638165013\n",
            "Round: 277 Weight: [1.90575606 1.01645511] Bias: -0.8736007629361379 loss: 0.3391730388102319\n",
            "Round: 278 Weight: [1.90778543 1.01742152] Bias: -0.8744474684603462 loss: 0.33911493943279597\n",
            "Round: 279 Weight: [1.90980553 1.01838354] Bias: -0.8752896214614349 loss: 0.3390573819381013\n",
            "Round: 280 Weight: [1.91181641 1.01934119] Bias: -0.8761272583028161 loss: 0.3390003601045344\n",
            "Round: 281 Weight: [1.91381814 1.02029451] Bias: -0.8769604149456001 loss: 0.33894386779856517\n",
            "Round: 282 Weight: [1.91581078 1.02124353] Bias: -0.8777891269542315 loss: 0.3388878989732376\n",
            "Round: 283 Weight: [1.91779438 1.02218826] Bias: -0.8786134295020326 loss: 0.3388324476666878\n",
            "Round: 284 Weight: [1.91976901 1.02312875] Bias: -0.879433357376652 loss: 0.33877750800069456\n",
            "Round: 285 Weight: [1.92173472 1.02406501] Bias: -0.8802489449854232 loss: 0.3387230741792577\n",
            "Round: 286 Weight: [1.92369158 1.02499708] Bias: -0.8810602263606331 loss: 0.3386691404872056\n",
            "Round: 287 Weight: [1.92563963 1.02592499] Bias: -0.8818672351647034 loss: 0.3386157012888304\n",
            "Round: 288 Weight: [1.92757894 1.02684875] Bias: -0.8826700046952859 loss: 0.3385627510265506\n",
            "Round: 289 Weight: [1.92950956 1.0277684 ] Bias: -0.8834685678902728 loss: 0.33851028421959967\n",
            "Round: 290 Weight: [1.93143155 1.02868397] Bias: -0.8842629573327261 loss: 0.3384582954627421\n",
            "Round: 291 Weight: [1.93334496 1.02959547] Bias: -0.8850532052557238 loss: 0.33840677942501307\n",
            "Round: 292 Weight: [1.93524985 1.03050295] Bias: -0.8858393435471287 loss: 0.33835573084848414\n",
            "Round: 293 Weight: [1.93714627 1.03140641] Bias: -0.8866214037542771 loss: 0.3383051445470533\n",
            "Round: 294 Weight: [1.93903427 1.03230589] Bias: -0.8873994170885929 loss: 0.3382550154052575\n",
            "Round: 295 Weight: [1.94091392 1.03320142] Bias: -0.8881734144301258 loss: 0.3382053383771098\n",
            "Round: 296 Weight: [1.94278525 1.03409302] Bias: -0.8889434263320153 loss: 0.33815610848495853\n",
            "Round: 297 Weight: [1.94464833 1.03498071] Bias: -0.889709483024884 loss: 0.3381073208183679\n",
            "Round: 298 Weight: [1.94650321 1.03586451] Bias: -0.8904716144211584 loss: 0.33805897053302214\n",
            "Round: 299 Weight: [1.94834993 1.03674446] Bias: -0.8912298501193218 loss: 0.3380110528496485\n",
            "Round: 300 Weight: [1.95018855 1.03762058] Bias: -0.891984219408097 loss: 0.33796356305296266\n",
            "Round: 301 Weight: [1.95201912 1.03849289] Bias: -0.8927347512705643 loss: 0.33791649649063393\n",
            "Round: 302 Weight: [1.95384169 1.03936141] Bias: -0.8934814743882121 loss: 0.33786984857226926\n",
            "Round: 303 Weight: [1.9556563  1.04022617] Bias: -0.8942244171449236 loss: 0.3378236147684185\n",
            "Round: 304 Weight: [1.95746301 1.04108719] Bias: -0.8949636076309003 loss: 0.3377777906095964\n",
            "Round: 305 Weight: [1.95926187 1.0419445 ] Bias: -0.8956990736465236 loss: 0.3377323716853251\n",
            "Round: 306 Weight: [1.96105292 1.04279812] Bias: -0.8964308427061546 loss: 0.33768735364319324\n",
            "Round: 307 Weight: [1.96283621 1.04364806] Bias: -0.8971589420418752 loss: 0.3376427321879336\n",
            "Round: 308 Weight: [1.96461179 1.04449436] Bias: -0.8978833986071696 loss: 0.33759850308051753\n",
            "Round: 309 Weight: [1.96637971 1.04533703] Bias: -0.8986042390805483 loss: 0.3375546621372671\n",
            "Round: 310 Weight: [1.96814001 1.0461761 ] Bias: -0.899321489869116 loss: 0.3375112052289826\n",
            "Round: 311 Weight: [1.96989274 1.04701159] Bias: -0.900035177112083 loss: 0.33746812828008765\n",
            "Round: 312 Weight: [1.97163794 1.04784352] Bias: -0.9007453266842231 loss: 0.33742542726778907\n",
            "Round: 313 Weight: [1.97337566 1.04867191] Bias: -0.9014519641992769 loss: 0.3373830982212528\n",
            "Round: 314 Weight: [1.97510595 1.04949679] Bias: -0.9021551150133029 loss: 0.33734113722079506\n",
            "Round: 315 Weight: [1.97682885 1.05031817] Bias: -0.9028548042279776 loss: 0.337299540397088\n",
            "Round: 316 Weight: [1.9785444  1.05113608] Bias: -0.9035510566938434 loss: 0.33725830393038025\n",
            "Round: 317 Weight: [1.98025265 1.05195054] Bias: -0.904243897013508 loss: 0.33721742404973165\n",
            "Round: 318 Weight: [1.98195363 1.05276156] Bias: -0.9049333495447944 loss: 0.337176897032262\n",
            "Round: 319 Weight: [1.98364741 1.05356917] Bias: -0.9056194384038424 loss: 0.337136719202413\n",
            "Round: 320 Weight: [1.98533401 1.05437338] Bias: -0.9063021874681634 loss: 0.33709688693122414\n",
            "Round: 321 Weight: [1.98701348 1.05517423] Bias: -0.9069816203796488 loss: 0.3370573966356216\n",
            "Round: 322 Weight: [1.98868586 1.05597172] Bias: -0.9076577605475327 loss: 0.3370182447777193\n",
            "Round: 323 Weight: [1.99035119 1.05676588] Bias: -0.9083306311513095 loss: 0.3369794278641335\n",
            "Round: 324 Weight: [1.99200952 1.05755673] Bias: -0.9090002551436085 loss: 0.3369409424453091\n",
            "Round: 325 Weight: [1.99366089 1.05834429] Bias: -0.909666655253024 loss: 0.3369027851148576\n",
            "Round: 326 Weight: [1.99530533 1.05912857] Bias: -0.9103298539869042 loss: 0.3368649525089078\n",
            "Round: 327 Weight: [1.99694289 1.05990959] Bias: -0.9109898736340978 loss: 0.3368274413054675\n",
            "Round: 328 Weight: [1.9985736  1.06068738] Bias: -0.911646736267659 loss: 0.3367902482237962\n",
            "Round: 329 Weight: [2.00019751 1.06146195] Bias: -0.9123004637475138 loss: 0.3367533700237895\n",
            "Round: 330 Weight: [2.00181465 1.06223333] Bias: -0.9129510777230855 loss: 0.3367168035053739\n",
            "Round: 331 Weight: [2.00342507 1.06300152] Bias: -0.9135985996358813 loss: 0.3366805455079125\n",
            "Round: 332 Weight: [2.00502881 1.06376655] Bias: -0.9142430507220415 loss: 0.3366445929096209\n",
            "Round: 333 Weight: [2.00662589 1.06452843] Bias: -0.9148844520148505 loss: 0.3366089426269933\n",
            "Round: 334 Weight: [2.00821636 1.06528719] Bias: -0.9155228243472111 loss: 0.336573591614239\n",
            "Round: 335 Weight: [2.00980026 1.06604285] Bias: -0.9161581883540826 loss: 0.336538536862728\n",
            "Round: 336 Weight: [2.01137763 1.06679541] Bias: -0.9167905644748829 loss: 0.3365037754004468\n",
            "Round: 337 Weight: [2.0129485 1.0675449] Bias: -0.9174199729558562 loss: 0.33646930429146316\n",
            "Round: 338 Weight: [2.01451291 1.06829133] Bias: -0.9180464338524051 loss: 0.3364351206354006\n",
            "Round: 339 Weight: [2.01607089 1.06903472] Bias: -0.9186699670313904 loss: 0.33640122156692126\n",
            "Round: 340 Weight: [2.01762248 1.0697751 ] Bias: -0.919290592173396 loss: 0.3363676042552181\n",
            "Round: 341 Weight: [2.01916773 1.07051247] Bias: -0.9199083287749626 loss: 0.33633426590351595\n",
            "Round: 342 Weight: [2.02070665 1.07124685] Bias: -0.9205231961507877 loss: 0.33630120374858025\n",
            "Round: 343 Weight: [2.0222393  1.07197826] Bias: -0.9211352134358949 loss: 0.3362684150602349\n",
            "Round: 344 Weight: [2.02376569 1.07270672] Bias: -0.921744399587772 loss: 0.3362358971408881\n",
            "Round: 345 Weight: [2.02528588 1.07343224] Bias: -0.9223507733884783 loss: 0.3362036473250658\n",
            "Round: 346 Weight: [2.02679989 1.07415483] Bias: -0.9229543534467216 loss: 0.336171662978954\n",
            "Round: 347 Weight: [2.02830776 1.07487453] Bias: -0.9235551581999063 loss: 0.3361399414999471\n",
            "Round: 348 Weight: [2.02980952 1.07559133] Bias: -0.9241532059161516 loss: 0.33610848031620594\n",
            "Round: 349 Weight: [2.03130521 1.07630526] Bias: -0.9247485146962815 loss: 0.3360772768862211\n",
            "Round: 350 Weight: [2.03279486 1.07701633] Bias: -0.9253411024757867 loss: 0.3360463286983851\n",
            "Round: 351 Weight: [2.03427849 1.07772456] Bias: -0.9259309870267588 loss: 0.3360156332705707\n",
            "Round: 352 Weight: [2.03575616 1.07842997] Bias: -0.926518185959797 loss: 0.33598518814971706\n",
            "Round: 353 Weight: [2.03722788 1.07913256] Bias: -0.927102716725888 loss: 0.33595499091142195\n",
            "Round: 354 Weight: [2.03869369 1.07983236] Bias: -0.9276845966182603 loss: 0.3359250391595411\n",
            "Round: 355 Weight: [2.04015363 1.08052938] Bias: -0.9282638427742118 loss: 0.33589533052579373\n",
            "Round: 356 Weight: [2.04160772 1.08122363] Bias: -0.9288404721769118 loss: 0.3358658626693758\n",
            "Round: 357 Weight: [2.043056   1.08191514] Bias: -0.9294145016571785 loss: 0.33583663327657753\n",
            "Round: 358 Weight: [2.0444985 1.0826039] Bias: -0.929985947895232 loss: 0.33580764006040936\n",
            "Round: 359 Weight: [2.04593525 1.08328995] Bias: -0.9305548274224219 loss: 0.33577888076023205\n",
            "Round: 360 Weight: [2.04736627 1.08397329] Bias: -0.931121156622932 loss: 0.3357503531413945\n",
            "Round: 361 Weight: [2.04879161 1.08465394] Bias: -0.9316849517354615 loss: 0.3357220549948762\n",
            "Round: 362 Weight: [2.0502113  1.08533191] Bias: -0.9322462288548823 loss: 0.335693984136936\n",
            "Round: 363 Weight: [2.05162535 1.08600722] Bias: -0.9328050039338743 loss: 0.3356661384087665\n",
            "Round: 364 Weight: [2.05303381 1.08667988] Bias: -0.9333612927845383 loss: 0.33563851567615366\n",
            "Round: 365 Weight: [2.0544367 1.0873499] Bias: -0.9339151110799859 loss: 0.3356111138291427\n",
            "Round: 366 Weight: [2.05583405 1.08801731] Bias: -0.9344664743559092 loss: 0.33558393078170856\n",
            "Round: 367 Weight: [2.05722589 1.0886821 ] Bias: -0.9350153980121279 loss: 0.33555696447143146\n",
            "Round: 368 Weight: [2.05861226 1.08934431] Bias: -0.9355618973141159 loss: 0.33553021285917867\n",
            "Round: 369 Weight: [2.05999317 1.09000393] Bias: -0.9361059873945075 loss: 0.3355036739287904\n",
            "Round: 370 Weight: [2.06136867 1.09066099] Bias: -0.9366476832545827 loss: 0.3354773456867708\n",
            "Round: 371 Weight: [2.06273877 1.0913155 ] Bias: -0.9371869997657329 loss: 0.33545122616198453\n",
            "Round: 372 Weight: [2.06410351 1.09196747] Bias: -0.9377239516709066 loss: 0.33542531340535686\n",
            "Round: 373 Weight: [2.06546291 1.09261691] Bias: -0.9382585535860357 loss: 0.3353996054895798\n",
            "Round: 374 Weight: [2.066817   1.09326384] Bias: -0.9387908200014432 loss: 0.33537410050882216\n",
            "Round: 375 Weight: [2.06816582 1.09390827] Bias: -0.9393207652832315 loss: 0.33534879657844396\n",
            "Round: 376 Weight: [2.06950938 1.09455021] Bias: -0.9398484036746522 loss: 0.33532369183471594\n",
            "Round: 377 Weight: [2.07084772 1.09518968] Bias: -0.9403737492974581 loss: 0.33529878443454264\n",
            "Round: 378 Weight: [2.07218085 1.09582668] Bias: -0.9408968161532373 loss: 0.3352740725551908\n",
            "Round: 379 Weight: [2.07350882 1.09646124] Bias: -0.9414176181247287 loss: 0.335249554394021\n",
            "Round: 380 Weight: [2.07483165 1.09709337] Bias: -0.9419361689771214 loss: 0.33522522816822364\n",
            "Round: 381 Weight: [2.07614935 1.09772307] Bias: -0.942452482359336 loss: 0.33520109211456\n",
            "Round: 382 Weight: [2.07746197 1.09835035] Bias: -0.9429665718052894 loss: 0.33517714448910535\n",
            "Round: 383 Weight: [2.07876952 1.09897525] Bias: -0.9434784507351432 loss: 0.3351533835669981\n",
            "Round: 384 Weight: [2.08007203 1.09959775] Bias: -0.9439881324565356 loss: 0.3351298076421914\n",
            "Round: 385 Weight: [2.08136953 1.10021788] Bias: -0.9444956301657963 loss: 0.3351064150272089\n",
            "Round: 386 Weight: [2.08266204 1.10083565] Bias: -0.9450009569491477 loss: 0.33508320405290437\n",
            "Round: 387 Weight: [2.08394959 1.10145106] Bias: -0.945504125783888 loss: 0.33506017306822483\n",
            "Round: 388 Weight: [2.0852322  1.10206414] Bias: -0.9460051495395607 loss: 0.33503732043997747\n",
            "Round: 389 Weight: [2.0865099 1.1026749] Bias: -0.9465040409791081 loss: 0.3350146445525999\n",
            "Round: 390 Weight: [2.08778272 1.10328333] Bias: -0.9470008127600101 loss: 0.3349921438079337\n",
            "Round: 391 Weight: [2.08905067 1.10388947] Bias: -0.9474954774354084 loss: 0.33496981662500197\n",
            "Round: 392 Weight: [2.09031379 1.10449331] Bias: -0.947988047455216 loss: 0.3349476614397895\n",
            "Round: 393 Weight: [2.09157209 1.10509487] Bias: -0.9484785351672128 loss: 0.33492567670502693\n",
            "Round: 394 Weight: [2.09282561 1.10569417] Bias: -0.9489669528181267 loss: 0.3349038608899775\n",
            "Round: 395 Weight: [2.09407436 1.1062912 ] Bias: -0.9494533125547011 loss: 0.33488221248022737\n",
            "Round: 396 Weight: [2.09531837 1.10688599] Bias: -0.949937626424749 loss: 0.33486072997747907\n",
            "Round: 397 Weight: [2.09655767 1.10747855] Bias: -0.9504199063781931 loss: 0.3348394118993478\n",
            "Round: 398 Weight: [2.09779227 1.10806888] Bias: -0.9509001642680933 loss: 0.33481825677916077\n",
            "Round: 399 Weight: [2.0990222 1.108657 ] Bias: -0.9513784118516607 loss: 0.33479726316576\n",
            "Round: 400 Weight: [2.10024749 1.10924291] Bias: -0.9518546607912591 loss: 0.3347764296233069\n",
            "Round: 401 Weight: [2.10146815 1.10982664] Bias: -0.9523289226553935 loss: 0.3347557547310914\n",
            "Round: 402 Weight: [2.10268421 1.11040818] Bias: -0.9528012089196862 loss: 0.33473523708334196\n",
            "Round: 403 Weight: [2.1038957  1.11098756] Bias: -0.9532715309678412 loss: 0.3347148752890401\n",
            "Round: 404 Weight: [2.10510263 1.11156478] Bias: -0.9537399000925957 loss: 0.3346946679717364\n",
            "Round: 405 Weight: [2.10630503 1.11213984] Bias: -0.95420632749666 loss: 0.33467461376936986\n",
            "Round: 406 Weight: [2.10750292 1.11271277] Bias: -0.9546708242936458 loss: 0.3346547113340895\n",
            "Round: 407 Weight: [2.10869632 1.11328357] Bias: -0.9551334015089825 loss: 0.33463495933207915\n",
            "Round: 408 Weight: [2.10988526 1.11385226] Bias: -0.9555940700808229 loss: 0.3346153564433838\n",
            "Round: 409 Weight: [2.11106975 1.11441884] Bias: -0.9560528408609364 loss: 0.33459590136173956\n",
            "Round: 410 Weight: [2.11224982 1.11498332] Bias: -0.9565097246155926 loss: 0.3345765927944048\n",
            "Round: 411 Weight: [2.11342549 1.11554571] Bias: -0.9569647320264324 loss: 0.33455742946199546\n",
            "Round: 412 Weight: [2.11459678 1.11610603] Bias: -0.9574178736913299 loss: 0.3345384100983206\n",
            "Round: 413 Weight: [2.11576372 1.11666428] Bias: -0.9578691601252424 loss: 0.33451953345022245\n",
            "Round: 414 Weight: [2.11692631 1.11722047] Bias: -0.9583186017610504 loss: 0.3345007982774169\n",
            "Round: 415 Weight: [2.1180846  1.11777462] Bias: -0.9587662089503881 loss: 0.33448220335233764\n",
            "Round: 416 Weight: [2.11923858 1.11832673] Bias: -0.959211991964462 loss: 0.33446374745998136\n",
            "Round: 417 Weight: [2.1203883  1.11887681] Bias: -0.9596559609948613 loss: 0.33444542939775634\n",
            "Round: 418 Weight: [2.12153376 1.11942488] Bias: -0.9600981261543569 loss: 0.3344272479753323\n",
            "Round: 419 Weight: [2.12267499 1.11997094] Bias: -0.9605384974776919 loss: 0.33440920201449265\n",
            "Round: 420 Weight: [2.123812 1.120515] Bias: -0.9609770849223618 loss: 0.33439129034898873\n",
            "Round: 421 Weight: [2.12494483 1.12105707] Bias: -0.9614138983693852 loss: 0.3343735118243964\n",
            "Round: 422 Weight: [2.12607348 1.12159716] Bias: -0.9618489476240655 loss: 0.33435586529797445\n",
            "Round: 423 Weight: [2.12719798 1.12213528] Bias: -0.9622822424167434 loss: 0.3343383496385246\n",
            "Round: 424 Weight: [2.12831835 1.12267144] Bias: -0.9627137924035403 loss: 0.33432096372625447\n",
            "Round: 425 Weight: [2.12943461 1.12320565] Bias: -0.9631436071670919 loss: 0.33430370645264124\n",
            "Round: 426 Weight: [2.13054677 1.12373791] Bias: -0.9635716962172748 loss: 0.33428657672029816\n",
            "Round: 427 Weight: [2.13165486 1.12426825] Bias: -0.9639980689919226 loss: 0.3342695734428424\n",
            "Round: 428 Weight: [2.1327589  1.12479666] Bias: -0.9644227348575347 loss: 0.33425269554476483\n",
            "Round: 429 Weight: [2.1338589  1.12532315] Bias: -0.9648457031099755 loss: 0.33423594196130174\n",
            "Round: 430 Weight: [2.13495488 1.12584774] Bias: -0.9652669829751666 loss: 0.3342193116383083\n",
            "Round: 431 Weight: [2.13604687 1.12637043] Bias: -0.9656865836097694 loss: 0.3342028035321339\n",
            "Round: 432 Weight: [2.13713488 1.12689123] Bias: -0.9661045141018612 loss: 0.33418641660949827\n",
            "Round: 433 Weight: [2.13821893 1.12741015] Bias: -0.9665207834716012 loss: 0.3341701498473708\n",
            "Round: 434 Weight: [2.13929905 1.1279272 ] Bias: -0.9669354006718907 loss: 0.33415400223285047\n",
            "Round: 435 Weight: [2.14037523 1.12844239] Bias: -0.9673483745890242 loss: 0.33413797276304763\n",
            "Round: 436 Weight: [2.14144752 1.12895573] Bias: -0.9677597140433337 loss: 0.3341220604449675\n",
            "Round: 437 Weight: [2.14251592 1.12946722] Bias: -0.9681694277898243 loss: 0.33410626429539536\n",
            "Round: 438 Weight: [2.14358045 1.12997687] Bias: -0.9685775245188034 loss: 0.33409058334078284\n",
            "Round: 439 Weight: [2.14464113 1.13048469] Bias: -0.9689840128565025 loss: 0.33407501661713657\n",
            "Round: 440 Weight: [2.14569798 1.1309907 ] Bias: -0.9693889013656909 loss: 0.3340595631699071\n",
            "Round: 441 Weight: [2.14675102 1.13149489] Bias: -0.969792198546283 loss: 0.3340442220538808\n",
            "Round: 442 Weight: [2.14780025 1.13199728] Bias: -0.9701939128359381 loss: 0.3340289923330718\n",
            "Round: 443 Weight: [2.14884572 1.13249788] Bias: -0.970594052610654 loss: 0.3340138730806167\n",
            "Round: 444 Weight: [2.14988742 1.13299669] Bias: -0.9709926261853525 loss: 0.33399886337866924\n",
            "Round: 445 Weight: [2.15092537 1.13349372] Bias: -0.9713896418144591 loss: 0.3339839623182979\n",
            "Round: 446 Weight: [2.1519596  1.13398898] Bias: -0.9717851076924756 loss: 0.3339691689993837\n",
            "Round: 447 Weight: [2.15299012 1.13448248] Bias: -0.9721790319545464 loss: 0.3339544825305202\n",
            "Round: 448 Weight: [2.15401695 1.13497422] Bias: -0.9725714226770177 loss: 0.33393990202891344\n",
            "Round: 449 Weight: [2.1550401  1.13546422] Bias: -0.9729622878779912 loss: 0.33392542662028585\n",
            "Round: 450 Weight: [2.15605959 1.13595248] Bias: -0.9733516355178706 loss: 0.3339110554387781\n",
            "Round: 451 Weight: [2.15707545 1.13643901] Bias: -0.9737394734999021 loss: 0.333896787626855\n",
            "Round: 452 Weight: [2.15808767 1.13692381] Bias: -0.974125809670709 loss: 0.333882622335211\n",
            "Round: 453 Weight: [2.15909629 1.1374069 ] Bias: -0.9745106518208203 loss: 0.3338685587226779\n",
            "Round: 454 Weight: [2.16010131 1.13788828] Bias: -0.9748940076851923 loss: 0.333854595956133\n",
            "Round: 455 Weight: [2.16110276 1.13836797] Bias: -0.9752758849437255 loss: 0.3338407332104091\n",
            "Round: 456 Weight: [2.16210065 1.13884596] Bias: -0.9756562912217754 loss: 0.333826969668205\n",
            "Round: 457 Weight: [2.16309499 1.13932226] Bias: -0.9760352340906567 loss: 0.3338133045199984\n",
            "Round: 458 Weight: [2.16408581 1.13979689] Bias: -0.9764127210681428 loss: 0.33379973696395787\n",
            "Round: 459 Weight: [2.16507311 1.14026985] Bias: -0.976788759618959 loss: 0.3337862662058585\n",
            "Round: 460 Weight: [2.16605692 1.14074115] Bias: -0.9771633571552706 loss: 0.33377289145899625\n",
            "Round: 461 Weight: [2.16703725 1.14121079] Bias: -0.9775365210371654 loss: 0.33375961194410514\n",
            "Round: 462 Weight: [2.16801411 1.14167878] Bias: -0.9779082585731307 loss: 0.3337464268892747\n",
            "Round: 463 Weight: [2.16898753 1.14214514] Bias: -0.978278577020525 loss: 0.33373333552986845\n",
            "Round: 464 Weight: [2.16995751 1.14260986] Bias: -0.9786474835860445 loss: 0.3337203371084442\n",
            "Round: 465 Weight: [2.17092407 1.14307295] Bias: -0.9790149854261841 loss: 0.3337074308746739\n",
            "Round: 466 Weight: [2.17188722 1.14353443] Bias: -0.9793810896476942 loss: 0.3336946160852665\n",
            "Round: 467 Weight: [2.17284699 1.1439943 ] Bias: -0.9797458033080311 loss: 0.33368189200388965\n",
            "Round: 468 Weight: [2.17380339 1.14445256] Bias: -0.9801091334158035 loss: 0.3336692579010943\n",
            "Round: 469 Weight: [2.17475643 1.14490922] Bias: -0.9804710869312135 loss: 0.33365671305423916\n",
            "Round: 470 Weight: [2.17570613 1.1453643 ] Bias: -0.9808316707664931 loss: 0.33364425674741616\n",
            "Round: 471 Weight: [2.17665249 1.14581779] Bias: -0.9811908917863355 loss: 0.3336318882713772\n",
            "Round: 472 Weight: [2.17759555 1.1462697 ] Bias: -0.9815487568083217 loss: 0.3336196069234623\n",
            "Round: 473 Weight: [2.1785353  1.14672004] Bias: -0.9819052726033431 loss: 0.33360741200752697\n",
            "Round: 474 Weight: [2.17947177 1.14716883] Bias: -0.9822604458960187 loss: 0.3335953028338727\n",
            "Round: 475 Weight: [2.18040497 1.14761605] Bias: -0.9826142833651077 loss: 0.3335832787191763\n",
            "Round: 476 Weight: [2.18133492 1.14806173] Bias: -0.9829667916439183 loss: 0.3335713389864221\n",
            "Round: 477 Weight: [2.18226162 1.14850586] Bias: -0.9833179773207117 loss: 0.33355948296483273\n",
            "Round: 478 Weight: [2.18318509 1.14894846] Bias: -0.9836678469391011 loss: 0.33354770998980293\n",
            "Round: 479 Weight: [2.18410536 1.14938953] Bias: -0.9840164069984477 loss: 0.3335360194028331\n",
            "Round: 480 Weight: [2.18502242 1.14982908] Bias: -0.9843636639542511 loss: 0.33352441055146353\n",
            "Round: 481 Weight: [2.1859363  1.15026711] Bias: -0.9847096242185361 loss: 0.3335128827892099\n",
            "Round: 482 Weight: [2.18684701 1.15070363] Bias: -0.9850542941602356 loss: 0.3335014354754996\n",
            "Round: 483 Weight: [2.18775456 1.15113865] Bias: -0.9853976801055686 loss: 0.33349006797560815\n",
            "Round: 484 Weight: [2.18865896 1.15157217] Bias: -0.9857397883384148 loss: 0.33347877966059797\n",
            "Round: 485 Weight: [2.18956024 1.15200421] Bias: -0.986080625100685 loss: 0.33346756990725573\n",
            "Round: 486 Weight: [2.1904584  1.15243475] Bias: -0.9864201965926873 loss: 0.3334564380980323\n",
            "Round: 487 Weight: [2.19135346 1.15286383] Bias: -0.9867585089734899 loss: 0.3334453836209826\n",
            "Round: 488 Weight: [2.19224543 1.15329143] Bias: -0.9870955683612793 loss: 0.33343440586970613\n",
            "Round: 489 Weight: [2.19313432 1.15371756] Bias: -0.9874313808337154 loss: 0.33342350424328887\n",
            "Round: 490 Weight: [2.19402015 1.15414224] Bias: -0.9877659524282824 loss: 0.33341267814624503\n",
            "Round: 491 Weight: [2.19490293 1.15456546] Bias: -0.9880992891426359 loss: 0.3334019269884602\n",
            "Round: 492 Weight: [2.19578267 1.15498724] Bias: -0.9884313969349471 loss: 0.33339125018513516\n",
            "Round: 493 Weight: [2.19665939 1.15540758] Bias: -0.9887622817242422 loss: 0.3333806471567295\n",
            "Round: 494 Weight: [2.1975331  1.15582649] Bias: -0.9890919493907391 loss: 0.33337011732890726\n",
            "Round: 495 Weight: [2.19840381 1.15624396] Bias: -0.9894204057761801 loss: 0.3333596601324821\n",
            "Round: 496 Weight: [2.19927153 1.15666002] Bias: -0.9897476566841613 loss: 0.3333492750033638\n",
            "Round: 497 Weight: [2.20013629 1.15707466] Bias: -0.9900737078804587 loss: 0.3333389613825054\n",
            "Round: 498 Weight: [2.20099808 1.15748789] Bias: -0.9903985650933502 loss: 0.33332871871585024\n",
            "Round: 499 Weight: [2.20185693 1.15789971] Bias: -0.9907222340139354 loss: 0.3333185464542806\n",
            "Round: 500 Weight: [2.20271284 1.15831014] Bias: -0.9910447202964507 loss: 0.3333084440535664\n",
            "Round: 501 Weight: [2.20356583 1.15871918] Bias: -0.9913660295585823 loss: 0.3332984109743146\n",
            "Round: 502 Weight: [2.20441591 1.15912683] Bias: -0.9916861673817751 loss: 0.3332884466819195\n",
            "Round: 503 Weight: [2.20526309 1.1595331 ] Bias: -0.9920051393115388 loss: 0.3332785506465129\n",
            "Round: 504 Weight: [2.20610739 1.15993799] Bias: -0.992322950857751 loss: 0.33326872234291594\n",
            "Round: 505 Weight: [2.20694882 1.16034151] Bias: -0.9926396074949568 loss: 0.3332589612505903\n",
            "Round: 506 Weight: [2.20778738 1.16074368] Bias: -0.9929551146626653 loss: 0.3332492668535913\n",
            "Round: 507 Weight: [2.2086231  1.16114448] Bias: -0.993269477765643 loss: 0.3332396386405202\n",
            "Round: 508 Weight: [2.20945598 1.16154393] Bias: -0.993582702174205 loss: 0.33323007610447813\n",
            "Round: 509 Weight: [2.21028603 1.16194204] Bias: -0.9938947932245019 loss: 0.33322057874301986\n",
            "Round: 510 Weight: [2.21111327 1.1623388 ] Bias: -0.9942057562188048 loss: 0.3332111460581089\n",
            "Round: 511 Weight: [2.21193771 1.16273423] Bias: -0.9945155964257869 loss: 0.33320177755607217\n",
            "Round: 512 Weight: [2.21275936 1.16312833] Bias: -0.9948243190808024 loss: 0.3331924727475556\n",
            "Round: 513 Weight: [2.21357824 1.16352111] Bias: -0.9951319293861621 loss: 0.333183231147481\n",
            "Round: 514 Weight: [2.21439434 1.16391257] Bias: -0.9954384325114073 loss: 0.3331740522750022\n",
            "Round: 515 Weight: [2.21520769 1.16430271] Bias: -0.9957438335935793 loss: 0.3331649356534621\n",
            "Round: 516 Weight: [2.2160183  1.16469154] Bias: -0.9960481377374879 loss: 0.33315588081035125\n",
            "Round: 517 Weight: [2.21682618 1.16507908] Bias: -0.9963513500159759 loss: 0.3331468872772651\n",
            "Round: 518 Weight: [2.21763133 1.16546531] Bias: -0.9966534754701811 loss: 0.3331379545898632\n",
            "Round: 519 Weight: [2.21843378 1.16585026] Bias: -0.9969545191097968 loss: 0.3331290822878285\n",
            "Round: 520 Weight: [2.21923353 1.16623392] Bias: -0.9972544859133278 loss: 0.3331202699148266\n",
            "Round: 521 Weight: [2.22003059 1.16661629] Bias: -0.9975533808283453 loss: 0.33311151701846614\n",
            "Round: 522 Weight: [2.22082498 1.16699739] Bias: -0.997851208771739 loss: 0.33310282315025913\n",
            "Round: 523 Weight: [2.2216167  1.16737722] Bias: -0.998147974629966 loss: 0.3330941878655827\n",
            "Round: 524 Weight: [2.22240577 1.16775578] Bias: -0.9984436832592976 loss: 0.3330856107236396\n",
            "Round: 525 Weight: [2.22319219 1.16813309] Bias: -0.998738339486064 loss: 0.33307709128742075\n",
            "Round: 526 Weight: [2.22397598 1.16850913] Bias: -0.9990319481068964 loss: 0.33306862912366747\n",
            "Round: 527 Weight: [2.22475715 1.16888393] Bias: -0.9993245138889659 loss: 0.33306022380283445\n",
            "Round: 528 Weight: [2.22553571 1.16925748] Bias: -0.9996160415702212 loss: 0.3330518748990525\n",
            "Round: 529 Weight: [2.22631167 1.16962979] Bias: -0.9999065358596231 loss: 0.33304358199009293\n",
            "Round: 530 Weight: [2.22708505 1.17000087] Bias: -1.0001960014373772 loss: 0.33303534465733053\n",
            "Round: 531 Weight: [2.22785584 1.17037071] Bias: -1.0004844429551638 loss: 0.3330271624857095\n",
            "Round: 532 Weight: [2.22862406 1.17073933] Bias: -1.0007718650363662 loss: 0.333019035063707\n",
            "Round: 533 Weight: [2.22938973 1.17110673] Bias: -1.0010582722762957 loss: 0.3330109619832993\n",
            "Round: 534 Weight: [2.23015285 1.17147292] Bias: -1.001343669242416 loss: 0.3330029428399269\n",
            "Round: 535 Weight: [2.23091343 1.17183789] Bias: -1.0016280604745638 loss: 0.332994977232461\n",
            "Round: 536 Weight: [2.23167149 1.17220166] Bias: -1.0019114504851676 loss: 0.3329870647631696\n",
            "Round: 537 Weight: [2.23242703 1.17256423] Bias: -1.0021938437594655 loss: 0.3329792050376844\n",
            "Round: 538 Weight: [2.23318006 1.1729256 ] Bias: -1.0024752447557195 loss: 0.3329713976649685\n",
            "Round: 539 Weight: [2.2339306  1.17328578] Bias: -1.0027556579054282 loss: 0.33296364225728314\n",
            "Round: 540 Weight: [2.23467865 1.17364477] Bias: -1.0030350876135377 loss: 0.33295593843015636\n",
            "Round: 541 Weight: [2.23542423 1.17400258] Bias: -1.0033135382586498 loss: 0.3329482858023507\n",
            "Round: 542 Weight: [2.23616734 1.17435921] Bias: -1.0035910141932292 loss: 0.3329406839958322\n",
            "Round: 543 Weight: [2.23690799 1.17471468] Bias: -1.0038675197438074 loss: 0.3329331326357394\n",
            "Round: 544 Weight: [2.2376462  1.17506897] Bias: -1.004143059211186 loss: 0.33292563135035264\n",
            "Round: 545 Weight: [2.23838197 1.1754221 ] Bias: -1.0044176368706368 loss: 0.33291817977106347\n",
            "Round: 546 Weight: [2.23911531 1.17577407] Bias: -1.0046912569721007 loss: 0.33291077753234505\n",
            "Round: 547 Weight: [2.23984624 1.17612489] Bias: -1.0049639237403847 loss: 0.3329034242717225\n",
            "Round: 548 Weight: [2.24057476 1.17647456] Bias: -1.0052356413753565 loss: 0.3328961196297431\n",
            "Round: 549 Weight: [2.24130088 1.17682308] Bias: -1.005506414052138 loss: 0.3328888632499481\n",
            "Round: 550 Weight: [2.24202462 1.17717047] Bias: -1.0057762459212958 loss: 0.3328816547788431\n",
            "Round: 551 Weight: [2.24274597 1.17751671] Bias: -1.0060451411090312 loss: 0.33287449386587054\n",
            "Round: 552 Weight: [2.24346496 1.17786183] Bias: -1.0063131037173678 loss: 0.3328673801633811\n",
            "Round: 553 Weight: [2.24418158 1.17820582] Bias: -1.0065801378243369 loss: 0.3328603133266062\n",
            "Round: 554 Weight: [2.24489586 1.17854869] Bias: -1.0068462474841617 loss: 0.3328532930136306\n",
            "Round: 555 Weight: [2.2456078  1.17889044] Bias: -1.0071114367274396 loss: 0.33284631888536503\n",
            "Round: 556 Weight: [2.2463174  1.17923107] Bias: -1.0073757095613225 loss: 0.33283939060551987\n",
            "Round: 557 Weight: [2.24702468 1.1795706 ] Bias: -1.0076390699696962 loss: 0.3328325078405779\n",
            "Round: 558 Weight: [2.24772965 1.17990902] Bias: -1.0079015219133574 loss: 0.33282567025976867\n",
            "Round: 559 Weight: [2.24843231 1.18024634] Bias: -1.0081630693301884 loss: 0.33281887753504197\n",
            "Round: 560 Weight: [2.24913268 1.18058256] Bias: -1.008423716135332 loss: 0.3328121293410429\n",
            "Round: 561 Weight: [2.24983076 1.1809177 ] Bias: -1.0086834662213633 loss: 0.3328054253550856\n",
            "Round: 562 Weight: [2.25052657 1.18125174] Bias: -1.00894232345846 loss: 0.33279876525712915\n",
            "Round: 563 Weight: [2.25122011 1.1815847 ] Bias: -1.009200291694572 loss: 0.3327921487297512\n",
            "Round: 564 Weight: [2.25191139 1.18191658] Bias: -1.009457374755588 loss: 0.33278557545812515\n",
            "Round: 565 Weight: [2.25260041 1.18224739] Bias: -1.009713576445502 loss: 0.3327790451299946\n",
            "Round: 566 Weight: [2.2532872  1.18257712] Bias: -1.009968900546578 loss: 0.33277255743564976\n",
            "Round: 567 Weight: [2.25397175 1.18290579] Bias: -1.010223350819511 loss: 0.33276611206790335\n",
            "Round: 568 Weight: [2.25465408 1.1832334 ] Bias: -1.0104769310035908 loss: 0.3327597087220677\n",
            "Round: 569 Weight: [2.2553342  1.18355994] Bias: -1.0107296448168597 loss: 0.33275334709593046\n",
            "Round: 570 Weight: [2.25601211 1.18388543] Bias: -1.0109814959562715 loss: 0.3327470268897327\n",
            "Round: 571 Weight: [2.25668781 1.18420988] Bias: -1.011232488097849 loss: 0.3327407478061451\n",
            "Round: 572 Weight: [2.25736133 1.18453327] Bias: -1.011482624896838 loss: 0.332734509550246\n",
            "Round: 573 Weight: [2.25803267 1.18485562] Bias: -1.0117319099878628 loss: 0.33272831182949897\n",
            "Round: 574 Weight: [2.25870184 1.18517694] Bias: -1.0119803469850774 loss: 0.33272215435373054\n",
            "Round: 575 Weight: [2.25936884 1.18549722] Bias: -1.0122279394823175 loss: 0.33271603683510864\n",
            "Round: 576 Weight: [2.26003369 1.18581647] Bias: -1.0124746910532498 loss: 0.3327099589881207\n",
            "Round: 577 Weight: [2.26069639 1.18613469] Bias: -1.012720605251521 loss: 0.3327039205295526\n",
            "Round: 578 Weight: [2.26135695 1.18645189] Bias: -1.012965685610904 loss: 0.33269792117846736\n",
            "Round: 579 Weight: [2.26201538 1.18676807] Bias: -1.013209935645444 loss: 0.33269196065618395\n",
            "Round: 580 Weight: [2.26267168 1.18708324] Bias: -1.0134533588496035 loss: 0.3326860386862569\n",
            "Round: 581 Weight: [2.26332587 1.18739739] Bias: -1.013695958698404 loss: 0.33268015499445597\n",
            "Round: 582 Weight: [2.26397796 1.18771054] Bias: -1.013937738647569 loss: 0.33267430930874536\n",
            "Round: 583 Weight: [2.26462795 1.18802269] Bias: -1.0141787021336637 loss: 0.33266850135926396\n",
            "Round: 584 Weight: [2.26527584 1.18833383] Bias: -1.0144188525742348 loss: 0.3326627308783056\n",
            "Round: 585 Weight: [2.26592166 1.18864399] Bias: -1.014658193367948 loss: 0.33265699760029915\n",
            "Round: 586 Weight: [2.2665654  1.18895314] Bias: -1.0148967278947245 loss: 0.33265130126178916\n",
            "Round: 587 Weight: [2.26720707 1.18926131] Bias: -1.0151344595158776 loss: 0.3326456416014169\n",
            "Round: 588 Weight: [2.26784669 1.1895685 ] Bias: -1.0153713915742457 loss: 0.33264001835990076\n",
            "Round: 589 Weight: [2.26848425 1.18987471] Bias: -1.0156075273943261 loss: 0.33263443128001785\n",
            "Round: 590 Weight: [2.26911978 1.19017994] Bias: -1.0158428702824065 loss: 0.3326288801065853\n",
            "Round: 591 Weight: [2.26975326 1.19048419] Bias: -1.0160774235266958 loss: 0.33262336458644187\n",
            "Round: 592 Weight: [2.27038472 1.19078748] Bias: -1.016311190397454 loss: 0.33261788446842927\n",
            "Round: 593 Weight: [2.27101417 1.1910898 ] Bias: -1.0165441741471197 loss: 0.3326124395033746\n",
            "Round: 594 Weight: [2.2716416  1.19139116] Bias: -1.0167763780104382 loss: 0.33260702944407217\n",
            "Round: 595 Weight: [2.27226702 1.19169155] Bias: -1.0170078052045872 loss: 0.3326016540452659\n",
            "Round: 596 Weight: [2.27289045 1.191991  ] Bias: -1.017238458929302 loss: 0.332596313063632\n",
            "Round: 597 Weight: [2.27351189 1.19228949] Bias: -1.017468342366999 loss: 0.3325910062577612\n",
            "Round: 598 Weight: [2.27413135 1.19258704] Bias: -1.0176974586828986 loss: 0.3325857333881419\n",
            "Round: 599 Weight: [2.27474883 1.19288364] Bias: -1.0179258110251475 loss: 0.33258049421714314\n",
            "Round: 600 Weight: [2.27536435 1.1931793 ] Bias: -1.0181534025249384 loss: 0.33257528850899776\n",
            "Round: 601 Weight: [2.27597791 1.19347402] Bias: -1.0183802362966299 loss: 0.3325701160297857\n",
            "Round: 602 Weight: [2.27658952 1.19376781] Bias: -1.0186063154378655 loss: 0.3325649765474178\n",
            "Round: 603 Weight: [2.27719918 1.19406067] Bias: -1.0188316430296906 loss: 0.33255986983161906\n",
            "Round: 604 Weight: [2.27780691 1.1943526 ] Bias: -1.019056222136669 loss: 0.33255479565391305\n",
            "Round: 605 Weight: [2.27841271 1.19464361] Bias: -1.0192800558069985 loss: 0.3325497537876055\n",
            "Round: 606 Weight: [2.27901658 1.1949337 ] Bias: -1.019503147072625 loss: 0.33254474400776834\n",
            "Round: 607 Weight: [2.27961854 1.19522287] Bias: -1.019725498949356 loss: 0.3325397660912249\n",
            "Round: 608 Weight: [2.28021859 1.19551113] Bias: -1.0199471144369736 loss: 0.3325348198165336\n",
            "Round: 609 Weight: [2.28081674 1.19579848] Bias: -1.0201679965193455 loss: 0.332529904963973\n",
            "Round: 610 Weight: [2.281413   1.19608492] Bias: -1.0203881481645354 loss: 0.33252502131552647\n",
            "Round: 611 Weight: [2.28200737 1.19637046] Bias: -1.0206075723249126 loss: 0.33252016865486717\n",
            "Round: 612 Weight: [2.28259986 1.1966551 ] Bias: -1.020826271937261 loss: 0.3325153467673432\n",
            "Round: 613 Weight: [2.28319047 1.19693885] Bias: -1.021044249922886 loss: 0.3325105554399631\n",
            "Round: 614 Weight: [2.28377923 1.1972217 ] Bias: -1.0212615091877224 loss: 0.332505794461381\n",
            "Round: 615 Weight: [2.28436612 1.19750366] Bias: -1.0214780526224392 loss: 0.3325010636218822\n",
            "Round: 616 Weight: [2.28495116 1.19778474] Bias: -1.0216938831025448 loss: 0.33249636271336913\n",
            "Round: 617 Weight: [2.28553436 1.19806493] Bias: -1.021909003488491 loss: 0.3324916915293469\n",
            "Round: 618 Weight: [2.28611571 1.19834424] Bias: -1.0221234166257764 loss: 0.33248704986490946\n",
            "Round: 619 Weight: [2.28669524 1.19862267] Bias: -1.0223371253450482 loss: 0.3324824375167257\n",
            "Round: 620 Weight: [2.28727294 1.19890024] Bias: -1.022550132462204 loss: 0.3324778542830259\n",
            "Round: 621 Weight: [2.28784883 1.19917693] Bias: -1.0227624407784919 loss: 0.33247329996358777\n",
            "Round: 622 Weight: [2.2884229  1.19945275] Bias: -1.0229740530806104 loss: 0.3324687743597236\n",
            "Round: 623 Weight: [2.28899517 1.19972771] Bias: -1.0231849721408073 loss: 0.33246427727426603\n",
            "Round: 624 Weight: [2.28956564 1.20000181] Bias: -1.0233952007169775 loss: 0.3324598085115557\n",
            "Round: 625 Weight: [2.29013432 1.20027506] Bias: -1.02360474155276 loss: 0.33245536787742813\n",
            "Round: 626 Weight: [2.29070121 1.20054745] Bias: -1.0238135973776348 loss: 0.3324509551792001\n",
            "Round: 627 Weight: [2.29126633 1.20081898] Bias: -1.0240217709070174 loss: 0.33244657022565755\n",
            "Round: 628 Weight: [2.29182968 1.20108967] Bias: -1.0242292648423545 loss: 0.3324422128270427\n",
            "Round: 629 Weight: [2.29239126 1.20135951] Bias: -1.0244360818712177 loss: 0.33243788279504133\n",
            "Round: 630 Weight: [2.29295108 1.20162852] Bias: -1.024642224667396 loss: 0.33243357994277073\n",
            "Round: 631 Weight: [2.29350915 1.20189668] Bias: -1.024847695890989 loss: 0.3324293040847668\n",
            "Round: 632 Weight: [2.29406548 1.202164  ] Bias: -1.0250524981884974 loss: 0.3324250550369724\n",
            "Round: 633 Weight: [2.29462006 1.2024305 ] Bias: -1.0252566341929152 loss: 0.33242083261672534\n",
            "Round: 634 Weight: [2.29517292 1.20269616] Bias: -1.0254601065238185 loss: 0.3324166366427458\n",
            "Round: 635 Weight: [2.29572405 1.202961  ] Bias: -1.0256629177874554 loss: 0.33241246693512516\n",
            "Round: 636 Weight: [2.29627345 1.20322501] Bias: -1.0258650705768348 loss: 0.3324083233153141\n",
            "Round: 637 Weight: [2.29682115 1.2034882 ] Bias: -1.0260665674718135 loss: 0.33240420560611056\n",
            "Round: 638 Weight: [2.29736713 1.20375058] Bias: -1.0262674110391834 loss: 0.3324001136316492\n",
            "Round: 639 Weight: [2.29791141 1.20401214] Bias: -1.0264676038327587 loss: 0.33239604721738875\n",
            "Round: 640 Weight: [2.298454   1.20427288] Bias: -1.0266671483934604 loss: 0.3323920061901022\n",
            "Round: 641 Weight: [2.2989949  1.20453282] Bias: -1.0268660472494024 loss: 0.3323879903778642\n",
            "Round: 642 Weight: [2.29953412 1.20479195] Bias: -1.0270643029159747 loss: 0.332383999610041\n",
            "Round: 643 Weight: [2.30007166 1.20505028] Bias: -1.0272619178959277 loss: 0.3323800337172794\n",
            "Round: 644 Weight: [2.30060753 1.20530781] Bias: -1.0274588946794545 loss: 0.33237609253149547\n",
            "Round: 645 Weight: [2.30114173 1.20556454] Bias: -1.0276552357442736 loss: 0.3323721758858639\n",
            "Round: 646 Weight: [2.30167428 1.20582048] Bias: -1.0278509435557104 loss: 0.3323682836148079\n",
            "Round: 647 Weight: [2.30220517 1.20607562] Bias: -1.0280460205667776 loss: 0.3323644155539882\n",
            "Round: 648 Weight: [2.30273441 1.20632998] Bias: -1.0282404692182556 loss: 0.3323605715402924\n",
            "Round: 649 Weight: [2.30326202 1.20658355] Bias: -1.0284342919387721 loss: 0.3323567514118255\n",
            "Round: 650 Weight: [2.30378799 1.20683633] Bias: -1.0286274911448812 loss: 0.3323529550078989\n",
            "Round: 651 Weight: [2.30431233 1.20708834] Bias: -1.028820069241141 loss: 0.3323491821690203\n",
            "Round: 652 Weight: [2.30483505 1.20733956] Bias: -1.0290120286201923 loss: 0.33234543273688427\n",
            "Round: 653 Weight: [2.30535615 1.20759002] Bias: -1.0292033716628342 loss: 0.33234170655436157\n",
            "Round: 654 Weight: [2.30587564 1.2078397 ] Bias: -1.0293941007381018 loss: 0.3323380034654899\n",
            "Round: 655 Weight: [2.30639352 1.20808861] Bias: -1.029584218203341 loss: 0.33233432331546375\n",
            "Round: 656 Weight: [2.3069098  1.20833675] Bias: -1.0297737264042839 loss: 0.33233066595062505\n",
            "Round: 657 Weight: [2.30742449 1.20858413] Bias: -1.029962627675124 loss: 0.3323270312184533\n",
            "Round: 658 Weight: [2.30793759 1.20883075] Bias: -1.0301509243385887 loss: 0.33232341896755635\n",
            "Round: 659 Weight: [2.30844911 1.20907661] Bias: -1.0303386187060142 loss: 0.33231982904766094\n",
            "Round: 660 Weight: [2.30895905 1.20932171] Bias: -1.0305257130774172 loss: 0.3323162613096032\n",
            "Round: 661 Weight: [2.30946742 1.20956606] Bias: -1.0307122097415677 loss: 0.33231271560531966\n",
            "Round: 662 Weight: [2.30997422 1.20980966] Bias: -1.03089811097606 loss: 0.3323091917878383\n",
            "Round: 663 Weight: [2.31047947 1.21005252] Bias: -1.0310834190473843 loss: 0.3323056897112691\n",
            "Round: 664 Weight: [2.31098315 1.21029462] Bias: -1.0312681362109966 loss: 0.3323022092307951\n",
            "Round: 665 Weight: [2.31148529 1.21053599] Bias: -1.0314522647113893 loss: 0.33229875020266425\n",
            "Round: 666 Weight: [2.31198589 1.21077661] Bias: -1.0316358067821598 loss: 0.33229531248417954\n",
            "Round: 667 Weight: [2.31248494 1.2110165 ] Bias: -1.03181876464608 loss: 0.332291895933691\n",
            "Round: 668 Weight: [2.31298246 1.21125565] Bias: -1.0320011405151637 loss: 0.3322885004105872\n",
            "Round: 669 Weight: [2.31347846 1.21149407] Bias: -1.0321829365907351 loss: 0.33228512577528596\n",
            "Round: 670 Weight: [2.31397293 1.21173176] Bias: -1.0323641550634959 loss: 0.3322817718892267\n",
            "Round: 671 Weight: [2.31446589 1.21196872] Bias: -1.0325447981135916 loss: 0.33227843861486156\n",
            "Round: 672 Weight: [2.31495734 1.21220496] Bias: -1.0327248679106775 loss: 0.3322751258156472\n",
            "Round: 673 Weight: [2.31544728 1.21244048] Bias: -1.0329043666139848 loss: 0.33227183335603705\n",
            "Round: 674 Weight: [2.31593572 1.21267528] Bias: -1.0330832963723855 loss: 0.33226856110147196\n",
            "Round: 675 Weight: [2.31642266 1.21290936] Bias: -1.0332616593244568 loss: 0.3322653089183735\n",
            "Round: 676 Weight: [2.31690811 1.21314272] Bias: -1.0334394575985453 loss: 0.3322620766741352\n",
            "Round: 677 Weight: [2.31739208 1.21337538] Bias: -1.0336166933128308 loss: 0.33225886423711465\n",
            "Round: 678 Weight: [2.31787457 1.21360732] Bias: -1.033793368575389 loss: 0.332255671476626\n",
            "Round: 679 Weight: [2.31835559 1.21383856] Bias: -1.0339694854842545 loss: 0.33225249826293146\n",
            "Round: 680 Weight: [2.31883513 1.21406909] Bias: -1.0341450461274821 loss: 0.33224934446723464\n",
            "Round: 681 Weight: [2.31931321 1.21429892] Bias: -1.03432005258321 loss: 0.3322462099616721\n",
            "Round: 682 Weight: [2.31978984 1.21452806] Bias: -1.0344945069197187 loss: 0.3322430946193059\n",
            "Round: 683 Weight: [2.32026501 1.21475649] Bias: -1.0346684111954938 loss: 0.33223999831411655\n",
            "Round: 684 Weight: [2.32073873 1.21498423] Bias: -1.0348417674592854 loss: 0.3322369209209947\n",
            "Round: 685 Weight: [2.321211   1.21521128] Bias: -1.035014577750167 loss: 0.33223386231573493\n",
            "Round: 686 Weight: [2.32168184 1.21543764] Bias: -1.0351868440975962 loss: 0.33223082237502766\n",
            "Round: 687 Weight: [2.32215124 1.21566331] Bias: -1.0353585685214726 loss: 0.3322278009764518\n",
            "Round: 688 Weight: [2.32261922 1.21588829] Bias: -1.0355297530321965 loss: 0.33222479799846844\n",
            "Round: 689 Weight: [2.32308577 1.21611259] Bias: -1.0357003996307268 loss: 0.3322218133204126\n",
            "Round: 690 Weight: [2.32355091 1.21633621] Bias: -1.0358705103086383 loss: 0.3322188468224873\n",
            "Round: 691 Weight: [2.32401463 1.21655916] Bias: -1.036040087048179 loss: 0.33221589838575605\n",
            "Round: 692 Weight: [2.32447694 1.21678143] Bias: -1.0362091318223265 loss: 0.33221296789213556\n",
            "Round: 693 Weight: [2.32493785 1.21700302] Bias: -1.0363776465948444 loss: 0.33221005522438984\n",
            "Round: 694 Weight: [2.32539735 1.21722394] Bias: -1.036545633320338 loss: 0.3322071602661227\n",
            "Round: 695 Weight: [2.32585547 1.2174442 ] Bias: -1.0367130939443094 loss: 0.33220428290177095\n",
            "Round: 696 Weight: [2.32631219 1.21766379] Bias: -1.0368800304032126 loss: 0.3322014230165986\n",
            "Round: 697 Weight: [2.32676753 1.21788271] Bias: -1.0370464446245078 loss: 0.33219858049668916\n",
            "Round: 698 Weight: [2.32722149 1.21810098] Bias: -1.0372123385267158 loss: 0.33219575522893996\n",
            "Round: 699 Weight: [2.32767408 1.21831858] Bias: -1.0373777140194715 loss: 0.3321929471010552\n",
            "Round: 700 Weight: [2.3281253  1.21853553] Bias: -1.0375425730035772 loss: 0.33219015600153956\n",
            "Round: 701 Weight: [2.32857515 1.21875182] Bias: -1.0377069173710551 loss: 0.3321873818196921\n",
            "Round: 702 Weight: [2.32902364 1.21896745] Bias: -1.0378707490052006 loss: 0.33218462444559965\n",
            "Round: 703 Weight: [2.32947077 1.21918244] Bias: -1.0380340697806334 loss: 0.3321818837701308\n",
            "Round: 704 Weight: [2.32991655 1.21939678] Bias: -1.03819688156335 loss: 0.33217915968492956\n",
            "Round: 705 Weight: [2.33036099 1.21961048] Bias: -1.0383591862107744 loss: 0.33217645208240915\n",
            "Round: 706 Weight: [2.33080408 1.21982352] Bias: -1.0385209855718096 loss: 0.3321737608557461\n",
            "Round: 707 Weight: [2.33124584 1.22003593] Bias: -1.0386822814868872 loss: 0.3321710858988743\n",
            "Round: 708 Weight: [2.33168626 1.2202477 ] Bias: -1.038843075788019 loss: 0.33216842710647837\n",
            "Round: 709 Weight: [2.33212536 1.22045883] Bias: -1.039003370298845 loss: 0.3321657843739887\n",
            "Round: 710 Weight: [2.33256313 1.22066933] Bias: -1.0391631668346846 loss: 0.3321631575975749\n",
            "Round: 711 Weight: [2.33299958 1.22087919] Bias: -1.039322467202584 loss: 0.3321605466741402\n",
            "Round: 712 Weight: [2.33343472 1.22108842] Bias: -1.0394812732013665 loss: 0.3321579515013157\n",
            "Round: 713 Weight: [2.33386855 1.22129703] Bias: -1.0396395866216794 loss: 0.3321553719774545\n",
            "Round: 714 Weight: [2.33430107 1.221505  ] Bias: -1.039797409246043 loss: 0.33215280800162617\n",
            "Round: 715 Weight: [2.33473229 1.22171236] Bias: -1.039954742848897 loss: 0.3321502594736112\n",
            "Round: 716 Weight: [2.33516221 1.22191909] Bias: -1.04011158919665 loss: 0.3321477262938954\n",
            "Round: 717 Weight: [2.33559084 1.2221252 ] Bias: -1.0402679500477232 loss: 0.33214520836366396\n",
            "Round: 718 Weight: [2.33601819 1.22233069] Bias: -1.0404238271526003 loss: 0.33214270558479664\n",
            "Round: 719 Weight: [2.33644425 1.22253557] Bias: -1.0405792222538712 loss: 0.33214021785986203\n",
            "Round: 720 Weight: [2.33686903 1.22273983] Bias: -1.0407341370862795 loss: 0.3321377450921122\n",
            "Round: 721 Weight: [2.33729254 1.22294348] Bias: -1.0408885733767668 loss: 0.33213528718547713\n",
            "Round: 722 Weight: [2.33771477 1.22314652] Bias: -1.041042532844519 loss: 0.33213284404456\n",
            "Round: 723 Weight: [2.33813574 1.22334896] Bias: -1.0411960172010106 loss: 0.3321304155746313\n",
            "Round: 724 Weight: [2.33855545 1.22355078] Bias: -1.0413490281500495 loss: 0.3321280016816243\n",
            "Round: 725 Weight: [2.3389739  1.22375201] Bias: -1.041501567387821 loss: 0.3321256022721293\n",
            "Round: 726 Weight: [2.3393911  1.22395263] Bias: -1.0416536366029319 loss: 0.33212321725338884\n",
            "Round: 727 Weight: [2.33980705 1.22415265] Bias: -1.0418052374764541 loss: 0.33212084653329277\n",
            "Round: 728 Weight: [2.34022175 1.22435208] Bias: -1.0419563716819682 loss: 0.33211849002037286\n",
            "Round: 729 Weight: [2.34063521 1.22455091] Bias: -1.0421070408856057 loss: 0.3321161476237981\n",
            "Round: 730 Weight: [2.34104744 1.22474915] Bias: -1.0422572467460922 loss: 0.3321138192533699\n",
            "Round: 731 Weight: [2.34145843 1.22494679] Bias: -1.04240699091479 loss: 0.33211150481951696\n",
            "Round: 732 Weight: [2.3418682  1.22514385] Bias: -1.042556275035739 loss: 0.3321092042332903\n",
            "Round: 733 Weight: [2.34227674 1.22534032] Bias: -1.0427051007457007 loss: 0.3321069174063589\n",
            "Round: 734 Weight: [2.34268407 1.2255362 ] Bias: -1.042853469674197 loss: 0.33210464425100467\n",
            "Round: 735 Weight: [2.34309017 1.2257315 ] Bias: -1.0430013834435528 loss: 0.33210238468011766\n",
            "Round: 736 Weight: [2.34349507 1.22592622] Bias: -1.0431488436689373 loss: 0.3321001386071918\n",
            "Round: 737 Weight: [2.34389876 1.22612036] Bias: -1.0432958519584035 loss: 0.33209790594631944\n",
            "Round: 738 Weight: [2.34430124 1.22631392] Bias: -1.0434424099129287 loss: 0.332095686612188\n",
            "Round: 739 Weight: [2.34470253 1.22650691] Bias: -1.043588519126455 loss: 0.33209348052007415\n",
            "Round: 740 Weight: [2.34510262 1.22669932] Bias: -1.0437341811859284 loss: 0.3320912875858401\n",
            "Round: 741 Weight: [2.34550152 1.22689116] Bias: -1.0438793976713392 loss: 0.3320891077259288\n",
            "Round: 742 Weight: [2.34589923 1.22708243] Bias: -1.04402417015576 loss: 0.3320869408573596\n",
            "Round: 743 Weight: [2.34629576 1.22727313] Bias: -1.044168500205385 loss: 0.3320847868977238\n",
            "Round: 744 Weight: [2.34669111 1.22746326] Bias: -1.0443123893795692 loss: 0.3320826457651806\n",
            "Round: 745 Weight: [2.34708528 1.22765283] Bias: -1.0444558392308654 loss: 0.3320805173784519\n",
            "Round: 746 Weight: [2.34747828 1.22784184] Bias: -1.0445988513050637 loss: 0.33207840165681923\n",
            "Round: 747 Weight: [2.34787012 1.22803029] Bias: -1.0447414271412283 loss: 0.3320762985201185\n",
            "Round: 748 Weight: [2.34826079 1.22821818] Bias: -1.0448835682717357 loss: 0.3320742078887363\n",
            "Round: 749 Weight: [2.3486503  1.22840551] Bias: -1.0450252762223111 loss: 0.3320721296836056\n",
            "Round: 750 Weight: [2.34903865 1.22859229] Bias: -1.0451665525120664 loss: 0.33207006382620147\n",
            "Round: 751 Weight: [2.34942586 1.22877851] Bias: -1.045307398653536 loss: 0.3320680102385371\n",
            "Round: 752 Weight: [2.34981191 1.22896419] Bias: -1.0454478161527139 loss: 0.3320659688431599\n",
            "Round: 753 Weight: [2.35019682 1.22914931] Bias: -1.04558780650909 loss: 0.3320639395631472\n",
            "Round: 754 Weight: [2.35058059 1.22933389] Bias: -1.0457273712156856 loss: 0.3320619223221023\n",
            "Round: 755 Weight: [2.35096323 1.22951792] Bias: -1.0458665117590895 loss: 0.33205991704415033\n",
            "Round: 756 Weight: [2.35134473 1.2297014 ] Bias: -1.046005229619493 loss: 0.3320579236539349\n",
            "Round: 757 Weight: [2.3517251  1.22988435] Bias: -1.046143526270726 loss: 0.3320559420766134\n",
            "Round: 758 Weight: [2.35210434 1.23006675] Bias: -1.046281403180291 loss: 0.33205397223785377\n",
            "Round: 759 Weight: [2.35248247 1.23024861] Bias: -1.0464188618093984 loss: 0.3320520140638305\n",
            "Round: 760 Weight: [2.35285947 1.23042994] Bias: -1.0465559036130008 loss: 0.33205006748122057\n",
            "Round: 761 Weight: [2.35323536 1.23061073] Bias: -1.0466925300398278 loss: 0.33204813241719966\n",
            "Round: 762 Weight: [2.35361014 1.23079099] Bias: -1.046828742532419 loss: 0.33204620879943914\n",
            "Round: 763 Weight: [2.35398382 1.23097072] Bias: -1.0469645425271588 loss: 0.3320442965561014\n",
            "Round: 764 Weight: [2.35435639 1.23114992] Bias: -1.0470999314543095 loss: 0.33204239561583665\n",
            "Round: 765 Weight: [2.35472786 1.23132859] Bias: -1.0472349107380443 loss: 0.3320405059077793\n",
            "Round: 766 Weight: [2.35509823 1.23150673] Bias: -1.0473694817964814 loss: 0.33203862736154416\n",
            "Round: 767 Weight: [2.35546752 1.23168435] Bias: -1.0475036460417158 loss: 0.3320367599072229\n",
            "Round: 768 Weight: [2.35583571 1.23186144] Bias: -1.0476374048798527 loss: 0.3320349034753808\n",
            "Round: 769 Weight: [2.35620282 1.23203802] Bias: -1.0477707597110395 loss: 0.33203305799705257\n",
            "Round: 770 Weight: [2.35656884 1.23221407] Bias: -1.047903711929498 loss: 0.3320312234037395\n",
            "Round: 771 Weight: [2.35693379 1.23238961] Bias: -1.0480362629235571 loss: 0.33202939962740563\n",
            "Round: 772 Weight: [2.35729767 1.23256463] Bias: -1.0481684140756835 loss: 0.33202758660047427\n",
            "Round: 773 Weight: [2.35766047 1.23273914] Bias: -1.0483001667625138 loss: 0.33202578425582496\n",
            "Round: 774 Weight: [2.35802221 1.23291313] Bias: -1.0484315223548861 loss: 0.3320239925267898\n",
            "Round: 775 Weight: [2.35838288 1.23308662] Bias: -1.048562482217871 loss: 0.3320222113471499\n",
            "Round: 776 Weight: [2.35874249 1.23325959] Bias: -1.0486930477108016 loss: 0.3320204406511324\n",
            "Round: 777 Weight: [2.35910104 1.23343206] Bias: -1.048823220187306 loss: 0.33201868037340715\n",
            "Round: 778 Weight: [2.35945854 1.23360402] Bias: -1.0489530009953363 loss: 0.33201693044908326\n",
            "Round: 779 Weight: [2.35981499 1.23377547] Bias: -1.0490823914771992 loss: 0.33201519081370595\n",
            "Round: 780 Weight: [2.3601704  1.23394642] Bias: -1.0492113929695868 loss: 0.3320134614032531\n",
            "Round: 781 Weight: [2.36052476 1.23411688] Bias: -1.0493400068036056 loss: 0.3320117421541328\n",
            "Round: 782 Weight: [2.36087808 1.23428683] Bias: -1.049468234304807 loss: 0.33201003300317905\n",
            "Round: 783 Weight: [2.36123036 1.23445628] Bias: -1.0495960767932158 loss: 0.3320083338876493\n",
            "Round: 784 Weight: [2.36158162 1.23462524] Bias: -1.0497235355833607 loss: 0.3320066447452217\n",
            "Round: 785 Weight: [2.36193184 1.2347937 ] Bias: -1.0498506119843025 loss: 0.3320049655139911\n",
            "Round: 786 Weight: [2.36228103 1.23496167] Bias: -1.0499773072996634 loss: 0.33200329613246654\n",
            "Round: 787 Weight: [2.3626292  1.23512915] Bias: -1.0501036228276557 loss: 0.33200163653956827\n",
            "Round: 788 Weight: [2.36297636 1.23529614] Bias: -1.05022955986111 loss: 0.3319999866746244\n",
            "Round: 789 Weight: [2.36332249 1.23546264] Bias: -1.050355119687504 loss: 0.33199834647736803\n",
            "Round: 790 Weight: [2.36366762 1.23562866] Bias: -1.0504803035889905 loss: 0.33199671588793467\n",
            "Round: 791 Weight: [2.36401173 1.23579419] Bias: -1.0506051128424252 loss: 0.3319950948468586\n",
            "Round: 792 Weight: [2.36435484 1.23595923] Bias: -1.0507295487193946 loss: 0.33199348329507034\n",
            "Round: 793 Weight: [2.36469694 1.2361238 ] Bias: -1.0508536124862435 loss: 0.3319918811738939\n",
            "Round: 794 Weight: [2.36503805 1.23628788] Bias: -1.0509773054041027 loss: 0.3319902884250438\n",
            "Round: 795 Weight: [2.36537816 1.23645148] Bias: -1.051100628728916 loss: 0.33198870499062194\n",
            "Round: 796 Weight: [2.36571727 1.23661461] Bias: -1.0512235837114672 loss: 0.33198713081311515\n",
            "Round: 797 Weight: [2.36605539 1.23677726] Bias: -1.0513461715974073 loss: 0.3319855658353921\n",
            "Round: 798 Weight: [2.36639253 1.23693944] Bias: -1.0514683936272808 loss: 0.33198401000070077\n",
            "Round: 799 Weight: [2.36672869 1.23710115] Bias: -1.0515902510365525 loss: 0.3319824632526655\n",
            "Round: 800 Weight: [2.36706386 1.23726238] Bias: -1.0517117450556333 loss: 0.33198092553528424\n",
            "Round: 801 Weight: [2.36739805 1.23742314] Bias: -1.0518328769099075 loss: 0.3319793967929263\n",
            "Round: 802 Weight: [2.36773127 1.23758344] Bias: -1.051953647819758 loss: 0.33197787697032893\n",
            "Round: 803 Weight: [2.36806352 1.23774327] Bias: -1.0520740590005921 loss: 0.3319763660125951\n",
            "Round: 804 Weight: [2.36839481 1.23790263] Bias: -1.0521941116628675 loss: 0.33197486386519076\n",
            "Round: 805 Weight: [2.36872512 1.23806153] Bias: -1.0523138070121174 loss: 0.33197337047394243\n",
            "Round: 806 Weight: [2.36905448 1.23821997] Bias: -1.0524331462489767 loss: 0.33197188578503406\n",
            "Round: 807 Weight: [2.36938288 1.23837795] Bias: -1.052552130569206 loss: 0.33197040974500475\n",
            "Round: 808 Weight: [2.36971032 1.23853547] Bias: -1.0526707611637176 loss: 0.33196894230074664\n",
            "Round: 809 Weight: [2.37003681 1.23869253] Bias: -1.0527890392186 loss: 0.3319674833995015\n",
            "Round: 810 Weight: [2.37036234 1.23884913] Bias: -1.0529069659151422 loss: 0.3319660329888588\n",
            "Round: 811 Weight: [2.37068694 1.23900528] Bias: -1.053024542429859 loss: 0.3319645910167531\n",
            "Round: 812 Weight: [2.37101059 1.23916098] Bias: -1.0531417699345147 loss: 0.3319631574314613\n",
            "Round: 813 Weight: [2.3713333  1.23931623] Bias: -1.0532586495961478 loss: 0.3319617321816007\n",
            "Round: 814 Weight: [2.37165507 1.23947102] Bias: -1.0533751825770947 loss: 0.331960315216126\n",
            "Round: 815 Weight: [2.37197591 1.23962537] Bias: -1.053491370035014 loss: 0.3319589064843273\n",
            "Round: 816 Weight: [2.37229581 1.23977926] Bias: -1.0536072131229095 loss: 0.33195750593582724\n",
            "Round: 817 Weight: [2.37261479 1.23993272] Bias: -1.053722712989155 loss: 0.33195611352057935\n",
            "Round: 818 Weight: [2.37293284 1.24008572] Bias: -1.0538378707775171 loss: 0.3319547291888647\n",
            "Round: 819 Weight: [2.37324997 1.24023829] Bias: -1.053952687627178 loss: 0.33195335289129047\n",
            "Round: 820 Weight: [2.37356618 1.24039041] Bias: -1.0540671646727595 loss: 0.3319519845787872\n",
            "Round: 821 Weight: [2.37388148 1.24054209] Bias: -1.0541813030443457 loss: 0.33195062420260624\n",
            "Round: 822 Weight: [2.37419586 1.24069333] Bias: -1.0542951038675055 loss: 0.331949271714318\n",
            "Round: 823 Weight: [2.37450933 1.24084414] Bias: -1.0544085682633162 loss: 0.3319479270658094\n",
            "Round: 824 Weight: [2.37482189 1.24099451] Bias: -1.054521697348385 loss: 0.33194659020928136\n",
            "Round: 825 Weight: [2.37513355 1.24114444] Bias: -1.0546344922348727 loss: 0.331945261097247\n",
            "Round: 826 Weight: [2.3754443  1.24129394] Bias: -1.0547469540305145 loss: 0.33194393968252933\n",
            "Round: 827 Weight: [2.37575416 1.24144301] Bias: -1.0548590838386434 loss: 0.3319426259182589\n",
            "Round: 828 Weight: [2.37606312 1.24159165] Bias: -1.0549708827582114 loss: 0.33194131975787156\n",
            "Round: 829 Weight: [2.37637119 1.24173986] Bias: -1.0550823518838122 loss: 0.3319400211551064\n",
            "Round: 830 Weight: [2.37667836 1.24188764] Bias: -1.0551934923057023 loss: 0.33193873006400393\n",
            "Round: 831 Weight: [2.37698465 1.24203499] Bias: -1.0553043051098223 loss: 0.33193744643890305\n",
            "Round: 832 Weight: [2.37729006 1.24218192] Bias: -1.0554147913778196 loss: 0.3319361702344399\n",
            "Round: 833 Weight: [2.37759458 1.24232842] Bias: -1.0555249521870682 loss: 0.3319349014055454\n",
            "Round: 834 Weight: [2.37789822 1.2424745 ] Bias: -1.0556347886106912 loss: 0.3319336399074429\n",
            "Round: 835 Weight: [2.37820099 1.24262017] Bias: -1.055744301717581 loss: 0.3319323856956463\n",
            "Round: 836 Weight: [2.37850288 1.24276541] Bias: -1.0558534925724208 loss: 0.33193113872595853\n",
            "Round: 837 Weight: [2.3788039  1.24291023] Bias: -1.0559623622357053 loss: 0.33192989895446817\n",
            "Round: 838 Weight: [2.37910406 1.24305463] Bias: -1.0560709117637608 loss: 0.331928666337549\n",
            "Round: 839 Weight: [2.37940334 1.24319862] Bias: -1.0561791422087665 loss: 0.33192744083185705\n",
            "Round: 840 Weight: [2.37970177 1.2433422 ] Bias: -1.0562870546187746 loss: 0.3319262223943286\n",
            "Round: 841 Weight: [2.37999933 1.24348536] Bias: -1.0563946500377304 loss: 0.3319250109821788\n",
            "Round: 842 Weight: [2.38029604 1.24362811] Bias: -1.056501929505493 loss: 0.33192380655289894\n",
            "Round: 843 Weight: [2.3805919  1.24377044] Bias: -1.0566088940578549 loss: 0.3319226090642554\n",
            "Round: 844 Weight: [2.3808869  1.24391237] Bias: -1.056715544726562 loss: 0.3319214184742868\n",
            "Round: 845 Weight: [2.38118105 1.24405389] Bias: -1.0568218825393334 loss: 0.33192023474130283\n",
            "Round: 846 Weight: [2.38147436 1.24419501] Bias: -1.0569279085198815 loss: 0.33191905782388176\n",
            "Round: 847 Weight: [2.38176682 1.24433571] Bias: -1.0570336236879307 loss: 0.3319178876808692\n",
            "Round: 848 Weight: [2.38205844 1.24447602] Bias: -1.0571390290592377 loss: 0.3319167242713755\n",
            "Round: 849 Weight: [2.38234922 1.24461592] Bias: -1.0572441256456104 loss: 0.3319155675547744\n",
            "Round: 850 Weight: [2.38263917 1.24475542] Bias: -1.057348914454927 loss: 0.33191441749070133\n",
            "Round: 851 Weight: [2.38292828 1.24489452] Bias: -1.0574533964911552 loss: 0.33191327403905074\n",
            "Round: 852 Weight: [2.38321657 1.24503321] Bias: -1.0575575727543713 loss: 0.3319121371599753\n",
            "Round: 853 Weight: [2.38350402 1.24517152] Bias: -1.057661444240779 loss: 0.3319110068138836\n",
            "Round: 854 Weight: [2.38379065 1.24530942] Bias: -1.0577650119427282 loss: 0.3319098829614383\n",
            "Round: 855 Weight: [2.38407646 1.24544693] Bias: -1.057868276848733 loss: 0.3319087655635546\n",
            "Round: 856 Weight: [2.38436145 1.24558404] Bias: -1.0579712399434915 loss: 0.3319076545813983\n",
            "Round: 857 Weight: [2.38464562 1.24572076] Bias: -1.0580739022079029 loss: 0.33190654997638414\n",
            "Round: 858 Weight: [2.38492897 1.24585709] Bias: -1.0581762646190862 loss: 0.3319054517101739\n",
            "Round: 859 Weight: [2.38521151 1.24599303] Bias: -1.058278328150399 loss: 0.3319043597446751\n",
            "Round: 860 Weight: [2.38549325 1.24612858] Bias: -1.0583800937714545 loss: 0.33190327404203884\n",
            "Round: 861 Weight: [2.38577417 1.24626374] Bias: -1.0584815624481403 loss: 0.33190219456465847\n",
            "Round: 862 Weight: [2.38605429 1.24639852] Bias: -1.0585827351426362 loss: 0.3319011212751676\n",
            "Round: 863 Weight: [2.38633361 1.24653291] Bias: -1.0586836128134314 loss: 0.3319000541364385\n",
            "Round: 864 Weight: [2.38661213 1.24666691] Bias: -1.0587841964153422 loss: 0.3318989931115809\n",
            "Round: 865 Weight: [2.38688985 1.24680053] Bias: -1.0588844868995304 loss: 0.3318979381639394\n",
            "Round: 866 Weight: [2.38716677 1.24693377] Bias: -1.0589844852135197 loss: 0.33189688925709304\n",
            "Round: 867 Weight: [2.3874429  1.24706663] Bias: -1.0590841923012135 loss: 0.33189584635485253\n",
            "Round: 868 Weight: [2.38771825 1.24719911] Bias: -1.059183609102912 loss: 0.33189480942125943\n",
            "Round: 869 Weight: [2.3879928  1.24733121] Bias: -1.0592827365553295 loss: 0.3318937784205843\n",
            "Round: 870 Weight: [2.38826657 1.24746293] Bias: -1.0593815755916112 loss: 0.3318927533173251\n",
            "Round: 871 Weight: [2.38853956 1.24759428] Bias: -1.05948012714135 loss: 0.3318917340762056\n",
            "Round: 872 Weight: [2.38881177 1.24772525] Bias: -1.059578392130604 loss: 0.3318907206621742\n",
            "Round: 873 Weight: [2.3890832  1.24785584] Bias: -1.059676371481912 loss: 0.33188971304040127\n",
            "Round: 874 Weight: [2.38935385 1.24798607] Bias: -1.0597740661143116 loss: 0.3318887111762794\n",
            "Round: 875 Weight: [2.38962374 1.24811592] Bias: -1.0598714769433544 loss: 0.3318877150354203\n",
            "Round: 876 Weight: [2.38989285 1.2482454 ] Bias: -1.059968604881123 loss: 0.33188672458365404\n",
            "Round: 877 Weight: [2.39016119 1.24837452] Bias: -1.0600654508362477 loss: 0.3318857397870274\n",
            "Round: 878 Weight: [2.39042877 1.24850326] Bias: -1.0601620157139218 loss: 0.3318847606118022\n",
            "Round: 879 Weight: [2.39069558 1.24863164] Bias: -1.0602583004159185 loss: 0.3318837870244543\n",
            "Round: 880 Weight: [2.39096164 1.24875965] Bias: -1.0603543058406066 loss: 0.3318828189916717\n",
            "Round: 881 Weight: [2.39122693 1.2488873 ] Bias: -1.0604500328829667 loss: 0.3318818564803532\n",
            "Round: 882 Weight: [2.39149147 1.24901458] Bias: -1.0605454824346066 loss: 0.33188089945760696\n",
            "Round: 883 Weight: [2.39175526 1.2491415 ] Bias: -1.0606406553837773 loss: 0.33187994789074937\n",
            "Round: 884 Weight: [2.39201829 1.24926806] Bias: -1.060735552615389 loss: 0.33187900174730295\n",
            "Round: 885 Weight: [2.39228058 1.24939426] Bias: -1.0608301750110258 loss: 0.33187806099499567\n",
            "Round: 886 Weight: [2.39254211 1.2495201 ] Bias: -1.0609245234489626 loss: 0.33187712560175925\n",
            "Round: 887 Weight: [2.39280291 1.24964558] Bias: -1.0610185988041787 loss: 0.33187619553572734\n",
            "Round: 888 Weight: [2.39306296 1.24977071] Bias: -1.0611124019483744 loss: 0.3318752707652349\n",
            "Round: 889 Weight: [2.39332227 1.24989548] Bias: -1.061205933749986 loss: 0.33187435125881654\n",
            "Round: 890 Weight: [2.39358084 1.25001989] Bias: -1.0612991950742003 loss: 0.33187343698520505\n",
            "Round: 891 Weight: [2.39383868 1.25014396] Bias: -1.0613921867829708 loss: 0.3318725279133299\n",
            "Round: 892 Weight: [2.39409578 1.25026767] Bias: -1.0614849097350312 loss: 0.33187162401231624\n",
            "Round: 893 Weight: [2.39435216 1.25039102] Bias: -1.0615773647859115 loss: 0.3318707252514836\n",
            "Round: 894 Weight: [2.3946078  1.25051403] Bias: -1.0616695527879518 loss: 0.3318698316003444\n",
            "Round: 895 Weight: [2.39486272 1.25063669] Bias: -1.061761474590318 loss: 0.33186894302860226\n",
            "Round: 896 Weight: [2.39511692 1.250759  ] Bias: -1.0618531310390156 loss: 0.33186805950615156\n",
            "Round: 897 Weight: [2.39537039 1.25088096] Bias: -1.0619445229769042 loss: 0.33186718100307555\n",
            "Round: 898 Weight: [2.39562314 1.25100258] Bias: -1.0620356512437128 loss: 0.3318663074896453\n",
            "Round: 899 Weight: [2.39587518 1.25112385] Bias: -1.0621265166760534 loss: 0.33186543893631804\n",
            "Round: 900 Weight: [2.3961265  1.25124477] Bias: -1.0622171201074353 loss: 0.3318645753137365\n",
            "Round: 901 Weight: [2.39637711 1.25136536] Bias: -1.0623074623682793 loss: 0.3318637165927274\n",
            "Round: 902 Weight: [2.396627  1.2514856] Bias: -1.0623975442859326 loss: 0.3318628627442999\n",
            "Round: 903 Weight: [2.39687619 1.2516055 ] Bias: -1.0624873666846815 loss: 0.33186201373964497\n",
            "Round: 904 Weight: [2.39712467 1.25172507] Bias: -1.0625769303857664 loss: 0.3318611695501335\n",
            "Round: 905 Weight: [2.39737245 1.25184429] Bias: -1.0626662362073953 loss: 0.33186033014731575\n",
            "Round: 906 Weight: [2.39761952 1.25196317] Bias: -1.0627552849647575 loss: 0.33185949550291954\n",
            "Round: 907 Weight: [2.3978659  1.25208172] Bias: -1.0628440774700376 loss: 0.33185866558884963\n",
            "Round: 908 Weight: [2.39811157 1.25219994] Bias: -1.0629326145324287 loss: 0.33185784037718585\n",
            "Round: 909 Weight: [2.39835655 1.25231782] Bias: -1.0630208969581465 loss: 0.33185701984018273\n",
            "Round: 910 Weight: [2.39860084 1.25243536] Bias: -1.0631089255504422 loss: 0.3318562039502676\n",
            "Round: 911 Weight: [2.39884444 1.25255257] Bias: -1.0631967011096164 loss: 0.33185539268004\n",
            "Round: 912 Weight: [2.39908734 1.25266945] Bias: -1.0632842244330323 loss: 0.3318545860022698\n",
            "Round: 913 Weight: [2.39932956 1.25278601] Bias: -1.0633714963151286 loss: 0.33185378388989706\n",
            "Round: 914 Weight: [2.3995711  1.25290223] Bias: -1.0634585175474331 loss: 0.33185298631603\n",
            "Round: 915 Weight: [2.39981195 1.25301812] Bias: -1.063545288918576 loss: 0.3318521932539444\n",
            "Round: 916 Weight: [2.40005212 1.25313368] Bias: -1.0636318112143017 loss: 0.33185140467708235\n",
            "Round: 917 Weight: [2.40029161 1.25324892] Bias: -1.063718085217484 loss: 0.33185062055905074\n",
            "Round: 918 Weight: [2.40053042 1.25336384] Bias: -1.0638041117081363 loss: 0.33184984087362096\n",
            "Round: 919 Weight: [2.40076856 1.25347842] Bias: -1.0638898914634267 loss: 0.331849065594727\n",
            "Round: 920 Weight: [2.40100603 1.25359269] Bias: -1.0639754252576894 loss: 0.33184829469646493\n",
            "Round: 921 Weight: [2.40124282 1.25370663] Bias: -1.0640607138624378 loss: 0.33184752815309165\n",
            "Round: 922 Weight: [2.40147895 1.25382025] Bias: -1.0641457580463771 loss: 0.3318467659390235\n",
            "Round: 923 Weight: [2.40171441 1.25393355] Bias: -1.064230558575417 loss: 0.3318460080288358\n",
            "Round: 924 Weight: [2.40194921 1.25404653] Bias: -1.0643151162126838 loss: 0.3318452543972611\n",
            "Round: 925 Weight: [2.40218334 1.2541592 ] Bias: -1.0643994317185328 loss: 0.33184450501918894\n",
            "Round: 926 Weight: [2.40241681 1.25427154] Bias: -1.064483505850561 loss: 0.3318437598696639\n",
            "Round: 927 Weight: [2.40264963 1.25438357] Bias: -1.0645673393636192 loss: 0.3318430189238854\n",
            "Round: 928 Weight: [2.40288179 1.25449528] Bias: -1.064650933009824 loss: 0.33184228215720607\n",
            "Round: 929 Weight: [2.40311329 1.25460668] Bias: -1.0647342875385697 loss: 0.3318415495451313\n",
            "Round: 930 Weight: [2.40334414 1.25471776] Bias: -1.0648174036965414 loss: 0.3318408210633174\n",
            "Round: 931 Weight: [2.40357434 1.25482853] Bias: -1.0649002822277258 loss: 0.3318400966875714\n",
            "Round: 932 Weight: [2.40380389 1.25493899] Bias: -1.0649829238734236 loss: 0.33183937639384986\n",
            "Round: 933 Weight: [2.4040328  1.25504914] Bias: -1.0650653293722616 loss: 0.3318386601582574\n",
            "Round: 934 Weight: [2.40426106 1.25515897] Bias: -1.0651474994602042 loss: 0.3318379479570465\n",
            "Round: 935 Weight: [2.40448868 1.2552685 ] Bias: -1.0652294348705649 loss: 0.33183723976661594\n",
            "Round: 936 Weight: [2.40471565 1.25537772] Bias: -1.0653111363340184 loss: 0.3318365355635098\n",
            "Round: 937 Weight: [2.40494199 1.25548664] Bias: -1.0653926045786122 loss: 0.33183583532441685\n",
            "Round: 938 Weight: [2.40516769 1.25559524] Bias: -1.0654738403297777 loss: 0.3318351390261697\n",
            "Round: 939 Weight: [2.40539276 1.25570354] Bias: -1.0655548443103418 loss: 0.33183444664574313\n",
            "Round: 940 Weight: [2.40561719 1.25581154] Bias: -1.0656356172405388 loss: 0.33183375816025407\n",
            "Round: 941 Weight: [2.40584099 1.25591923] Bias: -1.0657161598380214 loss: 0.33183307354695984\n",
            "Round: 942 Weight: [2.40606417 1.25602662] Bias: -1.0657964728178715 loss: 0.33183239278325793\n",
            "Round: 943 Weight: [2.40628671 1.25613371] Bias: -1.065876556892612 loss: 0.3318317158466846\n",
            "Round: 944 Weight: [2.40650863 1.2562405 ] Bias: -1.0659564127722183 loss: 0.3318310427149139\n",
            "Round: 945 Weight: [2.40672993 1.25634699] Bias: -1.0660360411641285 loss: 0.3318303733657574\n",
            "Round: 946 Weight: [2.4069506  1.25645318] Bias: -1.066115442773255 loss: 0.3318297077771625\n",
            "Round: 947 Weight: [2.40717066 1.25655907] Bias: -1.0661946183019955 loss: 0.33182904592721213\n",
            "Round: 948 Weight: [2.4073901  1.25666466] Bias: -1.0662735684502433 loss: 0.3318283877941235\n",
            "Round: 949 Weight: [2.40760892 1.25676996] Bias: -1.0663522939153993 loss: 0.33182773335624755\n",
            "Round: 950 Weight: [2.40782712 1.25687496] Bias: -1.0664307953923817 loss: 0.33182708259206756\n",
            "Round: 951 Weight: [2.40804472 1.25697967] Bias: -1.0665090735736376 loss: 0.33182643548019886\n",
            "Round: 952 Weight: [2.4082617  1.25708408] Bias: -1.0665871291491524 loss: 0.33182579199938766\n",
            "Round: 953 Weight: [2.40847808 1.2571882 ] Bias: -1.0666649628064624 loss: 0.33182515212851\n",
            "Round: 954 Weight: [2.40869385 1.25729203] Bias: -1.0667425752306636 loss: 0.3318245158465717\n",
            "Round: 955 Weight: [2.40890901 1.25739557] Bias: -1.0668199671044232 loss: 0.3318238831327062\n",
            "Round: 956 Weight: [2.40912357 1.25749882] Bias: -1.0668971391079896 loss: 0.3318232539661752\n",
            "Round: 957 Weight: [2.40933753 1.25760178] Bias: -1.066974091919203 loss: 0.33182262832636644\n",
            "Round: 958 Weight: [2.40955089 1.25770445] Bias: -1.0670508262135057 loss: 0.33182200619279406\n",
            "Round: 959 Weight: [2.40976365 1.25780683] Bias: -1.0671273426639523 loss: 0.331821387545097\n",
            "Round: 960 Weight: [2.40997582 1.25790893] Bias: -1.0672036419412203 loss: 0.33182077236303853\n",
            "Round: 961 Weight: [2.41018739 1.25801074] Bias: -1.0672797247136199 loss: 0.33182016062650527\n",
            "Round: 962 Weight: [2.41039837 1.25811226] Bias: -1.067355591647104 loss: 0.33181955231550664\n",
            "Round: 963 Weight: [2.41060876 1.2582135 ] Bias: -1.0674312434052788 loss: 0.3318189474101734\n",
            "Round: 964 Weight: [2.41081856 1.25831446] Bias: -1.0675066806494138 loss: 0.33181834589075815\n",
            "Round: 965 Weight: [2.41102777 1.25841514] Bias: -1.0675819040384509 loss: 0.33181774773763295\n",
            "Round: 966 Weight: [2.4112364  1.25851553] Bias: -1.0676569142290153 loss: 0.3318171529312898\n",
            "Round: 967 Weight: [2.41144444 1.25861564] Bias: -1.067731711875425 loss: 0.33181656145233923\n",
            "Round: 968 Weight: [2.4116519  1.25871548] Bias: -1.0678062976297007 loss: 0.33181597328150975\n",
            "Round: 969 Weight: [2.41185879 1.25881503] Bias: -1.0678806721415752 loss: 0.3318153883996468\n",
            "Round: 970 Weight: [2.41206509 1.25891431] Bias: -1.0679548360585036 loss: 0.33181480678771275\n",
            "Round: 971 Weight: [2.41227082 1.25901331] Bias: -1.0680287900256726 loss: 0.331814228426785\n",
            "Round: 972 Weight: [2.41247597 1.25911203] Bias: -1.0681025346860102 loss: 0.3318136532980561\n",
            "Round: 973 Weight: [2.41268055 1.25921047] Bias: -1.0681760706801957 loss: 0.33181308138283294\n",
            "Round: 974 Weight: [2.41288455 1.25930864] Bias: -1.0682493986466681 loss: 0.33181251266253553\n",
            "Round: 975 Weight: [2.41308799 1.25940654] Bias: -1.068322519221637 loss: 0.33181194711869666\n",
            "Round: 976 Weight: [2.41329086 1.25950417] Bias: -1.0683954330390908 loss: 0.3318113847329611\n",
            "Round: 977 Weight: [2.41349316 1.25960152] Bias: -1.0684681407308068 loss: 0.3318108254870849\n",
            "Round: 978 Weight: [2.4136949 1.2596986] Bias: -1.06854064292636 loss: 0.3318102693629344\n",
            "Round: 979 Weight: [2.41389608 1.25979541] Bias: -1.0686129402531326 loss: 0.3318097163424859\n",
            "Round: 980 Weight: [2.41409669 1.25989195] Bias: -1.0686850333363236 loss: 0.33180916640782493\n",
            "Round: 981 Weight: [2.41429675 1.25998822] Bias: -1.068756922798957 loss: 0.33180861954114504\n",
            "Round: 982 Weight: [2.41449624 1.26008422] Bias: -1.068828609261892 loss: 0.3318080757247478\n",
            "Round: 983 Weight: [2.41469518 1.26017995] Bias: -1.068900093343831 loss: 0.3318075349410416\n",
            "Round: 984 Weight: [2.41489357 1.26027542] Bias: -1.06897137566133 loss: 0.3318069971725412\n",
            "Round: 985 Weight: [2.4150914  1.26037062] Bias: -1.069042456828806 loss: 0.3318064624018669\n",
            "Round: 986 Weight: [2.41528868 1.26046555] Bias: -1.0691133374585469 loss: 0.3318059306117442\n",
            "Round: 987 Weight: [2.41548541 1.26056023] Bias: -1.0691840181607204 loss: 0.33180540178500223\n",
            "Round: 988 Weight: [2.41568159 1.26065463] Bias: -1.0692544995433824 loss: 0.33180487590457464\n",
            "Round: 989 Weight: [2.41587723 1.26074878] Bias: -1.069324782212486 loss: 0.3318043529534973\n",
            "Round: 990 Weight: [2.41607232 1.26084266] Bias: -1.0693948667718904 loss: 0.33180383291490856\n",
            "Round: 991 Weight: [2.41626687 1.26093628] Bias: -1.0694647538233693 loss: 0.3318033157720484\n",
            "Round: 992 Weight: [2.41646088 1.26102964] Bias: -1.0695344439666197 loss: 0.3318028015082579\n",
            "Round: 993 Weight: [2.41665434 1.26112274] Bias: -1.0696039377992705 loss: 0.33180229010697826\n",
            "Round: 994 Weight: [2.41684727 1.26121558] Bias: -1.0696732359168912 loss: 0.3318017815517505\n",
            "Round: 995 Weight: [2.41703966 1.26130817] Bias: -1.0697423389130003 loss: 0.33180127582621455\n",
            "Round: 996 Weight: [2.41723152 1.26140049] Bias: -1.0698112473790735 loss: 0.3318007729141088\n",
            "Round: 997 Weight: [2.41742284 1.26149256] Bias: -1.069879961904553 loss: 0.33180027279926955\n",
            "Round: 998 Weight: [2.41761363 1.26158438] Bias: -1.0699484830768546 loss: 0.3317997754656299\n",
            "Round: 999 Weight: [2.41780389 1.26167593] Bias: -1.0700168114813775 loss: 0.33179928089722\n",
            "Round: 1000 Weight: [2.41799362 1.26176724] Bias: -1.0700849477015115 loss: 0.3317987890781654\n",
            "Round: 1001 Weight: [2.41818283 1.26185829] Bias: -1.0701528923186456 loss: 0.3317982999926874\n",
            "Round: 1002 Weight: [2.4183715  1.26194908] Bias: -1.0702206459121764 loss: 0.3317978136251015\n",
            "Round: 1003 Weight: [2.41855966 1.26203963] Bias: -1.0702882090595158 loss: 0.3317973299598179\n",
            "Round: 1004 Weight: [2.41874729 1.26212992] Bias: -1.0703555823361002 loss: 0.33179684898133976\n",
            "Round: 1005 Weight: [2.4189344  1.26221996] Bias: -1.0704227663153973 loss: 0.3317963706742635\n",
            "Round: 1006 Weight: [2.41912099 1.26230976] Bias: -1.070489761568915 loss: 0.3317958950232775\n",
            "Round: 1007 Weight: [2.41930706 1.2623993 ] Bias: -1.0705565686662093 loss: 0.33179542201316226\n",
            "Round: 1008 Weight: [2.41949262 1.26248859] Bias: -1.070623188174892 loss: 0.33179495162878914\n",
            "Round: 1009 Weight: [2.41967766 1.26257764] Bias: -1.0706896206606387 loss: 0.33179448385512017\n",
            "Round: 1010 Weight: [2.41986218 1.26266644] Bias: -1.0707558666871966 loss: 0.33179401867720726\n",
            "Round: 1011 Weight: [2.4200462  1.26275499] Bias: -1.0708219268163932 loss: 0.33179355608019195\n",
            "Round: 1012 Weight: [2.4202297 1.2628433] Bias: -1.070887801608143 loss: 0.3317930960493044\n",
            "Round: 1013 Weight: [2.4204127  1.26293136] Bias: -1.0709534916204557 loss: 0.33179263856986313\n",
            "Round: 1014 Weight: [2.42059518 1.26301918] Bias: -1.0710189974094444 loss: 0.33179218362727453\n",
            "Round: 1015 Weight: [2.42077717 1.26310676] Bias: -1.0710843195293325 loss: 0.33179173120703176\n",
            "Round: 1016 Weight: [2.42095864 1.26319409] Bias: -1.0711494585324617 loss: 0.3317912812947151\n",
            "Round: 1017 Weight: [2.42113962 1.26328118] Bias: -1.0712144149693 loss: 0.33179083387599045\n",
            "Round: 1018 Weight: [2.42132009 1.26336803] Bias: -1.0712791893884488 loss: 0.33179038893660967\n",
            "Round: 1019 Weight: [2.42150006 1.26345464] Bias: -1.0713437823366507 loss: 0.33178994646240917\n",
            "Round: 1020 Weight: [2.42167954 1.26354101] Bias: -1.0714081943587968 loss: 0.33178950643931016\n",
            "Round: 1021 Weight: [2.42185851 1.26362714] Bias: -1.0714724259979342 loss: 0.3317890688533175\n",
            "Round: 1022 Weight: [2.42203699 1.26371303] Bias: -1.0715364777952738 loss: 0.33178863369051964\n",
            "Round: 1023 Weight: [2.42221498 1.26379868] Bias: -1.0716003502901974 loss: 0.3317882009370878\n",
            "Round: 1024 Weight: [2.42239247 1.2638841 ] Bias: -1.071664044020265 loss: 0.3317877705792752\n",
            "Round: 1025 Weight: [2.42256948 1.26396928] Bias: -1.0717275595212221 loss: 0.3317873426034176\n",
            "Round: 1026 Weight: [2.42274599 1.26405422] Bias: -1.0717908973270076 loss: 0.33178691699593155\n",
            "Round: 1027 Weight: [2.42292201 1.26413893] Bias: -1.07185405796976 loss: 0.3317864937433145\n",
            "Round: 1028 Weight: [2.42309755 1.26422341] Bias: -1.0719170419798254 loss: 0.33178607283214395\n",
            "Round: 1029 Weight: [2.4232726  1.26430765] Bias: -1.0719798498857647 loss: 0.3317856542490778\n",
            "Round: 1030 Weight: [2.42344717 1.26439166] Bias: -1.0720424822143604 loss: 0.3317852379808526\n",
            "Round: 1031 Weight: [2.42362126 1.26447543] Bias: -1.0721049394906235 loss: 0.33178482401428383\n",
            "Round: 1032 Weight: [2.42379486 1.26455898] Bias: -1.0721672222378014 loss: 0.3317844123362654\n",
            "Round: 1033 Weight: [2.42396798 1.26464229] Bias: -1.0722293309773843 loss: 0.3317840029337689\n",
            "Round: 1034 Weight: [2.42414063 1.26472537] Bias: -1.0722912662291122 loss: 0.33178359579384337\n",
            "Round: 1035 Weight: [2.4243128  1.26480823] Bias: -1.0723530285109821 loss: 0.33178319090361424\n",
            "Round: 1036 Weight: [2.42448449 1.26489085] Bias: -1.072414618339255 loss: 0.33178278825028396\n",
            "Round: 1037 Weight: [2.42465571 1.26497325] Bias: -1.0724760362284629 loss: 0.3317823878211302\n",
            "Round: 1038 Weight: [2.42482645 1.26505542] Bias: -1.0725372826914148 loss: 0.33178198960350624\n",
            "Round: 1039 Weight: [2.42499672 1.26513736] Bias: -1.0725983582392047 loss: 0.3317815935848404\n",
            "Round: 1040 Weight: [2.42516653 1.26521907] Bias: -1.0726592633812178 loss: 0.3317811997526352\n",
            "Round: 1041 Weight: [2.42533586 1.26530056] Bias: -1.0727199986251372 loss: 0.33178080809446725\n",
            "Round: 1042 Weight: [2.42550473 1.26538183] Bias: -1.0727805644769512 loss: 0.33178041859798685\n",
            "Round: 1043 Weight: [2.42567313 1.26546287] Bias: -1.0728409614409595 loss: 0.33178003125091704\n",
            "Round: 1044 Weight: [2.42584107 1.26554369] Bias: -1.0729011900197798 loss: 0.3317796460410536\n",
            "Round: 1045 Weight: [2.42600854 1.26562428] Bias: -1.0729612507143547 loss: 0.3317792629562644\n",
            "Round: 1046 Weight: [2.42617555 1.26570466] Bias: -1.0730211440239583 loss: 0.33177888198448907\n",
            "Round: 1047 Weight: [2.4263421  1.26578481] Bias: -1.0730808704462027 loss: 0.33177850311373847\n",
            "Round: 1048 Weight: [2.42650819 1.26586474] Bias: -1.0731404304770447 loss: 0.331778126332094\n",
            "Round: 1049 Weight: [2.42667382 1.26594444] Bias: -1.0731998246107919 loss: 0.33177775162770823\n",
            "Round: 1050 Weight: [2.426839   1.26602393] Bias: -1.0732590533401098 loss: 0.3317773789888025\n",
            "Round: 1051 Weight: [2.42700372 1.2661032 ] Bias: -1.0733181171560278 loss: 0.33177700840366847\n",
            "Round: 1052 Weight: [2.42716798 1.26618226] Bias: -1.0733770165479457 loss: 0.3317766398606666\n",
            "Round: 1053 Weight: [2.4273318  1.26626109] Bias: -1.0734357520036402 loss: 0.33177627334822574\n",
            "Round: 1054 Weight: [2.42749516 1.26633971] Bias: -1.073494324009271 loss: 0.33177590885484337\n",
            "Round: 1055 Weight: [2.42765807 1.26641811] Bias: -1.0735527330493875 loss: 0.3317755463690845\n",
            "Round: 1056 Weight: [2.42782054 1.26649629] Bias: -1.073610979606935 loss: 0.33177518587958144\n",
            "Round: 1057 Weight: [2.42798255 1.26657426] Bias: -1.0736690641632607 loss: 0.3317748273750335\n",
            "Round: 1058 Weight: [2.42814412 1.26665202] Bias: -1.0737269871981203 loss: 0.3317744708442067\n",
            "Round: 1059 Weight: [2.42830525 1.26672956] Bias: -1.073784749189684 loss: 0.3317741162759327\n",
            "Round: 1060 Weight: [2.42846593 1.26680688] Bias: -1.0738423506145423 loss: 0.3317737636591092\n",
            "Round: 1061 Weight: [2.42862617 1.266884  ] Bias: -1.0738997919477131 loss: 0.3317734129826992\n",
            "Round: 1062 Weight: [2.42878597 1.2669609 ] Bias: -1.0739570736626474 loss: 0.33177306423573044\n",
            "Round: 1063 Weight: [2.42894533 1.26703759] Bias: -1.0740141962312346 loss: 0.3317727174072952\n",
            "Round: 1064 Weight: [2.42910425 1.26711407] Bias: -1.0740711601238098 loss: 0.3317723724865498\n",
            "Round: 1065 Weight: [2.42926273 1.26719034] Bias: -1.0741279658091591 loss: 0.3317720294627144\n",
            "Round: 1066 Weight: [2.42942078 1.2672664 ] Bias: -1.074184613754526 loss: 0.3317716883250721\n",
            "Round: 1067 Weight: [2.42957839 1.26734225] Bias: -1.0742411044256164 loss: 0.3317713490629693\n",
            "Round: 1068 Weight: [2.42973557 1.26741789] Bias: -1.0742974382866062 loss: 0.3317710116658146\n",
            "Round: 1069 Weight: [2.42989232 1.26749332] Bias: -1.0743536158001459 loss: 0.33177067612307876\n",
            "Round: 1070 Weight: [2.43004863 1.26756855] Bias: -1.0744096374273668 loss: 0.3317703424242947\n",
            "Round: 1071 Weight: [2.43020452 1.26764357] Bias: -1.0744655036278874 loss: 0.33177001055905603\n",
            "Round: 1072 Weight: [2.43035998 1.26771838] Bias: -1.0745212148598182 loss: 0.3317696805170179\n",
            "Round: 1073 Weight: [2.43051501 1.26779299] Bias: -1.0745767715797687 loss: 0.33176935228789567\n",
            "Round: 1074 Weight: [2.43066962 1.2678674 ] Bias: -1.0746321742428524 loss: 0.3317690258614652\n",
            "Round: 1075 Weight: [2.4308238  1.26794159] Bias: -1.0746874233026926 loss: 0.33176870122756213\n",
            "Round: 1076 Weight: [2.43097755 1.26801559] Bias: -1.0747425192114286 loss: 0.33176837837608136\n",
            "Round: 1077 Weight: [2.43113089 1.26808938] Bias: -1.074797462419721 loss: 0.3317680572969774\n",
            "Round: 1078 Weight: [2.4312838  1.26816297] Bias: -1.0748522533767573 loss: 0.3317677379802629\n",
            "Round: 1079 Weight: [2.4314363  1.26823636] Bias: -1.0749068925302576 loss: 0.33176742041600954\n",
            "Round: 1080 Weight: [2.43158837 1.26830954] Bias: -1.0749613803264808 loss: 0.33176710459434655\n",
            "Round: 1081 Weight: [2.43174003 1.26838253] Bias: -1.0750157172102293 loss: 0.3317667905054611\n",
            "Round: 1082 Weight: [2.43189127 1.26845531] Bias: -1.0750699036248552 loss: 0.3317664781395976\n",
            "Round: 1083 Weight: [2.4320421 1.2685279] Bias: -1.0751239400122656 loss: 0.3317661674870574\n",
            "Round: 1084 Weight: [2.43219251 1.26860029] Bias: -1.0751778268129282 loss: 0.33176585853819857\n",
            "Round: 1085 Weight: [2.43234251 1.26867247] Bias: -1.0752315644658765 loss: 0.3317655512834355\n",
            "Round: 1086 Weight: [2.4324921  1.26874446] Bias: -1.075285153408716 loss: 0.33176524571323834\n",
            "Round: 1087 Weight: [2.43264128 1.26881626] Bias: -1.0753385940776286 loss: 0.33176494181813276\n",
            "Round: 1088 Weight: [2.43279005 1.26888785] Bias: -1.075391886907379 loss: 0.3317646395887001\n",
            "Round: 1089 Weight: [2.43293841 1.26895925] Bias: -1.0754450323313196 loss: 0.3317643390155761\n",
            "Round: 1090 Weight: [2.43308637 1.26903045] Bias: -1.0754980307813955 loss: 0.33176404008945154\n",
            "Round: 1091 Weight: [2.43323392 1.26910146] Bias: -1.0755508826881508 loss: 0.33176374280107096\n",
            "Round: 1092 Weight: [2.43338107 1.26917228] Bias: -1.0756035884807333 loss: 0.33176344714123324\n",
            "Round: 1093 Weight: [2.43352781 1.2692429 ] Bias: -1.0756561485868996 loss: 0.3317631531007907\n",
            "Round: 1094 Weight: [2.43367415 1.26931332] Bias: -1.075708563433021 loss: 0.3317628606706486\n",
            "Round: 1095 Weight: [2.43382009 1.26938356] Bias: -1.075760833444088 loss: 0.33176256984176566\n",
            "Round: 1096 Weight: [2.43396563 1.2694536 ] Bias: -1.075812959043716 loss: 0.3317622806051528\n",
            "Round: 1097 Weight: [2.43411077 1.26952345] Bias: -1.0758649406541507 loss: 0.33176199295187336\n",
            "Round: 1098 Weight: [2.43425551 1.26959311] Bias: -1.0759167786962727 loss: 0.3317617068730427\n",
            "Round: 1099 Weight: [2.43439986 1.26966257] Bias: -1.075968473589603 loss: 0.33176142235982764\n",
            "Round: 1100 Weight: [2.43454382 1.26973185] Bias: -1.0760200257523078 loss: 0.3317611394034464\n",
            "Round: 1101 Weight: [2.43468737 1.26980094] Bias: -1.0760714356012044 loss: 0.3317608579951686\n",
            "Round: 1102 Weight: [2.43483054 1.26986984] Bias: -1.0761227035517653 loss: 0.3317605781263138\n",
            "Round: 1103 Weight: [2.43497332 1.26993855] Bias: -1.0761738300181236 loss: 0.3317602997882527\n",
            "Round: 1104 Weight: [2.4351157  1.27000707] Bias: -1.0762248154130785 loss: 0.3317600229724055\n",
            "Round: 1105 Weight: [2.43525769 1.2700754 ] Bias: -1.0762756601480994 loss: 0.3317597476702427\n",
            "Round: 1106 Weight: [2.4353993  1.27014355] Bias: -1.0763263646333319 loss: 0.33175947387328375\n",
            "Round: 1107 Weight: [2.43554052 1.27021151] Bias: -1.0763769292776018 loss: 0.3317592015730978\n",
            "Round: 1108 Weight: [2.43568135 1.27027929] Bias: -1.0764273544884209 loss: 0.3317589307613026\n",
            "Round: 1109 Weight: [2.4358218  1.27034688] Bias: -1.0764776406719914 loss: 0.33175866142956445\n",
            "Round: 1110 Weight: [2.43596186 1.27041429] Bias: -1.0765277882332107 loss: 0.33175839356959796\n",
            "Round: 1111 Weight: [2.43610154 1.27048151] Bias: -1.0765777975756767 loss: 0.33175812717316594\n",
            "Round: 1112 Weight: [2.43624084 1.27054855] Bias: -1.0766276691016925 loss: 0.3317578622320786\n",
            "Round: 1113 Weight: [2.43637976 1.2706154 ] Bias: -1.0766774032122708 loss: 0.3317575987381939\n",
            "Round: 1114 Weight: [2.4365183  1.27068207] Bias: -1.0767270003071394 loss: 0.3317573366834165\n",
            "Round: 1115 Weight: [2.43665646 1.27074856] Bias: -1.0767764607847456 loss: 0.3317570760596984\n",
            "Round: 1116 Weight: [2.43679424 1.27081487] Bias: -1.0768257850422611 loss: 0.3317568168590378\n",
            "Round: 1117 Weight: [2.43693165 1.270881  ] Bias: -1.0768749734755865 loss: 0.3317565590734791\n",
            "Round: 1118 Weight: [2.43706868 1.27094695] Bias: -1.0769240264793563 loss: 0.3317563026951131\n",
            "Round: 1119 Weight: [2.43720534 1.27101271] Bias: -1.0769729444469434 loss: 0.331756047716076\n",
            "Round: 1120 Weight: [2.43734162 1.2710783 ] Bias: -1.077021727770464 loss: 0.33175579412854944\n",
            "Round: 1121 Weight: [2.43747753 1.27114371] Bias: -1.0770703768407817 loss: 0.33175554192476037\n",
            "Round: 1122 Weight: [2.43761307 1.27120894] Bias: -1.077118892047513 loss: 0.3317552910969807\n",
            "Round: 1123 Weight: [2.43774825 1.27127399] Bias: -1.0771672737790314 loss: 0.33175504163752656\n",
            "Round: 1124 Weight: [2.43788305 1.27133886] Bias: -1.0772155224224722 loss: 0.33175479353875875\n",
            "Round: 1125 Weight: [2.43801748 1.27140356] Bias: -1.0772636383637366 loss: 0.33175454679308247\n",
            "Round: 1126 Weight: [2.43815155 1.27146808] Bias: -1.077311621987497 loss: 0.33175430139294576\n",
            "Round: 1127 Weight: [2.43828525 1.27153243] Bias: -1.0773594736772005 loss: 0.3317540573308413\n",
            "Round: 1128 Weight: [2.43841859 1.2715966 ] Bias: -1.0774071938150749 loss: 0.33175381459930425\n",
            "Round: 1129 Weight: [2.43855156 1.27166059] Bias: -1.0774547827821315 loss: 0.3317535731909135\n",
            "Round: 1130 Weight: [2.43868418 1.27172441] Bias: -1.0775022409581712 loss: 0.33175333309828986\n",
            "Round: 1131 Weight: [2.43881643 1.27178806] Bias: -1.0775495687217875 loss: 0.3317530943140974\n",
            "Round: 1132 Weight: [2.43894832 1.27185153] Bias: -1.077596766450372 loss: 0.3317528568310421\n",
            "Round: 1133 Weight: [2.43907985 1.27191483] Bias: -1.0776438345201185 loss: 0.33175262064187194\n",
            "Round: 1134 Weight: [2.43921102 1.27197795] Bias: -1.0776907733060268 loss: 0.33175238573937693\n",
            "Round: 1135 Weight: [2.43934183 1.27204091] Bias: -1.0777375831819083 loss: 0.33175215211638803\n",
            "Round: 1136 Weight: [2.43947229 1.27210369] Bias: -1.077784264520389 loss: 0.33175191976577784\n",
            "Round: 1137 Weight: [2.43960239 1.2721663 ] Bias: -1.077830817692915 loss: 0.3317516886804601\n",
            "Round: 1138 Weight: [2.43973214 1.27222875] Bias: -1.0778772430697559 loss: 0.33175145885338886\n",
            "Round: 1139 Weight: [2.43986153 1.27229102] Bias: -1.0779235410200096 loss: 0.33175123027755904\n",
            "Round: 1140 Weight: [2.43999057 1.27235312] Bias: -1.077969711911607 loss: 0.3317510029460056\n",
            "Round: 1141 Weight: [2.44011926 1.27241505] Bias: -1.0780157561113148 loss: 0.3317507768518036\n",
            "Round: 1142 Weight: [2.44024761 1.27247682] Bias: -1.0780616739847415 loss: 0.3317505519880679\n",
            "Round: 1143 Weight: [2.4403756  1.27253841] Bias: -1.0781074658963403 loss: 0.3317503283479529\n",
            "Round: 1144 Weight: [2.44050324 1.27259984] Bias: -1.0781531322094142 loss: 0.3317501059246522\n",
            "Round: 1145 Weight: [2.44063053 1.2726611 ] Bias: -1.0781986732861195 loss: 0.3317498847113987\n",
            "Round: 1146 Weight: [2.44075748 1.2727222 ] Bias: -1.0782440894874705 loss: 0.3317496647014639\n",
            "Round: 1147 Weight: [2.44088409 1.27278313] Bias: -1.0782893811733434 loss: 0.331749445888158\n",
            "Round: 1148 Weight: [2.44101034 1.27284389] Bias: -1.0783345487024802 loss: 0.3317492282648296\n",
            "Round: 1149 Weight: [2.44113626 1.27290449] Bias: -1.0783795924324933 loss: 0.3317490118248653\n",
            "Round: 1150 Weight: [2.44126183 1.27296492] Bias: -1.0784245127198693 loss: 0.33174879656168976\n",
            "Round: 1151 Weight: [2.44138706 1.27302519] Bias: -1.0784693099199731 loss: 0.3317485824687654\n",
            "Round: 1152 Weight: [2.44151195 1.27308529] Bias: -1.0785139843870524 loss: 0.33174836953959186\n",
            "Round: 1153 Weight: [2.44163651 1.27314523] Bias: -1.0785585364742407 loss: 0.3317481577677062\n",
            "Round: 1154 Weight: [2.44176072 1.27320501] Bias: -1.0786029665335624 loss: 0.33174794714668226\n",
            "Round: 1155 Weight: [2.44188459 1.27326463] Bias: -1.0786472749159361 loss: 0.33174773767013105\n",
            "Round: 1156 Weight: [2.44200813 1.27332408] Bias: -1.0786914619711792 loss: 0.3317475293316999\n",
            "Round: 1157 Weight: [2.44213133 1.27338337] Bias: -1.0787355280480113 loss: 0.3317473221250725\n",
            "Round: 1158 Weight: [2.4422542 1.2734425] Bias: -1.0787794734940586 loss: 0.33174711604396867\n",
            "Round: 1159 Weight: [2.44237673 1.27350147] Bias: -1.0788232986558572 loss: 0.3317469110821444\n",
            "Round: 1160 Weight: [2.44249894 1.27356028] Bias: -1.0788670038788584 loss: 0.3317467072333907\n",
            "Round: 1161 Weight: [2.4426208  1.27361893] Bias: -1.0789105895074305 loss: 0.3317465044915352\n",
            "Round: 1162 Weight: [2.44274234 1.27367743] Bias: -1.0789540558848645 loss: 0.33174630285043966\n",
            "Round: 1163 Weight: [2.44286355 1.27373576] Bias: -1.0789974033533773 loss: 0.3317461023040017\n",
            "Round: 1164 Weight: [2.44298443 1.27379393] Bias: -1.0790406322541157 loss: 0.33174590284615346\n",
            "Round: 1165 Weight: [2.44310498 1.27385195] Bias: -1.0790837429271598 loss: 0.3317457044708617\n",
            "Round: 1166 Weight: [2.4432252  1.27390981] Bias: -1.0791267357115273 loss: 0.3317455071721279\n",
            "Round: 1167 Weight: [2.4433451  1.27396751] Bias: -1.079169610945177 loss: 0.3317453109439874\n",
            "Round: 1168 Weight: [2.44346467 1.27402505] Bias: -1.0792123689650128 loss: 0.3317451157805099\n",
            "Round: 1169 Weight: [2.44358392 1.27408244] Bias: -1.0792550101068878 loss: 0.33174492167579894\n",
            "Round: 1170 Weight: [2.44370284 1.27413967] Bias: -1.079297534705607 loss: 0.3317447286239914\n",
            "Round: 1171 Weight: [2.44382144 1.27419675] Bias: -1.0793399430949324 loss: 0.331744536619258\n",
            "Round: 1172 Weight: [2.44393972 1.27425367] Bias: -1.0793822356075853 loss: 0.33174434565580224\n",
            "Round: 1173 Weight: [2.44405767 1.27431044] Bias: -1.0794244125752512 loss: 0.33174415572786103\n",
            "Round: 1174 Weight: [2.44417531 1.27436705] Bias: -1.079466474328583 loss: 0.33174396682970403\n",
            "Round: 1175 Weight: [2.44429263 1.27442351] Bias: -1.0795084211972044 loss: 0.33174377895563334\n",
            "Round: 1176 Weight: [2.44440963 1.27447982] Bias: -1.0795502535097143 loss: 0.33174359209998383\n",
            "Round: 1177 Weight: [2.44452631 1.27453598] Bias: -1.0795919715936901 loss: 0.3317434062571226\n",
            "Round: 1178 Weight: [2.44464268 1.27459198] Bias: -1.0796335757756907 loss: 0.3317432214214486\n",
            "Round: 1179 Weight: [2.44475873 1.27464783] Bias: -1.0796750663812609 loss: 0.33174303758739265\n",
            "Round: 1180 Weight: [2.44487447 1.27470353] Bias: -1.0797164437349347 loss: 0.33174285474941767\n",
            "Round: 1181 Weight: [2.44498989 1.27475908] Bias: -1.0797577081602392 loss: 0.3317426729020176\n",
            "Round: 1182 Weight: [2.445105   1.27481447] Bias: -1.0797988599796977 loss: 0.33174249203971795\n",
            "Round: 1183 Weight: [2.4452198  1.27486972] Bias: -1.0798398995148335 loss: 0.3317423121570754\n",
            "Round: 1184 Weight: [2.44533429 1.27492482] Bias: -1.0798808270861733 loss: 0.33174213324867724\n",
            "Round: 1185 Weight: [2.44544846 1.27497977] Bias: -1.079921643013251 loss: 0.3317419553091423\n",
            "Round: 1186 Weight: [2.44556233 1.27503457] Bias: -1.0799623476146112 loss: 0.33174177833311896\n",
            "Round: 1187 Weight: [2.44567589 1.27508922] Bias: -1.080002941207812 loss: 0.33174160231528677\n",
            "Round: 1188 Weight: [2.44578914 1.27514372] Bias: -1.0800434241094294 loss: 0.33174142725035516\n",
            "Round: 1189 Weight: [2.44590209 1.27519808] Bias: -1.0800837966350605 loss: 0.33174125313306374\n",
            "Round: 1190 Weight: [2.44601472 1.27525229] Bias: -1.0801240590993264 loss: 0.331741079958182\n",
            "Round: 1191 Weight: [2.44612706 1.27530635] Bias: -1.0801642118158763 loss: 0.331740907720509\n",
            "Round: 1192 Weight: [2.44623909 1.27536026] Bias: -1.0802042550973907 loss: 0.33174073641487345\n",
            "Round: 1193 Weight: [2.44635081 1.27541403] Bias: -1.080244189255585 loss: 0.3317405660361332\n",
            "Round: 1194 Weight: [2.44646224 1.27546766] Bias: -1.080284014601212 loss: 0.3317403965791756\n",
            "Round: 1195 Weight: [2.44657336 1.27552113] Bias: -1.0803237314440668 loss: 0.3317402280389165\n",
            "Round: 1196 Weight: [2.44668418 1.27557447] Bias: -1.0803633400929888 loss: 0.3317400604103013\n",
            "Round: 1197 Weight: [2.4467947  1.27562766] Bias: -1.080402840855866 loss: 0.33173989368830337\n",
            "Round: 1198 Weight: [2.44690493 1.2756807 ] Bias: -1.0804422340396371 loss: 0.3317397278679246\n",
            "Round: 1199 Weight: [2.44701485 1.27573361] Bias: -1.0804815199502966 loss: 0.3317395629441959\n",
            "Round: 1200 Weight: [2.44712448 1.27578636] Bias: -1.0805206988928964 loss: 0.3317393989121757\n",
            "Round: 1201 Weight: [2.44723381 1.27583898] Bias: -1.0805597711715502 loss: 0.3317392357669504\n",
            "Round: 1202 Weight: [2.44734284 1.27589146] Bias: -1.0805987370894365 loss: 0.33173907350363446\n",
            "Round: 1203 Weight: [2.44745158 1.27594379] Bias: -1.0806375969488018 loss: 0.33173891211737\n",
            "Round: 1204 Weight: [2.44756003 1.27599598] Bias: -1.0806763510509634 loss: 0.3317387516033267\n",
            "Round: 1205 Weight: [2.44766818 1.27604803] Bias: -1.0807149996963135 loss: 0.33173859195670125\n",
            "Round: 1206 Weight: [2.44777604 1.27609994] Bias: -1.080753543184322 loss: 0.33173843317271773\n",
            "Round: 1207 Weight: [2.44788361 1.2761517 ] Bias: -1.0807919818135396 loss: 0.33173827524662725\n",
            "Round: 1208 Weight: [2.44799089 1.27620333] Bias: -1.080830315881601 loss: 0.33173811817370774\n",
            "Round: 1209 Weight: [2.44809788 1.27625482] Bias: -1.0808685456852285 loss: 0.33173796194926375\n",
            "Round: 1210 Weight: [2.44820458 1.27630617] Bias: -1.0809066715202347 loss: 0.33173780656862667\n",
            "Round: 1211 Weight: [2.44831099 1.27635738] Bias: -1.0809446936815257 loss: 0.3317376520271537\n",
            "Round: 1212 Weight: [2.44841711 1.27640846] Bias: -1.0809826124631048 loss: 0.331737498320229\n",
            "Round: 1213 Weight: [2.44852295 1.27645939] Bias: -1.0810204281580749 loss: 0.3317373454432621\n",
            "Round: 1214 Weight: [2.4486285  1.27651019] Bias: -1.0810581410586422 loss: 0.331737193391689\n",
            "Round: 1215 Weight: [2.44873376 1.27656085] Bias: -1.0810957514561188 loss: 0.3317370421609711\n",
            "Round: 1216 Weight: [2.44883875 1.27661137] Bias: -1.0811332596409262 loss: 0.33173689174659565\n",
            "Round: 1217 Weight: [2.44894344 1.27666176] Bias: -1.0811706659025981 loss: 0.33173674214407534\n",
            "Round: 1218 Weight: [2.44904786 1.27671201] Bias: -1.081207970529784 loss: 0.33173659334894806\n",
            "Round: 1219 Weight: [2.44915199 1.27676212] Bias: -1.081245173810251 loss: 0.33173644535677693\n",
            "Round: 1220 Weight: [2.44925584 1.2768121 ] Bias: -1.0812822760308891 loss: 0.3317362981631502\n",
            "Round: 1221 Weight: [2.44935941 1.27686195] Bias: -1.0813192774777114 loss: 0.3317361517636808\n",
            "Round: 1222 Weight: [2.44946271 1.27691166] Bias: -1.0813561784358594 loss: 0.3317360061540066\n",
            "Round: 1223 Weight: [2.44956572 1.27696123] Bias: -1.081392979189605 loss: 0.3317358613297899\n",
            "Round: 1224 Weight: [2.44966845 1.27701068] Bias: -1.081429680022354 loss: 0.3317357172867174\n",
            "Round: 1225 Weight: [2.44977091 1.27705999] Bias: -1.0814662812166478 loss: 0.3317355740205005\n",
            "Round: 1226 Weight: [2.44987309 1.27710916] Bias: -1.0815027830541684 loss: 0.33173543152687435\n",
            "Round: 1227 Weight: [2.449975  1.2771582] Bias: -1.0815391858157395 loss: 0.3317352898015981\n",
            "Round: 1228 Weight: [2.45007663 1.27720712] Bias: -1.0815754897813308 loss: 0.3317351488404551\n",
            "Round: 1229 Weight: [2.45017799 1.27725589] Bias: -1.08161169523006 loss: 0.3317350086392521\n",
            "Round: 1230 Weight: [2.45027907 1.27730454] Bias: -1.0816478024401965 loss: 0.3317348691938198\n",
            "Round: 1231 Weight: [2.45037988 1.27735306] Bias: -1.0816838116891634 loss: 0.33173473050001195\n",
            "Round: 1232 Weight: [2.45048042 1.27740144] Bias: -1.0817197232535412 loss: 0.331734592553706\n",
            "Round: 1233 Weight: [2.45058069 1.2774497 ] Bias: -1.0817555374090702 loss: 0.3317344553508026\n",
            "Round: 1234 Weight: [2.45068068 1.27749782] Bias: -1.0817912544306538 loss: 0.3317343188872249\n",
            "Round: 1235 Weight: [2.45078041 1.27754582] Bias: -1.0818268745923612 loss: 0.33173418315891967\n",
            "Round: 1236 Weight: [2.45087987 1.27759368] Bias: -1.0818623981674298 loss: 0.3317340481618562\n",
            "Round: 1237 Weight: [2.45097906 1.27764142] Bias: -1.081897825428269 loss: 0.3317339138920261\n",
            "Round: 1238 Weight: [2.45107799 1.27768903] Bias: -1.0819331566464618 loss: 0.33173378034544404\n",
            "Round: 1239 Weight: [2.45117664 1.27773651] Bias: -1.0819683920927687 loss: 0.331733647518147\n",
            "Round: 1240 Weight: [2.45127503 1.27778386] Bias: -1.0820035320371302 loss: 0.33173351540619367\n",
            "Round: 1241 Weight: [2.45137316 1.27783108] Bias: -1.0820385767486689 loss: 0.33173338400566543\n",
            "Round: 1242 Weight: [2.45147102 1.27787818] Bias: -1.0820735264956935 loss: 0.3317332533126658\n",
            "Round: 1243 Weight: [2.45156862 1.27792515] Bias: -1.0821083815457009 loss: 0.3317331233233195\n",
            "Round: 1244 Weight: [2.45166595 1.27797199] Bias: -1.0821431421653784 loss: 0.33173299403377354\n",
            "Round: 1245 Weight: [2.45176303 1.27801871] Bias: -1.0821778086206078 loss: 0.33173286544019637\n",
            "Round: 1246 Weight: [2.45185984 1.2780653 ] Bias: -1.0822123811764668 loss: 0.33173273753877797\n",
            "Round: 1247 Weight: [2.45195639 1.27811177] Bias: -1.0822468600972328 loss: 0.3317326103257297\n",
            "Round: 1248 Weight: [2.45205268 1.27815811] Bias: -1.0822812456463848 loss: 0.3317324837972841\n",
            "Round: 1249 Weight: [2.45214871 1.27820432] Bias: -1.0823155380866067 loss: 0.331732357949695\n",
            "Round: 1250 Weight: [2.45224448 1.27825042] Bias: -1.0823497376797897 loss: 0.3317322327792371\n",
            "Round: 1251 Weight: [2.45234    1.27829638] Bias: -1.082383844687035 loss: 0.33173210828220573\n",
            "Round: 1252 Weight: [2.45243526 1.27834223] Bias: -1.0824178593686564 loss: 0.3317319844549176\n",
            "Round: 1253 Weight: [2.45253026 1.27838795] Bias: -1.0824517819841832 loss: 0.33173186129370946\n",
            "Round: 1254 Weight: [2.452625   1.27843354] Bias: -1.082485612792363 loss: 0.33173173879493895\n",
            "Round: 1255 Weight: [2.4527195  1.27847902] Bias: -1.0825193520511633 loss: 0.331731616954984\n",
            "Round: 1256 Weight: [2.45281373 1.27852437] Bias: -1.0825530000177759 loss: 0.33173149577024263\n",
            "Round: 1257 Weight: [2.45290771 1.2785696 ] Bias: -1.0825865569486177 loss: 0.3317313752371335\n",
            "Round: 1258 Weight: [2.45300145 1.27861471] Bias: -1.0826200230993348 loss: 0.33173125535209463\n",
            "Round: 1259 Weight: [2.45309492 1.2786597 ] Bias: -1.082653398724804 loss: 0.3317311361115848\n",
            "Round: 1260 Weight: [2.45318815 1.27870456] Bias: -1.0826866840791358 loss: 0.3317310175120818\n",
            "Round: 1261 Weight: [2.45328113 1.27874931] Bias: -1.0827198794156774 loss: 0.33173089955008367\n",
            "Round: 1262 Weight: [2.45337385 1.27879393] Bias: -1.0827529849870146 loss: 0.33173078222210783\n",
            "Round: 1263 Weight: [2.45346633 1.27883844] Bias: -1.0827860010449748 loss: 0.3317306655246912\n",
            "Round: 1264 Weight: [2.45355856 1.27888283] Bias: -1.0828189278406295 loss: 0.3317305494543901\n",
            "Round: 1265 Weight: [2.45365054 1.27892709] Bias: -1.0828517656242964 loss: 0.33173043400777996\n",
            "Round: 1266 Weight: [2.45374227 1.27897124] Bias: -1.0828845146455426 loss: 0.3317303191814555\n",
            "Round: 1267 Weight: [2.45383375 1.27901527] Bias: -1.0829171751531865 loss: 0.3317302049720305\n",
            "Round: 1268 Weight: [2.45392499 1.27905918] Bias: -1.0829497473953011 loss: 0.33173009137613746\n",
            "Round: 1269 Weight: [2.45401599 1.27910297] Bias: -1.0829822316192155 loss: 0.3317299783904279\n",
            "Round: 1270 Weight: [2.45410674 1.27914664] Bias: -1.083014628071518 loss: 0.3317298660115719\n",
            "Round: 1271 Weight: [2.45419725 1.2791902 ] Bias: -1.0830469369980589 loss: 0.3317297542362582\n",
            "Round: 1272 Weight: [2.45428751 1.27923364] Bias: -1.0830791586439519 loss: 0.331729643061194\n",
            "Round: 1273 Weight: [2.45437753 1.27927696] Bias: -1.0831112932535776 loss: 0.3317295324831049\n",
            "Round: 1274 Weight: [2.45446731 1.27932017] Bias: -1.0831433410705855 loss: 0.33172942249873477\n",
            "Round: 1275 Weight: [2.45455684 1.27936326] Bias: -1.0831753023378967 loss: 0.33172931310484566\n",
            "Round: 1276 Weight: [2.45464614 1.27940624] Bias: -1.0832071772977059 loss: 0.3317292042982176\n",
            "Round: 1277 Weight: [2.4547352 1.2794491] Bias: -1.083238966191484 loss: 0.33172909607564866\n",
            "Round: 1278 Weight: [2.45482402 1.27949184] Bias: -1.083270669259981 loss: 0.3317289884339548\n",
            "Round: 1279 Weight: [2.4549126  1.27953447] Bias: -1.0833022867432274 loss: 0.33172888136996964\n",
            "Round: 1280 Weight: [2.45500094 1.27957699] Bias: -1.0833338188805375 loss: 0.3317287748805444\n",
            "Round: 1281 Weight: [2.45508904 1.27961939] Bias: -1.0833652659105115 loss: 0.33172866896254816\n",
            "Round: 1282 Weight: [2.45517691 1.27966167] Bias: -1.083396628071038 loss: 0.3317285636128671\n",
            "Round: 1283 Weight: [2.45526454 1.27970385] Bias: -1.083427905599296 loss: 0.33172845882840485\n",
            "Round: 1284 Weight: [2.45535194 1.27974591] Bias: -1.0834590987317572 loss: 0.33172835460608235\n",
            "Round: 1285 Weight: [2.4554391  1.27978786] Bias: -1.083490207704189 loss: 0.33172825094283775\n",
            "Round: 1286 Weight: [2.45552603 1.27982969] Bias: -1.0835212327516566 loss: 0.33172814783562593\n",
            "Round: 1287 Weight: [2.45561272 1.27987141] Bias: -1.0835521741085246 loss: 0.33172804528141914\n",
            "Round: 1288 Weight: [2.45569919 1.27991302] Bias: -1.0835830320084605 loss: 0.3317279432772062\n",
            "Round: 1289 Weight: [2.45578542 1.27995452] Bias: -1.083613806684436 loss: 0.3317278418199929\n",
            "Round: 1290 Weight: [2.45587141 1.27999591] Bias: -1.0836444983687303 loss: 0.3317277409068014\n",
            "Round: 1291 Weight: [2.45595718 1.28003719] Bias: -1.0836751072929312 loss: 0.33172764053467074\n",
            "Round: 1292 Weight: [2.45604272 1.28007835] Bias: -1.083705633687938 loss: 0.33172754070065613\n",
            "Round: 1293 Weight: [2.45612803 1.28011941] Bias: -1.0837360777839644 loss: 0.3317274414018295\n",
            "Round: 1294 Weight: [2.45621311 1.28016035] Bias: -1.0837664398105398 loss: 0.3317273426352788\n",
            "Round: 1295 Weight: [2.45629796 1.28020119] Bias: -1.0837967199965117 loss: 0.3317272443981083\n",
            "Round: 1296 Weight: [2.45638258 1.28024192] Bias: -1.0838269185700486 loss: 0.33172714668743825\n",
            "Round: 1297 Weight: [2.45646698 1.28028253] Bias: -1.0838570357586415 loss: 0.33172704950040505\n",
            "Round: 1298 Weight: [2.45655115 1.28032304] Bias: -1.0838870717891065 loss: 0.3317269528341608\n",
            "Round: 1299 Weight: [2.4566351  1.28036344] Bias: -1.083917026887587 loss: 0.33172685668587365\n",
            "Round: 1300 Weight: [2.45671882 1.28040373] Bias: -1.0839469012795562 loss: 0.3317267610527274\n",
            "Round: 1301 Weight: [2.45680231 1.28044391] Bias: -1.0839766951898184 loss: 0.3317266659319215\n",
            "Round: 1302 Weight: [2.45688558 1.28048399] Bias: -1.084006408842512 loss: 0.33172657132067085\n",
            "Round: 1303 Weight: [2.45696863 1.28052396] Bias: -1.084036042461112 loss: 0.3317264772162059\n",
            "Round: 1304 Weight: [2.45705146 1.28056382] Bias: -1.0840655962684307 loss: 0.33172638361577267\n",
            "Round: 1305 Weight: [2.45713406 1.28060357] Bias: -1.0840950704866217 loss: 0.33172629051663194\n",
            "Round: 1306 Weight: [2.45721644 1.28064322] Bias: -1.0841244653371809 loss: 0.3317261979160602\n",
            "Round: 1307 Weight: [2.4572986  1.28068276] Bias: -1.084153781040949 loss: 0.33172610581134887\n",
            "Round: 1308 Weight: [2.45738055 1.2807222 ] Bias: -1.0841830178181133 loss: 0.33172601419980435\n",
            "Round: 1309 Weight: [2.45746227 1.28076152] Bias: -1.0842121758882106 loss: 0.33172592307874793\n",
            "Round: 1310 Weight: [2.45754377 1.28080075] Bias: -1.0842412554701288 loss: 0.331725832445516\n",
            "Round: 1311 Weight: [2.45762506 1.28083987] Bias: -1.084270256782109 loss: 0.3317257422974596\n",
            "Round: 1312 Weight: [2.45770612 1.28087888] Bias: -1.0842991800417476 loss: 0.3317256526319443\n",
            "Round: 1313 Weight: [2.45778697 1.28091779] Bias: -1.084328025465999 loss: 0.3317255634463503\n",
            "Round: 1314 Weight: [2.45786761 1.2809566 ] Bias: -1.0843567932711768 loss: 0.3317254747380727\n",
            "Round: 1315 Weight: [2.45794802 1.2809953 ] Bias: -1.0843854836729567 loss: 0.3317253865045204\n",
            "Round: 1316 Weight: [2.45802823 1.2810339 ] Bias: -1.0844140968863778 loss: 0.3317252987431172\n",
            "Round: 1317 Weight: [2.45810821 1.28107239] Bias: -1.0844426331258454 loss: 0.3317252114513009\n",
            "Round: 1318 Weight: [2.45818799 1.28111078] Bias: -1.0844710926051329 loss: 0.3317251246265236\n",
            "Round: 1319 Weight: [2.45826755 1.28114907] Bias: -1.0844994755373831 loss: 0.33172503826625144\n",
            "Round: 1320 Weight: [2.45834689 1.28118726] Bias: -1.0845277821351116 loss: 0.3317249523679646\n",
            "Round: 1321 Weight: [2.45842603 1.28122534] Bias: -1.0845560126102078 loss: 0.33172486692915726\n",
            "Round: 1322 Weight: [2.45850495 1.28126332] Bias: -1.0845841671739374 loss: 0.33172478194733745\n",
            "Round: 1323 Weight: [2.45858366 1.2813012 ] Bias: -1.084612246036944 loss: 0.33172469742002686\n",
            "Round: 1324 Weight: [2.45866216 1.28133898] Bias: -1.0846402494092517 loss: 0.3317246133447611\n",
            "Round: 1325 Weight: [2.45874045 1.28137666] Bias: -1.084668177500267 loss: 0.3317245297190892\n",
            "Round: 1326 Weight: [2.45881853 1.28141424] Bias: -1.08469603051878 loss: 0.33172444654057404\n",
            "Round: 1327 Weight: [2.4588964  1.28145172] Bias: -1.0847238086729678 loss: 0.33172436380679166\n",
            "Round: 1328 Weight: [2.45897407 1.28148909] Bias: -1.0847515121703952 loss: 0.33172428151533173\n",
            "Round: 1329 Weight: [2.45905152 1.28152637] Bias: -1.0847791412180177 loss: 0.331724199663797\n",
            "Round: 1330 Weight: [2.45912877 1.28156354] Bias: -1.0848066960221825 loss: 0.3317241182498038\n",
            "Round: 1331 Weight: [2.45920581 1.28160062] Bias: -1.0848341767886311 loss: 0.3317240372709815\n",
            "Round: 1332 Weight: [2.45928265 1.2816376 ] Bias: -1.0848615837225015 loss: 0.33172395672497224\n",
            "Round: 1333 Weight: [2.45935928 1.28167448] Bias: -1.0848889170283293 loss: 0.33172387660943164\n",
            "Round: 1334 Weight: [2.45943571 1.28171126] Bias: -1.0849161769100506 loss: 0.3317237969220282\n",
            "Round: 1335 Weight: [2.45951193 1.28174794] Bias: -1.0849433635710029 loss: 0.33172371766044306\n",
            "Round: 1336 Weight: [2.45958795 1.28178453] Bias: -1.0849704772139281 loss: 0.3317236388223704\n",
            "Round: 1337 Weight: [2.45966376 1.28182101] Bias: -1.0849975180409739 loss: 0.33172356040551704\n",
            "Round: 1338 Weight: [2.45973937 1.2818574 ] Bias: -1.0850244862536955 loss: 0.33172348240760235\n",
            "Round: 1339 Weight: [2.45981478 1.28189369] Bias: -1.085051382053058 loss: 0.3317234048263585\n",
            "Round: 1340 Weight: [2.45988999 1.28192989] Bias: -1.085078205639438 loss: 0.3317233276595301\n",
            "Round: 1341 Weight: [2.45996499 1.28196598] Bias: -1.0851049572126252 loss: 0.331723250904874\n",
            "Round: 1342 Weight: [2.4600398  1.28200199] Bias: -1.0851316369718256 loss: 0.3317231745601598\n",
            "Round: 1343 Weight: [2.46011441 1.28203789] Bias: -1.0851582451156616 loss: 0.3317230986231691\n",
            "Round: 1344 Weight: [2.46018881 1.2820737 ] Bias: -1.085184781842175 loss: 0.33172302309169593\n",
            "Round: 1345 Weight: [2.46026302 1.28210941] Bias: -1.0852112473488285 loss: 0.33172294796354623\n",
            "Round: 1346 Weight: [2.46033703 1.28214503] Bias: -1.0852376418325078 loss: 0.3317228732365385\n",
            "Round: 1347 Weight: [2.46041084 1.28218055] Bias: -1.0852639654895233 loss: 0.33172279890850265\n",
            "Round: 1348 Weight: [2.46048446 1.28221598] Bias: -1.085290218515612 loss: 0.33172272497728095\n",
            "Round: 1349 Weight: [2.46055788 1.28225131] Bias: -1.085316401105939 loss: 0.3317226514407276\n",
            "Round: 1350 Weight: [2.4606311  1.28228655] Bias: -1.0853425134551 loss: 0.33172257829670837\n",
            "Round: 1351 Weight: [2.46070413 1.2823217 ] Bias: -1.0853685557571227 loss: 0.3317225055431011\n",
            "Round: 1352 Weight: [2.46077696 1.28235675] Bias: -1.0853945282054684 loss: 0.33172243317779504\n",
            "Round: 1353 Weight: [2.46084959 1.2823917 ] Bias: -1.0854204309930346 loss: 0.33172236119869114\n",
            "Round: 1354 Weight: [2.46092204 1.28242657] Bias: -1.0854462643121559 loss: 0.331722289603702\n",
            "Round: 1355 Weight: [2.46099429 1.28246134] Bias: -1.0854720283546062 loss: 0.3317222183907516\n",
            "Round: 1356 Weight: [2.46106634 1.28249602] Bias: -1.0854977233116008 loss: 0.3317221475577754\n",
            "Round: 1357 Weight: [2.46113821 1.2825306 ] Bias: -1.0855233493737977 loss: 0.33172207710272034\n",
            "Round: 1358 Weight: [2.46120988 1.28256509] Bias: -1.0855489067312996 loss: 0.33172200702354443\n",
            "Round: 1359 Weight: [2.46128136 1.2825995 ] Bias: -1.0855743955736559 loss: 0.33172193731821714\n",
            "Round: 1360 Weight: [2.46135265 1.2826338 ] Bias: -1.0855998160898637 loss: 0.331721867984719\n",
            "Round: 1361 Weight: [2.46142375 1.28266802] Bias: -1.0856251684683706 loss: 0.3317217990210416\n",
            "Round: 1362 Weight: [2.46149466 1.28270215] Bias: -1.0856504528970758 loss: 0.33172173042518743\n",
            "Round: 1363 Weight: [2.46156538 1.28273618] Bias: -1.0856756695633318 loss: 0.33172166219517063\n",
            "Round: 1364 Weight: [2.46163591 1.28277013] Bias: -1.0857008186539465 loss: 0.3317215943290155\n",
            "Round: 1365 Weight: [2.46170626 1.28280398] Bias: -1.0857259003551847 loss: 0.3317215268247574\n",
            "Round: 1366 Weight: [2.46177641 1.28283774] Bias: -1.0857509148527698 loss: 0.3317214596804429\n",
            "Round: 1367 Weight: [2.46184638 1.28287142] Bias: -1.0857758623318858 loss: 0.33172139289412883\n",
            "Round: 1368 Weight: [2.46191616 1.282905  ] Bias: -1.085800742977179 loss: 0.3317213264638829\n",
            "Round: 1369 Weight: [2.46198576 1.28293849] Bias: -1.0858255569727593 loss: 0.33172126038778343\n",
            "Round: 1370 Weight: [2.46205517 1.2829719 ] Bias: -1.085850304502202 loss: 0.3317211946639192\n",
            "Round: 1371 Weight: [2.4621244  1.28300521] Bias: -1.0858749857485503 loss: 0.33172112929038966\n",
            "Round: 1372 Weight: [2.46219344 1.28303844] Bias: -1.0858996008943156 loss: 0.3317210642653045\n",
            "Round: 1373 Weight: [2.46226229 1.28307158] Bias: -1.0859241501214802 loss: 0.33172099958678397\n",
            "Round: 1374 Weight: [2.46233097 1.28310463] Bias: -1.085948633611499 loss: 0.3317209352529586\n",
            "Round: 1375 Weight: [2.46239946 1.28313759] Bias: -1.0859730515453005 loss: 0.33172087126196914\n",
            "Round: 1376 Weight: [2.46246776 1.28317046] Bias: -1.0859974041032892 loss: 0.33172080761196643\n",
            "Round: 1377 Weight: [2.46253589 1.28320325] Bias: -1.0860216914653464 loss: 0.3317207443011117\n",
            "Round: 1378 Weight: [2.46260383 1.28323594] Bias: -1.086045913810833 loss: 0.3317206813275762\n",
            "Round: 1379 Weight: [2.46267159 1.28326856] Bias: -1.08607007131859 loss: 0.33172061868954106\n",
            "Round: 1380 Weight: [2.46273917 1.28330108] Bias: -1.0860941641669413 loss: 0.33172055638519754\n",
            "Round: 1381 Weight: [2.46280658 1.28333352] Bias: -1.086118192533694 loss: 0.3317204944127469\n",
            "Round: 1382 Weight: [2.4628738  1.28336587] Bias: -1.086142156596141 loss: 0.33172043277039986\n",
            "Round: 1383 Weight: [2.46294084 1.28339813] Bias: -1.086166056531063 loss: 0.3317203714563776\n",
            "Round: 1384 Weight: [2.4630077  1.28343031] Bias: -1.0861898925147282 loss: 0.3317203104689105\n",
            "Round: 1385 Weight: [2.46307439 1.2834624 ] Bias: -1.0862136647228964 loss: 0.33172024980623877\n",
            "Round: 1386 Weight: [2.4631409  1.28349441] Bias: -1.0862373733308186 loss: 0.3317201894666124\n",
            "Round: 1387 Weight: [2.46320723 1.28352633] Bias: -1.08626101851324 loss: 0.33172012944829105\n",
            "Round: 1388 Weight: [2.46327338 1.28355817] Bias: -1.0862846004444007 loss: 0.3317200697495437\n",
            "Round: 1389 Weight: [2.46333936 1.28358992] Bias: -1.0863081192980375 loss: 0.33172001036864873\n",
            "Round: 1390 Weight: [2.46340516 1.28362159] Bias: -1.086331575247386 loss: 0.33171995130389426\n",
            "Round: 1391 Weight: [2.46347079 1.28365317] Bias: -1.0863549684651816 loss: 0.3317198925535777\n",
            "Round: 1392 Weight: [2.46353624 1.28368467] Bias: -1.0863782991236608 loss: 0.3317198341160056\n",
            "Round: 1393 Weight: [2.46360151 1.28371609] Bias: -1.0864015673945637 loss: 0.33171977598949404\n",
            "Round: 1394 Weight: [2.46366662 1.28374742] Bias: -1.086424773449135 loss: 0.33171971817236806\n",
            "Round: 1395 Weight: [2.46373155 1.28377867] Bias: -1.0864479174581256 loss: 0.331719660662962\n",
            "Round: 1396 Weight: [2.4637963  1.28380983] Bias: -1.086470999591794 loss: 0.33171960345961937\n",
            "Round: 1397 Weight: [2.46386089 1.28384091] Bias: -1.0864940200199085 loss: 0.33171954656069275\n",
            "Round: 1398 Weight: [2.4639253  1.28387191] Bias: -1.0865169789117475 loss: 0.33171948996454365\n",
            "Round: 1399 Weight: [2.46398954 1.28390283] Bias: -1.0865398764361025 loss: 0.33171943366954254\n",
            "Round: 1400 Weight: [2.46405361 1.28393366] Bias: -1.0865627127612787 loss: 0.33171937767406895\n",
            "Round: 1401 Weight: [2.46411751 1.28396441] Bias: -1.086585488055097 loss: 0.33171932197651094\n",
            "Round: 1402 Weight: [2.46418124 1.28399508] Bias: -1.0866082024848944 loss: 0.3317192665752659\n",
            "Round: 1403 Weight: [2.4642448  1.28402567] Bias: -1.0866308562175275 loss: 0.33171921146873956\n",
            "Round: 1404 Weight: [2.46430819 1.28405618] Bias: -1.0866534494193723 loss: 0.3317191566553466\n",
            "Round: 1405 Weight: [2.46437141 1.28408661] Bias: -1.0866759822563263 loss: 0.3317191021335102\n",
            "Round: 1406 Weight: [2.46443446 1.28411695] Bias: -1.0866984548938103 loss: 0.33171904790166223\n",
            "Round: 1407 Weight: [2.46449735 1.28414721] Bias: -1.0867208674967694 loss: 0.3317189939582432\n",
            "Round: 1408 Weight: [2.46456007 1.2841774 ] Bias: -1.0867432202296745 loss: 0.331718940301702\n",
            "Round: 1409 Weight: [2.46462262 1.2842075 ] Bias: -1.0867655132565242 loss: 0.33171888693049634\n",
            "Round: 1410 Weight: [2.464685   1.28423752] Bias: -1.0867877467408458 loss: 0.33171883384309175\n",
            "Round: 1411 Weight: [2.46474722 1.28426747] Bias: -1.0868099208456974 loss: 0.33171878103796276\n",
            "Round: 1412 Weight: [2.46480928 1.28429733] Bias: -1.0868320357336687 loss: 0.33171872851359174\n",
            "Round: 1413 Weight: [2.46487116 1.28432711] Bias: -1.0868540915668827 loss: 0.3317186762684698\n",
            "Round: 1414 Weight: [2.46493289 1.28435682] Bias: -1.0868760885069972 loss: 0.3317186243010961\n",
            "Round: 1415 Weight: [2.46499445 1.28438644] Bias: -1.0868980267152064 loss: 0.3317185726099778\n",
            "Round: 1416 Weight: [2.46505584 1.28441599] Bias: -1.0869199063522421 loss: 0.33171852119363043\n",
            "Round: 1417 Weight: [2.46511707 1.28444546] Bias: -1.086941727578375 loss: 0.33171847005057753\n",
            "Round: 1418 Weight: [2.46517814 1.28447485] Bias: -1.0869634905534167 loss: 0.3317184191793508\n",
            "Round: 1419 Weight: [2.46523905 1.28450416] Bias: -1.0869851954367205 loss: 0.33171836857848996\n",
            "Round: 1420 Weight: [2.46529979 1.28453339] Bias: -1.087006842387183 loss: 0.3317183182465425\n",
            "Round: 1421 Weight: [2.46536038 1.28456255] Bias: -1.0870284315632461 loss: 0.33171826818206407\n",
            "Round: 1422 Weight: [2.4654208  1.28459163] Bias: -1.0870499631228978 loss: 0.3317182183836181\n",
            "Round: 1423 Weight: [2.46548106 1.28462063] Bias: -1.0870714372236734 loss: 0.33171816884977584\n",
            "Round: 1424 Weight: [2.46554116 1.28464955] Bias: -1.0870928540226577 loss: 0.33171811957911623\n",
            "Round: 1425 Weight: [2.4656011 1.2846784] Bias: -1.0871142136764855 loss: 0.33171807057022645\n",
            "Round: 1426 Weight: [2.46566088 1.28470717] Bias: -1.0871355163413439 loss: 0.33171802182170057\n",
            "Round: 1427 Weight: [2.46572051 1.28473587] Bias: -1.087156762172973 loss: 0.331717973332141\n",
            "Round: 1428 Weight: [2.46577997 1.28476448] Bias: -1.0871779513266673 loss: 0.33171792510015746\n",
            "Round: 1429 Weight: [2.46583928 1.28479302] Bias: -1.0871990839572778 loss: 0.33171787712436757\n",
            "Round: 1430 Weight: [2.46589843 1.28482149] Bias: -1.0872201602192126 loss: 0.3317178294033959\n",
            "Round: 1431 Weight: [2.46595742 1.28484988] Bias: -1.0872411802664386 loss: 0.3317177819358752\n",
            "Round: 1432 Weight: [2.46601625 1.28487819] Bias: -1.0872621442524828 loss: 0.3317177347204451\n",
            "Round: 1433 Weight: [2.46607493 1.28490643] Bias: -1.0872830523304335 loss: 0.33171768775575283\n",
            "Round: 1434 Weight: [2.46613345 1.2849346 ] Bias: -1.0873039046529422 loss: 0.33171764104045326\n",
            "Round: 1435 Weight: [2.46619182 1.28496269] Bias: -1.0873247013722245 loss: 0.3317175945732084\n",
            "Round: 1436 Weight: [2.46625003 1.2849907 ] Bias: -1.087345442640061 loss: 0.3317175483526871\n",
            "Round: 1437 Weight: [2.46630809 1.28501864] Bias: -1.0873661286077998 loss: 0.33171750237756625\n",
            "Round: 1438 Weight: [2.46636599 1.28504651] Bias: -1.087386759426357 loss: 0.3317174566465295\n",
            "Round: 1439 Weight: [2.46642374 1.2850743 ] Bias: -1.0874073352462184 loss: 0.33171741115826764\n",
            "Round: 1440 Weight: [2.46648134 1.28510202] Bias: -1.0874278562174402 loss: 0.3317173659114788\n",
            "Round: 1441 Weight: [2.46653878 1.28512966] Bias: -1.0874483224896512 loss: 0.33171732090486794\n",
            "Round: 1442 Weight: [2.46659607 1.28515723] Bias: -1.0874687342120535 loss: 0.33171727613714724\n",
            "Round: 1443 Weight: [2.46665321 1.28518473] Bias: -1.087489091533424 loss: 0.33171723160703603\n",
            "Round: 1444 Weight: [2.46671019 1.28521216] Bias: -1.0875093946021164 loss: 0.3317171873132602\n",
            "Round: 1445 Weight: [2.46676703 1.28523951] Bias: -1.0875296435660606 loss: 0.3317171432545528\n",
            "Round: 1446 Weight: [2.46682371 1.28526679] Bias: -1.0875498385727664 loss: 0.33171709942965405\n",
            "Round: 1447 Weight: [2.46688024 1.285294  ] Bias: -1.087569979769323 loss: 0.33171705583731054\n",
            "Round: 1448 Weight: [2.46693663 1.28532113] Bias: -1.087590067302401 loss: 0.3317170124762759\n",
            "Round: 1449 Weight: [2.46699286 1.28534819] Bias: -1.0876101013182538 loss: 0.3317169693453105\n",
            "Round: 1450 Weight: [2.46704894 1.28537518] Bias: -1.0876300819627185 loss: 0.33171692644318157\n",
            "Round: 1451 Weight: [2.46710488 1.2854021 ] Bias: -1.0876500093812174 loss: 0.3317168837686629\n",
            "Round: 1452 Weight: [2.46716067 1.28542895] Bias: -1.0876698837187593 loss: 0.331716841320535\n",
            "Round: 1453 Weight: [2.4672163  1.28545573] Bias: -1.0876897051199408 loss: 0.331716799097585\n",
            "Round: 1454 Weight: [2.46727179 1.28548243] Bias: -1.0877094737289472 loss: 0.3317167570986066\n",
            "Round: 1455 Weight: [2.46732714 1.28550906] Bias: -1.0877291896895545 loss: 0.33171671532240027\n",
            "Round: 1456 Weight: [2.46738233 1.28553563] Bias: -1.0877488531451296 loss: 0.33171667376777253\n",
            "Round: 1457 Weight: [2.46743738 1.28556212] Bias: -1.0877684642386327 loss: 0.3317166324335367\n",
            "Round: 1458 Weight: [2.46749229 1.28558854] Bias: -1.0877880231126176 loss: 0.3317165913185127\n",
            "Round: 1459 Weight: [2.46754705 1.2856149 ] Bias: -1.0878075299092336 loss: 0.33171655042152665\n",
            "Round: 1460 Weight: [2.46760166 1.28564118] Bias: -1.0878269847702262 loss: 0.331716509741411\n",
            "Round: 1461 Weight: [2.46765613 1.28566739] Bias: -1.0878463878369389 loss: 0.3317164692770044\n",
            "Round: 1462 Weight: [2.46771045 1.28569354] Bias: -1.087865739250314 loss: 0.33171642902715226\n",
            "Round: 1463 Weight: [2.46776463 1.28571961] Bias: -1.0878850391508939 loss: 0.33171638899070616\n",
            "Round: 1464 Weight: [2.46781866 1.28574561] Bias: -1.0879042876788225 loss: 0.3317163491665234\n",
            "Round: 1465 Weight: [2.46787256 1.28577155] Bias: -1.0879234849738464 loss: 0.3317163095534681\n",
            "Round: 1466 Weight: [2.46792631 1.28579742] Bias: -1.0879426311753155 loss: 0.3317162701504103\n",
            "Round: 1467 Weight: [2.46797991 1.28582322] Bias: -1.0879617264221855 loss: 0.33171623095622593\n",
            "Round: 1468 Weight: [2.46803338 1.28584895] Bias: -1.0879807708530176 loss: 0.3317161919697975\n",
            "Round: 1469 Weight: [2.4680867  1.28587461] Bias: -1.087999764605981 loss: 0.3317161531900132\n",
            "Round: 1470 Weight: [2.46813988 1.2859002 ] Bias: -1.088018707818853 loss: 0.3317161146157675\n",
            "Round: 1471 Weight: [2.46819292 1.28592573] Bias: -1.0880376006290213 loss: 0.3317160762459609\n",
            "Round: 1472 Weight: [2.46824582 1.28595118] Bias: -1.0880564431734843 loss: 0.3317160380794993\n",
            "Round: 1473 Weight: [2.46829858 1.28597657] Bias: -1.0880752355888526 loss: 0.33171600011529534\n",
            "Round: 1474 Weight: [2.4683512 1.2860019] Bias: -1.0880939780113499 loss: 0.3317159623522669\n",
            "Round: 1475 Weight: [2.46840367 1.28602715] Bias: -1.088112670576815 loss: 0.3317159247893383\n",
            "Round: 1476 Weight: [2.46845601 1.28605234] Bias: -1.088131313420702 loss: 0.33171588742543906\n",
            "Round: 1477 Weight: [2.46850822 1.28607746] Bias: -1.0881499066780824 loss: 0.3317158502595053\n",
            "Round: 1478 Weight: [2.46856028 1.28610252] Bias: -1.088168450483645 loss: 0.33171581329047795\n",
            "Round: 1479 Weight: [2.4686122  1.28612751] Bias: -1.0881869449716985 loss: 0.3317157765173044\n",
            "Round: 1480 Weight: [2.46866399 1.28615243] Bias: -1.0882053902761717 loss: 0.33171573993893766\n",
            "Round: 1481 Weight: [2.46871564 1.28617729] Bias: -1.0882237865306148 loss: 0.331715703554336\n",
            "Round: 1482 Weight: [2.46876715 1.28620208] Bias: -1.0882421338682007 loss: 0.3317156673624639\n",
            "Round: 1483 Weight: [2.46881853 1.2862268 ] Bias: -1.0882604324217262 loss: 0.3317156313622908\n",
            "Round: 1484 Weight: [2.46886977 1.28625146] Bias: -1.0882786823236132 loss: 0.3317155955527924\n",
            "Round: 1485 Weight: [2.46892088 1.28627606] Bias: -1.0882968837059097 loss: 0.3317155599329495\n",
            "Round: 1486 Weight: [2.46897184 1.28630059] Bias: -1.0883150367002907 loss: 0.33171552450174857\n",
            "Round: 1487 Weight: [2.46902268 1.28632505] Bias: -1.0883331414380595 loss: 0.3317154892581815\n",
            "Round: 1488 Weight: [2.46907338 1.28634945] Bias: -1.0883511980501492 loss: 0.3317154542012457\n",
            "Round: 1489 Weight: [2.46912394 1.28637378] Bias: -1.0883692066671233 loss: 0.33171541932994403\n",
            "Round: 1490 Weight: [2.46917437 1.28639805] Bias: -1.0883871674191772 loss: 0.33171538464328476\n",
            "Round: 1491 Weight: [2.46922467 1.28642226] Bias: -1.0884050804361387 loss: 0.3317153501402815\n",
            "Round: 1492 Weight: [2.46927483 1.2864464 ] Bias: -1.0884229458474701 loss: 0.33171531581995295\n",
            "Round: 1493 Weight: [2.46932486 1.28647048] Bias: -1.0884407637822684 loss: 0.3317152816813235\n",
            "Round: 1494 Weight: [2.46937476 1.28649449] Bias: -1.0884585343692668 loss: 0.3317152477234227\n",
            "Round: 1495 Weight: [2.46942453 1.28651844] Bias: -1.0884762577368359 loss: 0.33171521394528547\n",
            "Round: 1496 Weight: [2.46947416 1.28654233] Bias: -1.0884939340129847 loss: 0.33171518034595154\n",
            "Round: 1497 Weight: [2.46952367 1.28656615] Bias: -1.0885115633253613 loss: 0.3317151469244662\n",
            "Round: 1498 Weight: [2.46957304 1.28658991] Bias: -1.0885291458012547 loss: 0.33171511367987977\n",
            "Round: 1499 Weight: [2.46962228 1.28661361] Bias: -1.0885466815675953 loss: 0.33171508061124766\n",
            "Round: 1500 Weight: [2.46967139 1.28663724] Bias: -1.0885641707509561 loss: 0.3317150477176307\n",
            "Round: 1501 Weight: [2.46972037 1.28666082] Bias: -1.0885816134775543 loss: 0.3317150149980944\n",
            "Round: 1502 Weight: [2.46976922 1.28668433] Bias: -1.0885990098732514 loss: 0.3317149824517096\n",
            "Round: 1503 Weight: [2.46981794 1.28670777] Bias: -1.0886163600635552 loss: 0.331714950077552\n",
            "Round: 1504 Weight: [2.46986653 1.28673116] Bias: -1.0886336641736205 loss: 0.3317149178747023\n",
            "Round: 1505 Weight: [2.469915   1.28675448] Bias: -1.08865092232825 loss: 0.3317148858422463\n",
            "Round: 1506 Weight: [2.46996333 1.28677774] Bias: -1.0886681346518952 loss: 0.3317148539792745\n",
            "Round: 1507 Weight: [2.47001154 1.28680094] Bias: -1.0886853012686584 loss: 0.3317148222848827\n",
            "Round: 1508 Weight: [2.47005962 1.28682408] Bias: -1.0887024223022925 loss: 0.3317147907581711\n",
            "Round: 1509 Weight: [2.47010757 1.28684716] Bias: -1.0887194978762031 loss: 0.33171475939824535\n",
            "Round: 1510 Weight: [2.4701554  1.28687017] Bias: -1.0887365281134491 loss: 0.3317147282042153\n",
            "Round: 1511 Weight: [2.47020309 1.28689313] Bias: -1.0887535131367434 loss: 0.33171469717519614\n",
            "Round: 1512 Weight: [2.47025067 1.28691602] Bias: -1.0887704530684543 loss: 0.3317146663103074\n",
            "Round: 1513 Weight: [2.47029811 1.28693886] Bias: -1.088787348030607 loss: 0.33171463560867387\n",
            "Round: 1514 Weight: [2.47034543 1.28696163] Bias: -1.0888041981448835 loss: 0.33171460506942435\n",
            "Round: 1515 Weight: [2.47039263 1.28698434] Bias: -1.088821003532625 loss: 0.3317145746916932\n",
            "Round: 1516 Weight: [2.4704397 1.287007 ] Bias: -1.0888377643148315 loss: 0.3317145444746187\n",
            "Round: 1517 Weight: [2.47048665 1.28702959] Bias: -1.0888544806121638 loss: 0.33171451441734434\n",
            "Round: 1518 Weight: [2.47053347 1.28705212] Bias: -1.0888711525449446 loss: 0.33171448451901775\n",
            "Round: 1519 Weight: [2.47058017 1.2870746 ] Bias: -1.0888877802331585 loss: 0.33171445477879175\n",
            "Round: 1520 Weight: [2.47062674 1.28709701] Bias: -1.0889043637964542 loss: 0.3317144251958231\n",
            "Round: 1521 Weight: [2.47067319 1.28711936] Bias: -1.0889209033541445 loss: 0.33171439576927353\n",
            "Round: 1522 Weight: [2.47071952 1.28714166] Bias: -1.0889373990252083 loss: 0.3317143664983092\n",
            "Round: 1523 Weight: [2.47076572 1.2871639 ] Bias: -1.0889538509282903 loss: 0.3317143373821006\n",
            "Round: 1524 Weight: [2.47081181 1.28718607] Bias: -1.0889702591817039 loss: 0.33171430841982297\n",
            "Round: 1525 Weight: [2.47085777 1.28720819] Bias: -1.0889866239034298 loss: 0.3317142796106557\n",
            "Round: 1526 Weight: [2.47090361 1.28723025] Bias: -1.0890029452111194 loss: 0.33171425095378304\n",
            "Round: 1527 Weight: [2.47094933 1.28725225] Bias: -1.0890192232220937 loss: 0.33171422244839316\n",
            "Round: 1528 Weight: [2.47099492 1.2872742 ] Bias: -1.089035458053346 loss: 0.3317141940936787\n",
            "Round: 1529 Weight: [2.4710404  1.28729608] Bias: -1.0890516498215412 loss: 0.33171416588883706\n",
            "Round: 1530 Weight: [2.47108576 1.28731791] Bias: -1.0890677986430188 loss: 0.3317141378330696\n",
            "Round: 1531 Weight: [2.47113099 1.28733968] Bias: -1.089083904633792 loss: 0.3317141099255818\n",
            "Round: 1532 Weight: [2.47117611 1.2873614 ] Bias: -1.0890999679095494 loss: 0.33171408216558407\n",
            "Round: 1533 Weight: [2.47122111 1.28738305] Bias: -1.0891159885856565 loss: 0.33171405455229047\n",
            "Round: 1534 Weight: [2.47126599 1.28740465] Bias: -1.0891319667771557 loss: 0.3317140270849195\n",
            "Round: 1535 Weight: [2.47131075 1.28742619] Bias: -1.089147902598768 loss: 0.33171399976269406\n",
            "Round: 1536 Weight: [2.47135539 1.28744767] Bias: -1.0891637961648934 loss: 0.3317139725848409\n",
            "Round: 1537 Weight: [2.47139991 1.2874691 ] Bias: -1.0891796475896125 loss: 0.3317139455505912\n",
            "Round: 1538 Weight: [2.47144432 1.28749047] Bias: -1.0891954569866866 loss: 0.33171391865918015\n",
            "Round: 1539 Weight: [2.4714886  1.28751178] Bias: -1.0892112244695598 loss: 0.3317138919098472\n",
            "Round: 1540 Weight: [2.47153277 1.28753304] Bias: -1.0892269501513585 loss: 0.3317138653018356\n",
            "Round: 1541 Weight: [2.47157683 1.28755424] Bias: -1.0892426341448938 loss: 0.3317138388343931\n",
            "Round: 1542 Weight: [2.47162077 1.28757539] Bias: -1.0892582765626613 loss: 0.33171381250677107\n",
            "Round: 1543 Weight: [2.47166459 1.28759648] Bias: -1.0892738775168427 loss: 0.3317137863182252\n",
            "Round: 1544 Weight: [2.47170829 1.28761751] Bias: -1.0892894371193067 loss: 0.33171376026801513\n",
            "Round: 1545 Weight: [2.47175188 1.28763849] Bias: -1.0893049554816094 loss: 0.3317137343554045\n",
            "Round: 1546 Weight: [2.47179536 1.28765941] Bias: -1.089320432714996 loss: 0.33171370857966076\n",
            "Round: 1547 Weight: [2.47183872 1.28768028] Bias: -1.0893358689304005 loss: 0.3317136829400555\n",
            "Round: 1548 Weight: [2.47188196 1.28770109] Bias: -1.0893512642384484 loss: 0.33171365743586423\n",
            "Round: 1549 Weight: [2.4719251  1.28772185] Bias: -1.0893666187494564 loss: 0.33171363206636606\n",
            "Round: 1550 Weight: [2.47196811 1.28774255] Bias: -1.089381932573433 loss: 0.3317136068308444\n",
            "Round: 1551 Weight: [2.47201102 1.28776319] Bias: -1.089397205820081 loss: 0.33171358172858606\n",
            "Round: 1552 Weight: [2.47205381 1.28778379] Bias: -1.0894124385987962 loss: 0.33171355675888226\n",
            "Round: 1553 Weight: [2.47209648 1.28780433] Bias: -1.0894276310186704 loss: 0.33171353192102765\n",
            "Round: 1554 Weight: [2.47213905 1.28782481] Bias: -1.089442783188491 loss: 0.3317135072143207\n",
            "Round: 1555 Weight: [2.4721815  1.28784524] Bias: -1.0894578952167422 loss: 0.33171348263806366\n",
            "Round: 1556 Weight: [2.47222384 1.28786561] Bias: -1.0894729672116064 loss: 0.33171345819156256\n",
            "Round: 1557 Weight: [2.47226606 1.28788594] Bias: -1.0894879992809643 loss: 0.3317134338741271\n",
            "Round: 1558 Weight: [2.47230818 1.28790621] Bias: -1.0895029915323964 loss: 0.331713409685071\n",
            "Round: 1559 Weight: [2.47235019 1.28792642] Bias: -1.0895179440731835 loss: 0.3317133856237113\n",
            "Round: 1560 Weight: [2.47239208 1.28794658] Bias: -1.089532857010308 loss: 0.3317133616893689\n",
            "Round: 1561 Weight: [2.47243386 1.28796669] Bias: -1.0895477304504542 loss: 0.3317133378813682\n",
            "Round: 1562 Weight: [2.47247553 1.28798674] Bias: -1.0895625645000098 loss: 0.3317133141990375\n",
            "Round: 1563 Weight: [2.4725171  1.28800675] Bias: -1.0895773592650662 loss: 0.33171329064170846\n",
            "Round: 1564 Weight: [2.47255855 1.2880267 ] Bias: -1.08959211485142 loss: 0.33171326720871636\n",
            "Round: 1565 Weight: [2.47259989 1.28804659] Bias: -1.0896068313645735 loss: 0.3317132438994002\n",
            "Round: 1566 Weight: [2.47264113 1.28806644] Bias: -1.0896215089097352 loss: 0.33171322071310233\n",
            "Round: 1567 Weight: [2.47268225 1.28808623] Bias: -1.0896361475918215 loss: 0.3317131976491689\n",
            "Round: 1568 Weight: [2.47272327 1.28810597] Bias: -1.0896507475154569 loss: 0.3317131747069493\n",
            "Round: 1569 Weight: [2.47276418 1.28812565] Bias: -1.0896653087849753 loss: 0.33171315188579664\n",
            "Round: 1570 Weight: [2.47280498 1.28814529] Bias: -1.0896798315044203 loss: 0.33171312918506746\n",
            "Round: 1571 Weight: [2.47284567 1.28816487] Bias: -1.089694315777547 loss: 0.3317131066041214\n",
            "Round: 1572 Weight: [2.47288625 1.2881844 ] Bias: -1.0897087617078214 loss: 0.33171308414232215\n",
            "Round: 1573 Weight: [2.47292673 1.28820388] Bias: -1.0897231693984228 loss: 0.33171306179903637\n",
            "Round: 1574 Weight: [2.4729671  1.28822331] Bias: -1.089737538952244 loss: 0.3317130395736343\n",
            "Round: 1575 Weight: [2.47300737 1.28824269] Bias: -1.0897518704718914 loss: 0.3317130174654895\n",
            "Round: 1576 Weight: [2.47304752 1.28826201] Bias: -1.089766164059687 loss: 0.3317129954739789\n",
            "Round: 1577 Weight: [2.47308757 1.28828129] Bias: -1.0897804198176688 loss: 0.33171297359848295\n",
            "Round: 1578 Weight: [2.47312752 1.28830051] Bias: -1.0897946378475916 loss: 0.3317129518383852\n",
            "Round: 1579 Weight: [2.47316736 1.28831969] Bias: -1.0898088182509276 loss: 0.3317129301930723\n",
            "Round: 1580 Weight: [2.4732071  1.28833881] Bias: -1.0898229611288677 loss: 0.33171290866193476\n",
            "Round: 1581 Weight: [2.47324673 1.28835788] Bias: -1.089837066582322 loss: 0.33171288724436615\n",
            "Round: 1582 Weight: [2.47328625 1.2883769 ] Bias: -1.0898511347119209 loss: 0.331712865939763\n",
            "Round: 1583 Weight: [2.47332567 1.28839587] Bias: -1.0898651656180152 loss: 0.3317128447475253\n",
            "Round: 1584 Weight: [2.47336499 1.2884148 ] Bias: -1.089879159400678 loss: 0.3317128236670564\n",
            "Round: 1585 Weight: [2.4734042  1.28843367] Bias: -1.089893116159705 loss: 0.33171280269776265\n",
            "Round: 1586 Weight: [2.47344331 1.28845249] Bias: -1.0899070359946148 loss: 0.33171278183905367\n",
            "Round: 1587 Weight: [2.47348232 1.28847126] Bias: -1.0899209190046506 loss: 0.3317127610903421\n",
            "Round: 1588 Weight: [2.47352123 1.28848998] Bias: -1.0899347652887805 loss: 0.3317127404510441\n",
            "Round: 1589 Weight: [2.47356003 1.28850866] Bias: -1.0899485749456985 loss: 0.33171271992057844\n",
            "Round: 1590 Weight: [2.47359873 1.28852728] Bias: -1.089962348073825 loss: 0.33171269949836746\n",
            "Round: 1591 Weight: [2.47363732 1.28854585] Bias: -1.0899760847713078 loss: 0.33171267918383635\n",
            "Round: 1592 Weight: [2.47367582 1.28856438] Bias: -1.0899897851360234 loss: 0.33171265897641344\n",
            "Round: 1593 Weight: [2.47371421 1.28858286] Bias: -1.0900034492655768 loss: 0.3317126388755302\n",
            "Round: 1594 Weight: [2.4737525  1.28860128] Bias: -1.0900170772573028 loss: 0.3317126188806211\n",
            "Round: 1595 Weight: [2.47379069 1.28861966] Bias: -1.090030669208267 loss: 0.3317125989911236\n",
            "Round: 1596 Weight: [2.47382878 1.28863799] Bias: -1.0900442252152667 loss: 0.3317125792064781\n",
            "Round: 1597 Weight: [2.47386677 1.28865628] Bias: -1.0900577453748306 loss: 0.33171255952612827\n",
            "Round: 1598 Weight: [2.47390466 1.28867451] Bias: -1.090071229783221 loss: 0.33171253994952044\n",
            "Round: 1599 Weight: [2.47394245 1.2886927 ] Bias: -1.0900846785364335 loss: 0.3317125204761044\n",
            "Round: 1600 Weight: [2.47398014 1.28871084] Bias: -1.0900980917301988 loss: 0.33171250110533207\n",
            "Round: 1601 Weight: [2.47401773 1.28872893] Bias: -1.090111469459982 loss: 0.3317124818366591\n",
            "Round: 1602 Weight: [2.47405522 1.28874697] Bias: -1.090124811820985 loss: 0.33171246266954374\n",
            "Round: 1603 Weight: [2.47409261 1.28876496] Bias: -1.090138118908146 loss: 0.3317124436034471\n",
            "Round: 1604 Weight: [2.47412991 1.28878291] Bias: -1.0901513908161415 loss: 0.3317124246378332\n",
            "Round: 1605 Weight: [2.4741671  1.28880081] Bias: -1.0901646276393857 loss: 0.331712405772169\n",
            "Round: 1606 Weight: [2.4742042  1.28881866] Bias: -1.090177829472032 loss: 0.3317123870059243\n",
            "Round: 1607 Weight: [2.4742412  1.28883647] Bias: -1.0901909964079737 loss: 0.3317123683385717\n",
            "Round: 1608 Weight: [2.4742781  1.28885423] Bias: -1.0902041285408453 loss: 0.3317123497695866\n",
            "Round: 1609 Weight: [2.4743149  1.28887194] Bias: -1.090217225964022 loss: 0.3317123312984473\n",
            "Round: 1610 Weight: [2.47435161 1.28888961] Bias: -1.0902302887706214 loss: 0.33171231292463477\n",
            "Round: 1611 Weight: [2.47438822 1.28890722] Bias: -1.0902433170535042 loss: 0.331712294647633\n",
            "Round: 1612 Weight: [2.47442474 1.2889248 ] Bias: -1.0902563109052743 loss: 0.33171227646692847\n",
            "Round: 1613 Weight: [2.47446115 1.28894232] Bias: -1.0902692704182804 loss: 0.3317122583820105\n",
            "Round: 1614 Weight: [2.47449747 1.2889598 ] Bias: -1.0902821956846163 loss: 0.33171224039237124\n",
            "Round: 1615 Weight: [2.4745337  1.28897724] Bias: -1.0902950867961214 loss: 0.3317122224975054\n",
            "Round: 1616 Weight: [2.47456983 1.28899462] Bias: -1.090307943844382 loss: 0.3317122046969105\n",
            "Round: 1617 Weight: [2.47460587 1.28901197] Bias: -1.0903207669207315 loss: 0.3317121869900868\n",
            "Round: 1618 Weight: [2.47464181 1.28902926] Bias: -1.0903335561162517 loss: 0.33171216937653697\n",
            "Round: 1619 Weight: [2.47467765 1.28904651] Bias: -1.090346311521773 loss: 0.3317121518557667\n",
            "Round: 1620 Weight: [2.4747134  1.28906372] Bias: -1.0903590332278756 loss: 0.33171213442728426\n",
            "Round: 1621 Weight: [2.47474906 1.28908088] Bias: -1.0903717213248896 loss: 0.33171211709060017\n",
            "Round: 1622 Weight: [2.47478462 1.28909799] Bias: -1.0903843759028964 loss: 0.331712099845228\n",
            "Round: 1623 Weight: [2.47482009 1.28911506] Bias: -1.0903969970517289 loss: 0.3317120826906838\n",
            "Round: 1624 Weight: [2.47485546 1.28913208] Bias: -1.0904095848609727 loss: 0.33171206562648603\n",
            "Round: 1625 Weight: [2.47489075 1.28914906] Bias: -1.0904221394199665 loss: 0.3317120486521561\n",
            "Round: 1626 Weight: [2.47492593 1.289166  ] Bias: -1.0904346608178026 loss: 0.33171203176721753\n",
            "Round: 1627 Weight: [2.47496103 1.28918289] Bias: -1.0904471491433283 loss: 0.33171201497119684\n",
            "Round: 1628 Weight: [2.47499603 1.28919973] Bias: -1.0904596044851462 loss: 0.33171199826362263\n",
            "Round: 1629 Weight: [2.47503095 1.28921653] Bias: -1.0904720269316146 loss: 0.33171198164402643\n",
            "Round: 1630 Weight: [2.47506576 1.28923329] Bias: -1.0904844165708485 loss: 0.331711965111942\n",
            "Round: 1631 Weight: [2.47510049 1.28925   ] Bias: -1.0904967734907207 loss: 0.3317119486669057\n",
            "Round: 1632 Weight: [2.47513513 1.28926667] Bias: -1.0905090977788618 loss: 0.33171193230845647\n",
            "Round: 1633 Weight: [2.47516967 1.2892833 ] Bias: -1.0905213895226618 loss: 0.3317119160361353\n",
            "Round: 1634 Weight: [2.47520413 1.28929988] Bias: -1.0905336488092692 loss: 0.33171189984948624\n",
            "Round: 1635 Weight: [2.47523849 1.28931641] Bias: -1.0905458757255937 loss: 0.3317118837480553\n",
            "Round: 1636 Weight: [2.47527276 1.28933291] Bias: -1.0905580703583053 loss: 0.3317118677313912\n",
            "Round: 1637 Weight: [2.47530694 1.28934936] Bias: -1.090570232793836 loss: 0.33171185179904483\n",
            "Round: 1638 Weight: [2.47534104 1.28936576] Bias: -1.09058236311838 loss: 0.3317118359505698\n",
            "Round: 1639 Weight: [2.47537504 1.28938213] Bias: -1.0905944614178944 loss: 0.3317118201855218\n",
            "Round: 1640 Weight: [2.47540895 1.28939845] Bias: -1.0906065277780999 loss: 0.331711804503459\n",
            "Round: 1641 Weight: [2.47544277 1.28941473] Bias: -1.0906185622844817 loss: 0.3317117889039418\n",
            "Round: 1642 Weight: [2.47547651 1.28943096] Bias: -1.09063056502229 loss: 0.3317117733865334\n",
            "Round: 1643 Weight: [2.47551015 1.28944715] Bias: -1.0906425360765408 loss: 0.3317117579507988\n",
            "Round: 1644 Weight: [2.47554371 1.2894633 ] Bias: -1.0906544755320162 loss: 0.3317117425963057\n",
            "Round: 1645 Weight: [2.47557718 1.28947941] Bias: -1.0906663834732657 loss: 0.3317117273226237\n",
            "Round: 1646 Weight: [2.47561056 1.28949547] Bias: -1.0906782599846065 loss: 0.3317117121293254\n",
            "Round: 1647 Weight: [2.47564385 1.28951149] Bias: -1.0906901051501239 loss: 0.33171169701598474\n",
            "Round: 1648 Weight: [2.47567705 1.28952747] Bias: -1.0907019190536726 loss: 0.3317116819821787\n",
            "Round: 1649 Weight: [2.47571017 1.28954341] Bias: -1.0907137017788768 loss: 0.3317116670274863\n",
            "Round: 1650 Weight: [2.4757432 1.2895593] Bias: -1.0907254534091313 loss: 0.33171165215148846\n",
            "Round: 1651 Weight: [2.47577614 1.28957516] Bias: -1.090737174027602 loss: 0.33171163735376896\n",
            "Round: 1652 Weight: [2.475809   1.28959097] Bias: -1.090748863717226 loss: 0.3317116226339134\n",
            "Round: 1653 Weight: [2.47584177 1.28960674] Bias: -1.0907605225607135 loss: 0.3317116079915096\n",
            "Round: 1654 Weight: [2.47587445 1.28962247] Bias: -1.0907721506405477 loss: 0.33171159342614787\n",
            "Round: 1655 Weight: [2.47590705 1.28963816] Bias: -1.0907837480389848 loss: 0.3317115789374202\n",
            "Round: 1656 Weight: [2.47593956 1.2896538 ] Bias: -1.0907953148380558 loss: 0.3317115645249211\n",
            "Round: 1657 Weight: [2.47597198 1.28966941] Bias: -1.0908068511195668 loss: 0.3317115501882473\n",
            "Round: 1658 Weight: [2.47600433 1.28968497] Bias: -1.0908183569650993 loss: 0.3317115359269976\n",
            "Round: 1659 Weight: [2.47603658 1.28970049] Bias: -1.090829832456011 loss: 0.33171152174077273\n",
            "Round: 1660 Weight: [2.47606875 1.28971597] Bias: -1.090841277673437 loss: 0.3317115076291759\n",
            "Round: 1661 Weight: [2.47610084 1.28973142] Bias: -1.0908526926982898 loss: 0.33171149359181223\n",
            "Round: 1662 Weight: [2.47613284 1.28974682] Bias: -1.0908640776112595 loss: 0.3317114796282891\n",
            "Round: 1663 Weight: [2.47616475 1.28976218] Bias: -1.0908754324928158 loss: 0.33171146573821575\n",
            "Round: 1664 Weight: [2.47619659 1.2897775 ] Bias: -1.0908867574232075 loss: 0.3317114519212036\n",
            "Round: 1665 Weight: [2.47622833 1.28979277] Bias: -1.0908980524824639 loss: 0.3317114381768661\n",
            "Round: 1666 Weight: [2.47626    1.28980801] Bias: -1.0909093177503943 loss: 0.3317114245048191\n",
            "Round: 1667 Weight: [2.47629158 1.28982321] Bias: -1.0909205533065902 loss: 0.3317114109046801\n",
            "Round: 1668 Weight: [2.47632308 1.28983837] Bias: -1.0909317592304246 loss: 0.33171139737606875\n",
            "Round: 1669 Weight: [2.4763545  1.28985349] Bias: -1.0909429356010534 loss: 0.33171138391860666\n",
            "Round: 1670 Weight: [2.47638583 1.28986857] Bias: -1.0909540824974153 loss: 0.33171137053191774\n",
            "Round: 1671 Weight: [2.47641708 1.28988361] Bias: -1.0909651999982335 loss: 0.3317113572156277\n",
            "Round: 1672 Weight: [2.47644825 1.28989861] Bias: -1.0909762881820153 loss: 0.3317113439693641\n",
            "Round: 1673 Weight: [2.47647933 1.28991357] Bias: -1.090987347127053 loss: 0.3317113307927568\n",
            "Round: 1674 Weight: [2.47651034 1.28992849] Bias: -1.090998376911425 loss: 0.3317113176854374\n",
            "Round: 1675 Weight: [2.47654126 1.28994337] Bias: -1.0910093776129959 loss: 0.3317113046470396\n",
            "Round: 1676 Weight: [2.4765721  1.28995821] Bias: -1.091020349309417 loss: 0.33171129167719887\n",
            "Round: 1677 Weight: [2.47660286 1.28997301] Bias: -1.0910312920781275 loss: 0.33171127877555295\n",
            "Round: 1678 Weight: [2.47663354 1.28998778] Bias: -1.0910422059963547 loss: 0.33171126594174116\n",
            "Round: 1679 Weight: [2.47666414 1.2900025 ] Bias: -1.0910530911411145 loss: 0.33171125317540495\n",
            "Round: 1680 Weight: [2.47669466 1.29001719] Bias: -1.0910639475892123 loss: 0.33171124047618766\n",
            "Round: 1681 Weight: [2.4767251  1.29003184] Bias: -1.0910747754172436 loss: 0.33171122784373447\n",
            "Round: 1682 Weight: [2.47675545 1.29004645] Bias: -1.0910855747015944 loss: 0.3317112152776924\n",
            "Round: 1683 Weight: [2.47678573 1.29006102] Bias: -1.0910963455184417 loss: 0.33171120277771055\n",
            "Round: 1684 Weight: [2.47681593 1.29007555] Bias: -1.0911070879437543 loss: 0.3317111903434397\n",
            "Round: 1685 Weight: [2.47684605 1.29009005] Bias: -1.0911178020532937 loss: 0.3317111779745325\n",
            "Round: 1686 Weight: [2.47687609 1.2901045 ] Bias: -1.091128487922614 loss: 0.33171116567064357\n",
            "Round: 1687 Weight: [2.47690605 1.29011892] Bias: -1.0911391456270632 loss: 0.3317111534314293\n",
            "Round: 1688 Weight: [2.47693593 1.2901333 ] Bias: -1.0911497752417831 loss: 0.331711141256548\n",
            "Round: 1689 Weight: [2.47696573 1.29014764] Bias: -1.0911603768417106 loss: 0.33171112914565964\n",
            "Round: 1690 Weight: [2.47699546 1.29016195] Bias: -1.0911709505015776 loss: 0.331711117098426\n",
            "Round: 1691 Weight: [2.4770251  1.29017622] Bias: -1.091181496295912 loss: 0.3317111051145109\n",
            "Round: 1692 Weight: [2.47705467 1.29019045] Bias: -1.0911920142990386 loss: 0.3317110931935798\n",
            "Round: 1693 Weight: [2.47708416 1.29020464] Bias: -1.0912025045850784 loss: 0.3317110813352996\n",
            "Round: 1694 Weight: [2.47711357 1.29021879] Bias: -1.0912129672279507 loss: 0.33171106953933965\n",
            "Round: 1695 Weight: [2.47714291 1.29023291] Bias: -1.091223402301373 loss: 0.33171105780537063\n",
            "Round: 1696 Weight: [2.47717217 1.29024699] Bias: -1.0912338098788612 loss: 0.331711046133065\n",
            "Round: 1697 Weight: [2.47720135 1.29026103] Bias: -1.091244190033731 loss: 0.33171103452209705\n",
            "Round: 1698 Weight: [2.47723045 1.29027504] Bias: -1.0912545428390983 loss: 0.33171102297214283\n",
            "Round: 1699 Weight: [2.47725948 1.29028901] Bias: -1.0912648683678785 loss: 0.33171101148288007\n",
            "Round: 1700 Weight: [2.47728843 1.29030294] Bias: -1.0912751666927891 loss: 0.3317110000539882\n",
            "Round: 1701 Weight: [2.47731731 1.29031684] Bias: -1.0912854378863486 loss: 0.33171098868514814\n",
            "Round: 1702 Weight: [2.47734611 1.2903307 ] Bias: -1.0912956820208781 loss: 0.331710977376043\n",
            "Round: 1703 Weight: [2.47737483 1.29034452] Bias: -1.0913058991685014 loss: 0.33171096612635714\n",
            "Round: 1704 Weight: [2.47740348 1.29035831] Bias: -1.0913160894011453 loss: 0.331710954935777\n",
            "Round: 1705 Weight: [2.47743205 1.29037206] Bias: -1.0913262527905412 loss: 0.3317109438039902\n",
            "Round: 1706 Weight: [2.47746055 1.29038577] Bias: -1.0913363894082242 loss: 0.33171093273068636\n",
            "Round: 1707 Weight: [2.47748897 1.29039945] Bias: -1.0913464993255348 loss: 0.33171092171555666\n",
            "Round: 1708 Weight: [2.47751732 1.29041309] Bias: -1.0913565826136193 loss: 0.33171091075829406\n",
            "Round: 1709 Weight: [2.4775456 1.2904267] Bias: -1.0913666393434296 loss: 0.3317108998585928\n",
            "Round: 1710 Weight: [2.4775738  1.29044027] Bias: -1.0913766695857245 loss: 0.33171088901614915\n",
            "Round: 1711 Weight: [2.47760192 1.29045381] Bias: -1.0913866734110702 loss: 0.33171087823066076\n",
            "Round: 1712 Weight: [2.47762997 1.29046731] Bias: -1.0913966508898403 loss: 0.33171086750182693\n",
            "Round: 1713 Weight: [2.47765795 1.29048077] Bias: -1.091406602092217 loss: 0.3317108568293487\n",
            "Round: 1714 Weight: [2.47768585 1.2904942 ] Bias: -1.0914165270881915 loss: 0.33171084621292823\n",
            "Round: 1715 Weight: [2.47771368 1.29050759] Bias: -1.091426425947564 loss: 0.33171083565227005\n",
            "Round: 1716 Weight: [2.47774144 1.29052095] Bias: -1.0914362987399446 loss: 0.33171082514707945\n",
            "Round: 1717 Weight: [2.47776912 1.29053427] Bias: -1.0914461455347546 loss: 0.3317108146970639\n",
            "Round: 1718 Weight: [2.47779674 1.29054756] Bias: -1.0914559664012256 loss: 0.3317108043019321\n",
            "Round: 1719 Weight: [2.47782428 1.29056081] Bias: -1.091465761408401 loss: 0.33171079396139436\n",
            "Round: 1720 Weight: [2.47785174 1.29057403] Bias: -1.0914755306251362 loss: 0.3317107836751626\n",
            "Round: 1721 Weight: [2.47787914 1.29058722] Bias: -1.0914852741200995 loss: 0.33171077344295025\n",
            "Round: 1722 Weight: [2.47790646 1.29060036] Bias: -1.091494991961772 loss: 0.33171076326447213\n",
            "Round: 1723 Weight: [2.47793371 1.29061348] Bias: -1.0915046842184486 loss: 0.3317107531394446\n",
            "Round: 1724 Weight: [2.47796089 1.29062656] Bias: -1.0915143509582386 loss: 0.33171074306758586\n",
            "Round: 1725 Weight: [2.477988  1.2906396] Bias: -1.0915239922490658 loss: 0.33171073304861526\n",
            "Round: 1726 Weight: [2.47801503 1.29065261] Bias: -1.0915336081586695 loss: 0.33171072308225363\n",
            "Round: 1727 Weight: [2.478042   1.29066559] Bias: -1.0915431987546045 loss: 0.3317107131682235\n",
            "Round: 1728 Weight: [2.47806889 1.29067853] Bias: -1.091552764104242 loss: 0.33171070330624874\n",
            "Round: 1729 Weight: [2.47809571 1.29069144] Bias: -1.0915623042747702 loss: 0.3317106934960548\n",
            "Round: 1730 Weight: [2.47812247 1.29070432] Bias: -1.0915718193331945 loss: 0.3317106837373683\n",
            "Round: 1731 Weight: [2.47814915 1.29071716] Bias: -1.0915813093463382 loss: 0.3317106740299177\n",
            "Round: 1732 Weight: [2.47817576 1.29072997] Bias: -1.091590774380843 loss: 0.33171066437343266\n",
            "Round: 1733 Weight: [2.47820231 1.29074274] Bias: -1.0916002145031696 loss: 0.33171065476764433\n",
            "Round: 1734 Weight: [2.47822878 1.29075548] Bias: -1.0916096297795976 loss: 0.33171064521228527\n",
            "Round: 1735 Weight: [2.47825518 1.29076819] Bias: -1.0916190202762273 loss: 0.3317106357070895\n",
            "Round: 1736 Weight: [2.47828152 1.29078086] Bias: -1.0916283860589786 loss: 0.33171062625179243\n",
            "Round: 1737 Weight: [2.47830778 1.2907935 ] Bias: -1.091637727193593 loss: 0.33171061684613085\n",
            "Round: 1738 Weight: [2.47833398 1.29080611] Bias: -1.0916470437456331 loss: 0.3317106074898431\n",
            "Round: 1739 Weight: [2.4783601  1.29081868] Bias: -1.0916563357804836 loss: 0.33171059818266857\n",
            "Round: 1740 Weight: [2.47838616 1.29083122] Bias: -1.0916656033633516 loss: 0.3317105889243485\n",
            "Round: 1741 Weight: [2.47841215 1.29084373] Bias: -1.091674846559267 loss: 0.33171057971462514\n",
            "Round: 1742 Weight: [2.47843807 1.2908562 ] Bias: -1.0916840654330833 loss: 0.3317105705532422\n",
            "Round: 1743 Weight: [2.47846393 1.29086864] Bias: -1.0916932600494778 loss: 0.3317105614399448\n",
            "Round: 1744 Weight: [2.47848971 1.29088105] Bias: -1.0917024304729526 loss: 0.33171055237447944\n",
            "Round: 1745 Weight: [2.47851543 1.29089343] Bias: -1.0917115767678343 loss: 0.33171054335659383\n",
            "Round: 1746 Weight: [2.47854108 1.29090577] Bias: -1.091720698998275 loss: 0.33171053438603715\n",
            "Round: 1747 Weight: [2.47856666 1.29091808] Bias: -1.0917297972282531 loss: 0.3317105254625598\n",
            "Round: 1748 Weight: [2.47859218 1.29093036] Bias: -1.0917388715215732 loss: 0.3317105165859138\n",
            "Round: 1749 Weight: [2.47861763 1.29094261] Bias: -1.0917479219418664 loss: 0.33171050775585187\n",
            "Round: 1750 Weight: [2.47864301 1.29095483] Bias: -1.091756948552592 loss: 0.3317104989721288\n",
            "Round: 1751 Weight: [2.47866832 1.29096701] Bias: -1.0917659514170364 loss: 0.3317104902345001\n",
            "Round: 1752 Weight: [2.47869357 1.29097916] Bias: -1.0917749305983147 loss: 0.3317104815427228\n",
            "Round: 1753 Weight: [2.47871875 1.29099128] Bias: -1.091783886159371 loss: 0.3317104728965553\n",
            "Round: 1754 Weight: [2.47874387 1.29100336] Bias: -1.0917928181629784 loss: 0.3317104642957571\n",
            "Round: 1755 Weight: [2.47876892 1.29101542] Bias: -1.09180172667174 loss: 0.33171045574008917\n",
            "Round: 1756 Weight: [2.4787939  1.29102744] Bias: -1.0918106117480892 loss: 0.33171044722931353\n",
            "Round: 1757 Weight: [2.47881882 1.29103943] Bias: -1.09181947345429 loss: 0.3317104387631936\n",
            "Round: 1758 Weight: [2.47884368 1.2910514 ] Bias: -1.0918283118524381 loss: 0.3317104303414941\n",
            "Round: 1759 Weight: [2.47886846 1.29106332] Bias: -1.0918371270044605 loss: 0.33171042196398093\n",
            "Round: 1760 Weight: [2.47889319 1.29107522] Bias: -1.0918459189721161 loss: 0.33171041363042114\n",
            "Round: 1761 Weight: [2.47891785 1.29108709] Bias: -1.0918546878169972 loss: 0.33171040534058316\n",
            "Round: 1762 Weight: [2.47894244 1.29109892] Bias: -1.0918634336005288 loss: 0.33171039709423655\n",
            "Round: 1763 Weight: [2.47896697 1.29111073] Bias: -1.0918721563839695 loss: 0.3317103888911522\n",
            "Round: 1764 Weight: [2.47899143 1.2911225 ] Bias: -1.0918808562284121 loss: 0.33171038073110226\n",
            "Round: 1765 Weight: [2.47901583 1.29113424] Bias: -1.091889533194784 loss: 0.33171037261385966\n",
            "Round: 1766 Weight: [2.47904017 1.29114596] Bias: -1.0918981873438471 loss: 0.33171036453919933\n",
            "Round: 1767 Weight: [2.47906444 1.29115764] Bias: -1.0919068187361995 loss: 0.33171035650689645\n",
            "Round: 1768 Weight: [2.47908865 1.29116929] Bias: -1.0919154274322749 loss: 0.331710348516728\n",
            "Round: 1769 Weight: [2.47911279 1.29118091] Bias: -1.0919240134923431 loss: 0.3317103405684722\n",
            "Round: 1770 Weight: [2.47913687 1.29119249] Bias: -1.0919325769765111 loss: 0.33171033266190797\n",
            "Round: 1771 Weight: [2.47916089 1.29120405] Bias: -1.0919411179447234 loss: 0.33171032479681595\n",
            "Round: 1772 Weight: [2.47918485 1.29121558] Bias: -1.0919496364567616 loss: 0.3317103169729774\n",
            "Round: 1773 Weight: [2.47920874 1.29122708] Bias: -1.091958132572246 loss: 0.33171030919017536\n",
            "Round: 1774 Weight: [2.47923257 1.29123855] Bias: -1.0919666063506355 loss: 0.33171030144819336\n",
            "Round: 1775 Weight: [2.47925633 1.29124998] Bias: -1.091975057851228 loss: 0.33171029374681643\n",
            "Round: 1776 Weight: [2.47928004 1.29126139] Bias: -1.091983487133161 loss: 0.33171028608583086\n",
            "Round: 1777 Weight: [2.47930368 1.29127277] Bias: -1.0919918942554125 loss: 0.3317102784650238\n",
            "Round: 1778 Weight: [2.47932726 1.29128412] Bias: -1.0920002792768002 loss: 0.3317102708841837\n",
            "Round: 1779 Weight: [2.47935078 1.29129544] Bias: -1.0920086422559832 loss: 0.3317102633431001\n",
            "Round: 1780 Weight: [2.47937424 1.29130672] Bias: -1.0920169832514617 loss: 0.33171025584156344\n",
            "Round: 1781 Weight: [2.47939763 1.29131798] Bias: -1.092025302321578 loss: 0.33171024837936575\n",
            "Round: 1782 Weight: [2.47942096 1.29132921] Bias: -1.0920335995245165 loss: 0.3317102409562996\n",
            "Round: 1783 Weight: [2.47944424 1.29134041] Bias: -1.0920418749183043 loss: 0.33171023357215906\n",
            "Round: 1784 Weight: [2.47946745 1.29135158] Bias: -1.0920501285608115 loss: 0.33171022622673924\n",
            "Round: 1785 Weight: [2.4794906  1.29136272] Bias: -1.092058360509752 loss: 0.3317102189198361\n",
            "Round: 1786 Weight: [2.47951369 1.29137383] Bias: -1.0920665708226838 loss: 0.3317102116512469\n",
            "Round: 1787 Weight: [2.47953672 1.29138492] Bias: -1.0920747595570088 loss: 0.33171020442077\n",
            "Round: 1788 Weight: [2.47955968 1.29139597] Bias: -1.0920829267699745 loss: 0.3317101972282045\n",
            "Round: 1789 Weight: [2.47958259 1.29140699] Bias: -1.0920910725186734 loss: 0.33171019007335106\n",
            "Round: 1790 Weight: [2.47960544 1.29141799] Bias: -1.0920991968600435 loss: 0.3317101829560111\n",
            "Round: 1791 Weight: [2.47962823 1.29142896] Bias: -1.0921072998508694 loss: 0.331710175875987\n",
            "Round: 1792 Weight: [2.47965096 1.29143989] Bias: -1.0921153815477822 loss: 0.33171016883308235\n",
            "Round: 1793 Weight: [2.47967362 1.2914508 ] Bias: -1.0921234420072599 loss: 0.3317101618271018\n",
            "Round: 1794 Weight: [2.47969623 1.29146168] Bias: -1.0921314812856278 loss: 0.33171015485785105\n",
            "Round: 1795 Weight: [2.47971878 1.29147253] Bias: -1.0921394994390596 loss: 0.3317101479251367\n",
            "Round: 1796 Weight: [2.47974127 1.29148336] Bias: -1.0921474965235771 loss: 0.3317101410287663\n",
            "Round: 1797 Weight: [2.47976371 1.29149415] Bias: -1.0921554725950506 loss: 0.33171013416854883\n",
            "Round: 1798 Weight: [2.47978608 1.29150492] Bias: -1.0921634277092 loss: 0.3317101273442938\n",
            "Round: 1799 Weight: [2.47980839 1.29151566] Bias: -1.0921713619215945 loss: 0.33171012055581195\n",
            "Round: 1800 Weight: [2.47983065 1.29152637] Bias: -1.0921792752876531 loss: 0.33171011380291515\n",
            "Round: 1801 Weight: [2.47985284 1.29153705] Bias: -1.0921871678626458 loss: 0.3317101070854159\n",
            "Round: 1802 Weight: [2.47987498 1.2915477 ] Bias: -1.092195039701693 loss: 0.33171010040312804\n",
            "Round: 1803 Weight: [2.47989706 1.29155833] Bias: -1.0922028908597667 loss: 0.33171009375586635\n",
            "Round: 1804 Weight: [2.47991909 1.29156893] Bias: -1.0922107213916903 loss: 0.3317100871434464\n",
            "Round: 1805 Weight: [2.47994105 1.2915795 ] Bias: -1.0922185313521393 loss: 0.33171008056568496\n",
            "Round: 1806 Weight: [2.47996296 1.29159004] Bias: -1.092226320795642 loss: 0.33171007402239944\n",
            "Round: 1807 Weight: [2.47998481 1.29160056] Bias: -1.0922340897765792 loss: 0.33171006751340876\n",
            "Round: 1808 Weight: [2.4800066  1.29161104] Bias: -1.0922418383491852 loss: 0.3317100610385322\n",
            "Round: 1809 Weight: [2.48002834 1.2916215 ] Bias: -1.092249566567548 loss: 0.33171005459759034\n",
            "Round: 1810 Weight: [2.48005001 1.29163194] Bias: -1.09225727448561 loss: 0.3317100481904046\n",
            "Round: 1811 Weight: [2.48007164 1.29164234] Bias: -1.0922649621571678 loss: 0.33171004181679753\n",
            "Round: 1812 Weight: [2.4800932  1.29165272] Bias: -1.0922726296358731 loss: 0.3317100354765924\n",
            "Round: 1813 Weight: [2.48011471 1.29166307] Bias: -1.092280276975233 loss: 0.3317100291696134\n",
            "Round: 1814 Weight: [2.48013616 1.29167339] Bias: -1.0922879042286104 loss: 0.33171002289568574\n",
            "Round: 1815 Weight: [2.48015756 1.29168369] Bias: -1.092295511449224 loss: 0.33171001665463584\n",
            "Round: 1816 Weight: [2.4801789  1.29169396] Bias: -1.0923030986901499 loss: 0.3317100104462904\n",
            "Round: 1817 Weight: [2.48020018 1.2917042 ] Bias: -1.09231066600432 loss: 0.33171000427047753\n",
            "Round: 1818 Weight: [2.48022141 1.29171442] Bias: -1.0923182134445244 loss: 0.33170999812702623\n",
            "Round: 1819 Weight: [2.48024258 1.29172461] Bias: -1.0923257410634106 loss: 0.33170999201576595\n",
            "Round: 1820 Weight: [2.48026369 1.29173477] Bias: -1.0923332489134845 loss: 0.3317099859365276\n",
            "Round: 1821 Weight: [2.48028476 1.2917449 ] Bias: -1.0923407370471103 loss: 0.3317099798891428\n",
            "Round: 1822 Weight: [2.48030576 1.29175501] Bias: -1.0923482055165115 loss: 0.331709973873444\n",
            "Round: 1823 Weight: [2.48032671 1.2917651 ] Bias: -1.0923556543737705 loss: 0.3317099678892644\n",
            "Round: 1824 Weight: [2.48034761 1.29177515] Bias: -1.0923630836708296 loss: 0.3317099619364384\n",
            "Round: 1825 Weight: [2.48036845 1.29178518] Bias: -1.0923704934594913 loss: 0.33170995601480113\n",
            "Round: 1826 Weight: [2.48038923 1.29179518] Bias: -1.0923778837914186 loss: 0.3317099501241883\n",
            "Round: 1827 Weight: [2.48040997 1.29180516] Bias: -1.0923852547181354 loss: 0.3317099442644371\n",
            "Round: 1828 Weight: [2.48043064 1.29181511] Bias: -1.0923926062910265 loss: 0.33170993843538515\n",
            "Round: 1829 Weight: [2.48045127 1.29182504] Bias: -1.092399938561339 loss: 0.331709932636871\n",
            "Round: 1830 Weight: [2.48047183 1.29183493] Bias: -1.0924072515801815 loss: 0.33170992686873396\n",
            "Round: 1831 Weight: [2.48049235 1.29184481] Bias: -1.0924145453985252 loss: 0.33170992113081443\n",
            "Round: 1832 Weight: [2.48051281 1.29185465] Bias: -1.0924218200672045 loss: 0.33170991542295347\n",
            "Round: 1833 Weight: [2.48053322 1.29186448] Bias: -1.0924290756369162 loss: 0.33170990974499315\n",
            "Round: 1834 Weight: [2.48055357 1.29187427] Bias: -1.0924363121582215 loss: 0.33170990409677614\n",
            "Round: 1835 Weight: [2.48057387 1.29188404] Bias: -1.092443529681545 loss: 0.3317098984781462\n",
            "Round: 1836 Weight: [2.48059412 1.29189378] Bias: -1.0924507282571758 loss: 0.3317098928889477\n",
            "Round: 1837 Weight: [2.48061432 1.2919035 ] Bias: -1.0924579079352679 loss: 0.3317098873290258\n",
            "Round: 1838 Weight: [2.48063446 1.2919132 ] Bias: -1.09246506876584 loss: 0.3317098817982267\n",
            "Round: 1839 Weight: [2.48065455 1.29192286] Bias: -1.0924722107987765 loss: 0.3317098762963974\n",
            "Round: 1840 Weight: [2.48067458 1.2919325 ] Bias: -1.092479334083828 loss: 0.3317098708233855\n",
            "Round: 1841 Weight: [2.48069456 1.29194212] Bias: -1.0924864386706101 loss: 0.3317098653790396\n",
            "Round: 1842 Weight: [2.4807145  1.29195171] Bias: -1.0924935246086065 loss: 0.3317098599632089\n",
            "Round: 1843 Weight: [2.48073437 1.29196128] Bias: -1.0925005919471669 loss: 0.33170985457574365\n",
            "Round: 1844 Weight: [2.4807542  1.29197082] Bias: -1.0925076407355083 loss: 0.33170984921649466\n",
            "Round: 1845 Weight: [2.48077398 1.29198034] Bias: -1.0925146710227158 loss: 0.33170984388531377\n",
            "Round: 1846 Weight: [2.4807937  1.29198983] Bias: -1.0925216828577422 loss: 0.3317098385820533\n",
            "Round: 1847 Weight: [2.48081337 1.2919993 ] Bias: -1.092528676289409 loss: 0.3317098333065664\n",
            "Round: 1848 Weight: [2.48083299 1.29200874] Bias: -1.0925356513664064 loss: 0.3317098280587075\n",
            "Round: 1849 Weight: [2.48085256 1.29201815] Bias: -1.0925426081372935 loss: 0.33170982283833095\n",
            "Round: 1850 Weight: [2.48087207 1.29202755] Bias: -1.0925495466504993 loss: 0.3317098176452928\n",
            "Round: 1851 Weight: [2.48089154 1.29203691] Bias: -1.0925564669543222 loss: 0.3317098124794489\n",
            "Round: 1852 Weight: [2.48091095 1.29204626] Bias: -1.0925633690969312 loss: 0.3317098073406567\n",
            "Round: 1853 Weight: [2.48093032 1.29205558] Bias: -1.0925702531263657 loss: 0.33170980222877394\n",
            "Round: 1854 Weight: [2.48094963 1.29206487] Bias: -1.0925771190905362 loss: 0.3317097971436592\n",
            "Round: 1855 Weight: [2.48096889 1.29207414] Bias: -1.0925839670372244 loss: 0.33170979208517176\n",
            "Round: 1856 Weight: [2.4809881  1.29208339] Bias: -1.0925907970140833 loss: 0.33170978705317195\n",
            "Round: 1857 Weight: [2.48100727 1.29209261] Bias: -1.0925976090686387 loss: 0.33170978204752033\n",
            "Round: 1858 Weight: [2.48102638 1.2921018 ] Bias: -1.092604403248288 loss: 0.3317097770680786\n",
            "Round: 1859 Weight: [2.48104544 1.29211098] Bias: -1.092611179600302 loss: 0.3317097721147089\n",
            "Round: 1860 Weight: [2.48106445 1.29212013] Bias: -1.0926179381718237 loss: 0.3317097671872746\n",
            "Round: 1861 Weight: [2.48108341 1.29212925] Bias: -1.0926246790098706 loss: 0.3317097622856391\n",
            "Round: 1862 Weight: [2.48110232 1.29213835] Bias: -1.092631402161333 loss: 0.33170975740966696\n",
            "Round: 1863 Weight: [2.48112118 1.29214743] Bias: -1.0926381076729759 loss: 0.3317097525592235\n",
            "Round: 1864 Weight: [2.48114    1.29215648] Bias: -1.0926447955914385 loss: 0.3317097477341744\n",
            "Round: 1865 Weight: [2.48115876 1.29216551] Bias: -1.0926514659632347 loss: 0.3317097429343864\n",
            "Round: 1866 Weight: [2.48117747 1.29217452] Bias: -1.092658118834754 loss: 0.3317097381597268\n",
            "Round: 1867 Weight: [2.48119614 1.2921835 ] Bias: -1.0926647542522612 loss: 0.33170973341006366\n",
            "Round: 1868 Weight: [2.48121476 1.29219246] Bias: -1.0926713722618968 loss: 0.3317097286852654\n",
            "Round: 1869 Weight: [2.48123332 1.29220139] Bias: -1.0926779729096776 loss: 0.33170972398520165\n",
            "Round: 1870 Weight: [2.48125184 1.29221031] Bias: -1.0926845562414969 loss: 0.33170971930974263\n",
            "Round: 1871 Weight: [2.48127031 1.2922192 ] Bias: -1.0926911223031248 loss: 0.3317097146587588\n",
            "Round: 1872 Weight: [2.48128873 1.29222806] Bias: -1.092697671140209 loss: 0.33170971003212185\n",
            "Round: 1873 Weight: [2.48130711 1.2922369 ] Bias: -1.0927042027982743 loss: 0.3317097054297037\n",
            "Round: 1874 Weight: [2.48132543 1.29224572] Bias: -1.0927107173227237 loss: 0.33170970085137724\n",
            "Round: 1875 Weight: [2.48134371 1.29225452] Bias: -1.0927172147588382 loss: 0.331709696297016\n",
            "Round: 1876 Weight: [2.48136194 1.29226329] Bias: -1.0927236951517774 loss: 0.3317096917664942\n",
            "Round: 1877 Weight: [2.48138012 1.29227204] Bias: -1.0927301585465798 loss: 0.33170968725968647\n",
            "Round: 1878 Weight: [2.48139826 1.29228077] Bias: -1.0927366049881633 loss: 0.3317096827764684\n",
            "Round: 1879 Weight: [2.48141634 1.29228947] Bias: -1.0927430345213252 loss: 0.3317096783167161\n",
            "Round: 1880 Weight: [2.48143438 1.29229815] Bias: -1.0927494471907426 loss: 0.3317096738803062\n",
            "Round: 1881 Weight: [2.48145237 1.29230681] Bias: -1.0927558430409732 loss: 0.33170966946711633\n",
            "Round: 1882 Weight: [2.48147032 1.29231545] Bias: -1.092762222116455 loss: 0.33170966507702443\n",
            "Round: 1883 Weight: [2.48148822 1.29232406] Bias: -1.092768584461507 loss: 0.3317096607099095\n",
            "Round: 1884 Weight: [2.48150607 1.29233265] Bias: -1.092774930120329 loss: 0.3317096563656505\n",
            "Round: 1885 Weight: [2.48152387 1.29234122] Bias: -1.0927812591370027 loss: 0.33170965204412756\n",
            "Round: 1886 Weight: [2.48154163 1.29234976] Bias: -1.092787571555492 loss: 0.33170964774522144\n",
            "Round: 1887 Weight: [2.48155934 1.29235829] Bias: -1.0927938674196425 loss: 0.3317096434688133\n",
            "Round: 1888 Weight: [2.481577   1.29236679] Bias: -1.0928001467731823 loss: 0.3317096392147851\n",
            "Round: 1889 Weight: [2.48159462 1.29237527] Bias: -1.0928064096597225 loss: 0.3317096349830193\n",
            "Round: 1890 Weight: [2.48161219 1.29238372] Bias: -1.0928126561227576 loss: 0.33170963077339893\n",
            "Round: 1891 Weight: [2.48162972 1.29239216] Bias: -1.0928188862056651 loss: 0.33170962658580794\n",
            "Round: 1892 Weight: [2.4816472  1.29240057] Bias: -1.0928250999517066 loss: 0.33170962242013047\n",
            "Round: 1893 Weight: [2.48166464 1.29240896] Bias: -1.092831297404028 loss: 0.33170961827625156\n",
            "Round: 1894 Weight: [2.48168202 1.29241733] Bias: -1.0928374786056592 loss: 0.3317096141540569\n",
            "Round: 1895 Weight: [2.48169937 1.29242567] Bias: -1.092843643599515 loss: 0.33170961005343264\n",
            "Round: 1896 Weight: [2.48171666 1.292434  ] Bias: -1.0928497924283957 loss: 0.3317096059742654\n",
            "Round: 1897 Weight: [2.48173392 1.2924423 ] Bias: -1.0928559251349865 loss: 0.3317096019164427\n",
            "Round: 1898 Weight: [2.48175112 1.29245058] Bias: -1.0928620417618586 loss: 0.33170959787985255\n",
            "Round: 1899 Weight: [2.48176829 1.29245884] Bias: -1.092868142351469 loss: 0.3317095938643833\n",
            "Round: 1900 Weight: [2.4817854  1.29246708] Bias: -1.092874226946161 loss: 0.3317095898699243\n",
            "Round: 1901 Weight: [2.48180248 1.29247529] Bias: -1.0928802955881651 loss: 0.3317095858963652\n",
            "Round: 1902 Weight: [2.4818195  1.29248349] Bias: -1.092886348319598 loss: 0.3317095819435963\n",
            "Round: 1903 Weight: [2.48183649 1.29249166] Bias: -1.0928923851824641 loss: 0.3317095780115085\n",
            "Round: 1904 Weight: [2.48185343 1.29249981] Bias: -1.0928984062186555 loss: 0.3317095740999934\n",
            "Round: 1905 Weight: [2.48187032 1.29250794] Bias: -1.0929044114699518 loss: 0.3317095702089427\n",
            "Round: 1906 Weight: [2.48188717 1.29251605] Bias: -1.092910400978021 loss: 0.3317095663382494\n",
            "Round: 1907 Weight: [2.48190398 1.29252414] Bias: -1.09291637478442 loss: 0.33170956248780653\n",
            "Round: 1908 Weight: [2.48192074 1.29253221] Bias: -1.0929223329305937 loss: 0.3317095586575077\n",
            "Round: 1909 Weight: [2.48193746 1.29254025] Bias: -1.0929282754578769 loss: 0.33170955484724723\n",
            "Round: 1910 Weight: [2.48195413 1.29254828] Bias: -1.0929342024074933 loss: 0.3317095510569202\n",
            "Round: 1911 Weight: [2.48197076 1.29255628] Bias: -1.0929401138205566 loss: 0.33170954728642177\n",
            "Round: 1912 Weight: [2.48198735 1.29256426] Bias: -1.09294600973807 loss: 0.331709543535648\n",
            "Round: 1913 Weight: [2.48200389 1.29257222] Bias: -1.092951890200928 loss: 0.3317095398044955\n",
            "Round: 1914 Weight: [2.48202039 1.29258016] Bias: -1.0929577552499152 loss: 0.3317095360928612\n",
            "Round: 1915 Weight: [2.48203685 1.29258808] Bias: -1.092963604925707 loss: 0.3317095324006427\n",
            "Round: 1916 Weight: [2.48205326 1.29259598] Bias: -1.09296943926887 loss: 0.33170952872773807\n",
            "Round: 1917 Weight: [2.48206963 1.29260386] Bias: -1.0929752583198629 loss: 0.33170952507404616\n",
            "Round: 1918 Weight: [2.48208596 1.29261172] Bias: -1.0929810621190355 loss: 0.3317095214394661\n",
            "Round: 1919 Weight: [2.48210225 1.29261955] Bias: -1.09298685070663 loss: 0.33170951782389757\n",
            "Round: 1920 Weight: [2.48211849 1.29262737] Bias: -1.0929926241227814 loss: 0.3317095142272408\n",
            "Round: 1921 Weight: [2.48213469 1.29263517] Bias: -1.092998382407517 loss: 0.33170951064939674\n",
            "Round: 1922 Weight: [2.48215085 1.29264294] Bias: -1.0930041256007568 loss: 0.3317095070902666\n",
            "Round: 1923 Weight: [2.48216696 1.2926507 ] Bias: -1.093009853742315 loss: 0.33170950354975226\n",
            "Round: 1924 Weight: [2.48218303 1.29265843] Bias: -1.0930155668718986 loss: 0.33170950002775595\n",
            "Round: 1925 Weight: [2.48219907 1.29266615] Bias: -1.093021265029109 loss: 0.33170949652418075\n",
            "Round: 1926 Weight: [2.48221505 1.29267384] Bias: -1.0930269482534412 loss: 0.33170949303892977\n",
            "Round: 1927 Weight: [2.482231   1.29268152] Bias: -1.0930326165842854 loss: 0.33170948957190716\n",
            "Round: 1928 Weight: [2.48224691 1.29268917] Bias: -1.093038270060926 loss: 0.33170948612301726\n",
            "Round: 1929 Weight: [2.48226277 1.29269681] Bias: -1.0930439087225428 loss: 0.3317094826921649\n",
            "Round: 1930 Weight: [2.48227859 1.29270442] Bias: -1.0930495326082106 loss: 0.33170947927925537\n",
            "Round: 1931 Weight: [2.48229437 1.29271201] Bias: -1.0930551417568999 loss: 0.33170947588419464\n",
            "Round: 1932 Weight: [2.48231011 1.29271959] Bias: -1.0930607362074773 loss: 0.33170947250688915\n",
            "Round: 1933 Weight: [2.48232581 1.29272714] Bias: -1.0930663159987055 loss: 0.3317094691472459\n",
            "Round: 1934 Weight: [2.48234147 1.29273468] Bias: -1.0930718811692437 loss: 0.3317094658051721\n",
            "Round: 1935 Weight: [2.48235709 1.29274219] Bias: -1.0930774317576477 loss: 0.3317094624805756\n",
            "Round: 1936 Weight: [2.48237266 1.29274969] Bias: -1.0930829678023704 loss: 0.33170945917336475\n",
            "Round: 1937 Weight: [2.4823882  1.29275717] Bias: -1.093088489341762 loss: 0.3317094558834485\n",
            "Round: 1938 Weight: [2.48240369 1.29276462] Bias: -1.0930939964140707 loss: 0.331709452610736\n",
            "Round: 1939 Weight: [2.48241914 1.29277206] Bias: -1.093099489057442 loss: 0.3317094493551372\n",
            "Round: 1940 Weight: [2.48243456 1.29277948] Bias: -1.0931049673099196 loss: 0.3317094461165622\n",
            "Round: 1941 Weight: [2.48244993 1.29278687] Bias: -1.0931104312094462 loss: 0.33170944289492194\n",
            "Round: 1942 Weight: [2.48246526 1.29279425] Bias: -1.0931158807938626 loss: 0.3317094396901273\n",
            "Round: 1943 Weight: [2.48248055 1.29280161] Bias: -1.093121316100909 loss: 0.3317094365020903\n",
            "Round: 1944 Weight: [2.48249581 1.29280895] Bias: -1.0931267371682247 loss: 0.33170943333072284\n",
            "Round: 1945 Weight: [2.48251102 1.29281627] Bias: -1.0931321440333486 loss: 0.3317094301759378\n",
            "Round: 1946 Weight: [2.48252619 1.29282357] Bias: -1.0931375367337195 loss: 0.3317094270376479\n",
            "Round: 1947 Weight: [2.48254132 1.29283086] Bias: -1.093142915306676 loss: 0.33170942391576685\n",
            "Round: 1948 Weight: [2.48255642 1.29283812] Bias: -1.0931482797894574 loss: 0.3317094208102086\n",
            "Round: 1949 Weight: [2.48257147 1.29284536] Bias: -1.0931536302192033 loss: 0.3317094177208874\n",
            "Round: 1950 Weight: [2.48258648 1.29285259] Bias: -1.0931589666329544 loss: 0.3317094146477185\n",
            "Round: 1951 Weight: [2.48260146 1.2928598 ] Bias: -1.0931642890676527 loss: 0.33170941159061695\n",
            "Round: 1952 Weight: [2.48261639 1.29286698] Bias: -1.0931695975601416 loss: 0.33170940854949854\n",
            "Round: 1953 Weight: [2.48263129 1.29287415] Bias: -1.093174892147166 loss: 0.3317094055242796\n",
            "Round: 1954 Weight: [2.48264615 1.2928813 ] Bias: -1.0931801728653732 loss: 0.3317094025148766\n",
            "Round: 1955 Weight: [2.48266097 1.29288843] Bias: -1.093185439751312 loss: 0.3317093995212068\n",
            "Round: 1956 Weight: [2.48267575 1.29289555] Bias: -1.0931906928414348 loss: 0.33170939654318765\n",
            "Round: 1957 Weight: [2.48269049 1.29290264] Bias: -1.0931959321720959 loss: 0.3317093935807371\n",
            "Round: 1958 Weight: [2.48270519 1.29290972] Bias: -1.0932011577795528 loss: 0.33170939063377364\n",
            "Round: 1959 Weight: [2.48271986 1.29291677] Bias: -1.093206369699967 loss: 0.33170938770221603\n",
            "Round: 1960 Weight: [2.48273448 1.29292381] Bias: -1.0932115679694026 loss: 0.33170938478598344\n",
            "Round: 1961 Weight: [2.48274907 1.29293083] Bias: -1.0932167526238281 loss: 0.33170938188499566\n",
            "Round: 1962 Weight: [2.48276362 1.29293783] Bias: -1.093221923699116 loss: 0.33170937899917285\n",
            "Round: 1963 Weight: [2.48277813 1.29294482] Bias: -1.0932270812310434 loss: 0.3317093761284354\n",
            "Round: 1964 Weight: [2.4827926  1.29295178] Bias: -1.0932322252552917 loss: 0.3317093732727042\n",
            "Round: 1965 Weight: [2.48280704 1.29295873] Bias: -1.0932373558074473 loss: 0.3317093704319008\n",
            "Round: 1966 Weight: [2.48282144 1.29296566] Bias: -1.0932424729230017 loss: 0.33170936760594677\n",
            "Round: 1967 Weight: [2.4828358  1.29297257] Bias: -1.093247576637352 loss: 0.3317093647947644\n",
            "Round: 1968 Weight: [2.48285012 1.29297946] Bias: -1.0932526669858005 loss: 0.3317093619982762\n",
            "Round: 1969 Weight: [2.4828644  1.29298634] Bias: -1.093257744003556 loss: 0.3317093592164053\n",
            "Round: 1970 Weight: [2.48287865 1.29299319] Bias: -1.0932628077257334 loss: 0.33170935644907507\n",
            "Round: 1971 Weight: [2.48289286 1.29300003] Bias: -1.0932678581873536 loss: 0.33170935369620924\n",
            "Round: 1972 Weight: [2.48290703 1.29300685] Bias: -1.0932728954233446 loss: 0.331709350957732\n",
            "Round: 1973 Weight: [2.48292117 1.29301365] Bias: -1.0932779194685411 loss: 0.33170934823356796\n",
            "Round: 1974 Weight: [2.48293527 1.29302044] Bias: -1.0932829303576852 loss: 0.33170934552364223\n",
            "Round: 1975 Weight: [2.48294933 1.29302721] Bias: -1.0932879281254262 loss: 0.33170934282788\n",
            "Round: 1976 Weight: [2.48296336 1.29303396] Bias: -1.0932929128063211 loss: 0.3317093401462073\n",
            "Round: 1977 Weight: [2.48297735 1.29304069] Bias: -1.0932978844348353 loss: 0.33170933747855014\n",
            "Round: 1978 Weight: [2.4829913 1.2930474] Bias: -1.0933028430453422 loss: 0.3317093348248352\n",
            "Round: 1979 Weight: [2.48300521 1.2930541 ] Bias: -1.0933077886721232 loss: 0.3317093321849892\n",
            "Round: 1980 Weight: [2.48301909 1.29306078] Bias: -1.093312721349369 loss: 0.3317093295589398\n",
            "Round: 1981 Weight: [2.48303294 1.29306744] Bias: -1.093317641111179 loss: 0.33170932694661454\n",
            "Round: 1982 Weight: [2.48304674 1.29307408] Bias: -1.0933225479915616 loss: 0.3317093243479415\n",
            "Round: 1983 Weight: [2.48306051 1.29308071] Bias: -1.093327442024435 loss: 0.3317093217628493\n",
            "Round: 1984 Weight: [2.48307425 1.29308732] Bias: -1.093332323243627 loss: 0.33170931919126656\n",
            "Round: 1985 Weight: [2.48308795 1.29309391] Bias: -1.0933371916828754 loss: 0.3317093166331226\n",
            "Round: 1986 Weight: [2.48310161 1.29310049] Bias: -1.0933420473758277 loss: 0.3317093140883471\n",
            "Round: 1987 Weight: [2.48311524 1.29310705] Bias: -1.0933468903560426 loss: 0.33170931155687\n",
            "Round: 1988 Weight: [2.48312883 1.29311359] Bias: -1.093351720656989 loss: 0.3317093090386216\n",
            "Round: 1989 Weight: [2.48314238 1.29312011] Bias: -1.0933565383120465 loss: 0.33170930653353264\n",
            "Round: 1990 Weight: [2.4831559  1.29312662] Bias: -1.0933613433545064 loss: 0.3317093040415341\n",
            "Round: 1991 Weight: [2.48316939 1.29313311] Bias: -1.093366135817571 loss: 0.3317093015625575\n",
            "Round: 1992 Weight: [2.48318284 1.29313958] Bias: -1.0933709157343545 loss: 0.3317092990965347\n",
            "Round: 1993 Weight: [2.48319625 1.29314603] Bias: -1.0933756831378827 loss: 0.3317092966433976\n",
            "Round: 1994 Weight: [2.48320963 1.29315247] Bias: -1.0933804380610939 loss: 0.33170929420307893\n",
            "Round: 1995 Weight: [2.48322298 1.29315889] Bias: -1.0933851805368384 loss: 0.33170929177551145\n",
            "Round: 1996 Weight: [2.48323629 1.2931653 ] Bias: -1.0933899105978793 loss: 0.3317092893606284\n",
            "Round: 1997 Weight: [2.48324956 1.29317169] Bias: -1.0933946282768923 loss: 0.3317092869583633\n",
            "Round: 1998 Weight: [2.4832628  1.29317806] Bias: -1.0933993336064665 loss: 0.33170928456865023\n",
            "Round: 1999 Weight: [2.48327601 1.29318441] Bias: -1.0934040266191039 loss: 0.33170928219142326\n",
            "Round: 2000 Weight: [2.48328918 1.29319075] Bias: -1.0934087073472205 loss: 0.3317092798266171\n",
            "Round: 2001 Weight: [2.48330231 1.29319707] Bias: -1.093413375823146 loss: 0.3317092774741666\n",
            "Round: 2002 Weight: [2.48331542 1.29320338] Bias: -1.0934180320791234 loss: 0.33170927513400716\n",
            "Round: 2003 Weight: [2.48332848 1.29320967] Bias: -1.093422676147311 loss: 0.3317092728060743\n",
            "Round: 2004 Weight: [2.48334152 1.29321594] Bias: -1.093427308059781 loss: 0.3317092704903042\n",
            "Round: 2005 Weight: [2.48335452 1.2932222 ] Bias: -1.0934319278485203 loss: 0.33170926818663293\n",
            "Round: 2006 Weight: [2.48336748 1.29322844] Bias: -1.0934365355454307 loss: 0.33170926589499716\n",
            "Round: 2007 Weight: [2.48338041 1.29323466] Bias: -1.0934411311823296 loss: 0.3317092636153339\n",
            "Round: 2008 Weight: [2.48339331 1.29324087] Bias: -1.0934457147909493 loss: 0.33170926134758066\n",
            "Round: 2009 Weight: [2.48340617 1.29324706] Bias: -1.093450286402938 loss: 0.33170925909167487\n",
            "Round: 2010 Weight: [2.483419   1.29325323] Bias: -1.0934548460498599 loss: 0.3317092568475545\n",
            "Round: 2011 Weight: [2.4834318  1.29325939] Bias: -1.0934593937631947 loss: 0.33170925461515777\n",
            "Round: 2012 Weight: [2.48344456 1.29326553] Bias: -1.093463929574339 loss: 0.3317092523944234\n",
            "Round: 2013 Weight: [2.48345729 1.29327166] Bias: -1.0934684535146055 loss: 0.33170925018529035\n",
            "Round: 2014 Weight: [2.48346999 1.29327777] Bias: -1.0934729656152244 loss: 0.3317092479876979\n",
            "Round: 2015 Weight: [2.48348265 1.29328386] Bias: -1.093477465907342 loss: 0.33170924580158545\n",
            "Round: 2016 Weight: [2.48349529 1.29328994] Bias: -1.0934819544220225 loss: 0.3317092436268931\n",
            "Round: 2017 Weight: [2.48350788 1.293296  ] Bias: -1.093486431190247 loss: 0.33170924146356084\n",
            "Round: 2018 Weight: [2.48352045 1.29330205] Bias: -1.0934908962429146 loss: 0.33170923931152935\n",
            "Round: 2019 Weight: [2.48353298 1.29330808] Bias: -1.0934953496108424 loss: 0.3317092371707394\n",
            "Round: 2020 Weight: [2.48354548 1.29331409] Bias: -1.093499791324765 loss: 0.33170923504113226\n",
            "Round: 2021 Weight: [2.48355794 1.29332009] Bias: -1.0935042214153363 loss: 0.33170923292264926\n",
            "Round: 2022 Weight: [2.48357038 1.29332608] Bias: -1.093508639913128 loss: 0.3317092308152322\n",
            "Round: 2023 Weight: [2.48358278 1.29333204] Bias: -1.0935130468486307 loss: 0.331709228718823\n",
            "Round: 2024 Weight: [2.48359515 1.293338  ] Bias: -1.0935174422522542 loss: 0.3317092266333644\n",
            "Round: 2025 Weight: [2.48360748 1.29334393] Bias: -1.0935218261543274 loss: 0.3317092245587986\n",
            "Round: 2026 Weight: [2.48361979 1.29334985] Bias: -1.0935261985850986 loss: 0.331709222495069\n",
            "Round: 2027 Weight: [2.48363206 1.29335576] Bias: -1.0935305595747358 loss: 0.33170922044211865\n",
            "Round: 2028 Weight: [2.4836443  1.29336165] Bias: -1.093534909153327 loss: 0.3317092183998911\n",
            "Round: 2029 Weight: [2.48365651 1.29336753] Bias: -1.0935392473508803 loss: 0.33170921636833045\n",
            "Round: 2030 Weight: [2.48366868 1.29337338] Bias: -1.0935435741973236 loss: 0.33170921434738054\n",
            "Round: 2031 Weight: [2.48368082 1.29337923] Bias: -1.093547889722506 loss: 0.3317092123369862\n",
            "Round: 2032 Weight: [2.48369294 1.29338506] Bias: -1.0935521939561967 loss: 0.3317092103370917\n",
            "Round: 2033 Weight: [2.48370502 1.29339087] Bias: -1.0935564869280865 loss: 0.3317092083476426\n",
            "Round: 2034 Weight: [2.48371707 1.29339667] Bias: -1.0935607686677868 loss: 0.3317092063685838\n",
            "Round: 2035 Weight: [2.48372908 1.29340245] Bias: -1.0935650392048308 loss: 0.3317092043998612\n",
            "Round: 2036 Weight: [2.48374107 1.29340822] Bias: -1.0935692985686731 loss: 0.33170920244142055\n",
            "Round: 2037 Weight: [2.48375302 1.29341397] Bias: -1.09357354678869 loss: 0.33170920049320823\n",
            "Round: 2038 Weight: [2.48376495 1.29341971] Bias: -1.09357778389418 loss: 0.3317091985551704\n",
            "Round: 2039 Weight: [2.48377684 1.29342543] Bias: -1.0935820099143636 loss: 0.33170919662725407\n",
            "Round: 2040 Weight: [2.4837887  1.29343114] Bias: -1.093586224878384 loss: 0.33170919470940613\n",
            "Round: 2041 Weight: [2.48380053 1.29343684] Bias: -1.093590428815307 loss: 0.33170919280157385\n",
            "Round: 2042 Weight: [2.48381233 1.29344251] Bias: -1.0935946217541213 loss: 0.33170919090370504\n",
            "Round: 2043 Weight: [2.4838241  1.29344818] Bias: -1.093598803723738 loss: 0.33170918901574736\n",
            "Round: 2044 Weight: [2.48383584 1.29345383] Bias: -1.0936029747529925 loss: 0.33170918713764885\n",
            "Round: 2045 Weight: [2.48384754 1.29345946] Bias: -1.093607134870643 loss: 0.3317091852693582\n",
            "Round: 2046 Weight: [2.48385922 1.29346508] Bias: -1.0936112841053718 loss: 0.331709183410824\n",
            "Round: 2047 Weight: [2.48387086 1.29347068] Bias: -1.0936154224857846 loss: 0.331709181561995\n",
            "Round: 2048 Weight: [2.48388248 1.29347627] Bias: -1.0936195500404116 loss: 0.3317091797228206\n",
            "Round: 2049 Weight: [2.48389407 1.29348185] Bias: -1.093623666797707 loss: 0.3317091778932502\n",
            "Round: 2050 Weight: [2.48390562 1.29348741] Bias: -1.09362777278605 loss: 0.33170917607323364\n",
            "Round: 2051 Weight: [2.48391714 1.29349295] Bias: -1.0936318680337438 loss: 0.3317091742627208\n",
            "Round: 2052 Weight: [2.48392864 1.29349849] Bias: -1.0936359525690171 loss: 0.33170917246166204\n",
            "Round: 2053 Weight: [2.4839401 1.293504 ] Bias: -1.0936400264200237 loss: 0.3317091706700078\n",
            "Round: 2054 Weight: [2.48395154 1.29350951] Bias: -1.093644089614842 loss: 0.33170916888770907\n",
            "Round: 2055 Weight: [2.48396294 1.29351499] Bias: -1.093648142181477 loss: 0.33170916711471665\n",
            "Round: 2056 Weight: [2.48397432 1.29352047] Bias: -1.0936521841478586 loss: 0.33170916535098205\n",
            "Round: 2057 Weight: [2.48398566 1.29352593] Bias: -1.093656215541843 loss: 0.33170916359645675\n",
            "Round: 2058 Weight: [2.48399698 1.29353137] Bias: -1.0936602363912125 loss: 0.33170916185109245\n",
            "Round: 2059 Weight: [2.48400826 1.2935368 ] Bias: -1.0936642467236755 loss: 0.33170916011484136\n",
            "Round: 2060 Weight: [2.48401952 1.29354222] Bias: -1.093668246566867 loss: 0.3317091583876558\n",
            "Round: 2061 Weight: [2.48403074 1.29354762] Bias: -1.0936722359483488 loss: 0.33170915666948825\n",
            "Round: 2062 Weight: [2.48404194 1.29355301] Bias: -1.0936762148956098 loss: 0.33170915496029163\n",
            "Round: 2063 Weight: [2.48405311 1.29355839] Bias: -1.0936801834360657 loss: 0.33170915326001904\n",
            "Round: 2064 Weight: [2.48406425 1.29356375] Bias: -1.0936841415970595 loss: 0.3317091515686235\n",
            "Round: 2065 Weight: [2.48407536 1.29356909] Bias: -1.093688089405862 loss: 0.33170914988605904\n",
            "Round: 2066 Weight: [2.48408644 1.29357443] Bias: -1.0936920268896715 loss: 0.3317091482122792\n",
            "Round: 2067 Weight: [2.48409749 1.29357974] Bias: -1.0936959540756144 loss: 0.3317091465472379\n",
            "Round: 2068 Weight: [2.48410851 1.29358505] Bias: -1.0936998709907446 loss: 0.33170914489088954\n",
            "Round: 2069 Weight: [2.48411951 1.29359034] Bias: -1.093703777662045 loss: 0.3317091432431888\n",
            "Round: 2070 Weight: [2.48413047 1.29359562] Bias: -1.0937076741164269 loss: 0.3317091416040902\n",
            "Round: 2071 Weight: [2.48414141 1.29360088] Bias: -1.0937115603807297 loss: 0.33170913997354895\n",
            "Round: 2072 Weight: [2.48415232 1.29360613] Bias: -1.093715436481722 loss: 0.3317091383515201\n",
            "Round: 2073 Weight: [2.4841632  1.29361136] Bias: -1.0937193024461018 loss: 0.3317091367379593\n",
            "Round: 2074 Weight: [2.48417405 1.29361659] Bias: -1.0937231583004958 loss: 0.3317091351328221\n",
            "Round: 2075 Weight: [2.48418487 1.29362179] Bias: -1.0937270040714604 loss: 0.33170913353606457\n",
            "Round: 2076 Weight: [2.48419567 1.29362699] Bias: -1.0937308397854817 loss: 0.33170913194764273\n",
            "Round: 2077 Weight: [2.48420643 1.29363217] Bias: -1.0937346654689755 loss: 0.3317091303675131\n",
            "Round: 2078 Weight: [2.48421717 1.29363734] Bias: -1.0937384811482875 loss: 0.3317091287956323\n",
            "Round: 2079 Weight: [2.48422788 1.29364249] Bias: -1.0937422868496938 loss: 0.3317091272319573\n",
            "Round: 2080 Weight: [2.48423856 1.29364763] Bias: -1.0937460825994008 loss: 0.33170912567644467\n",
            "Round: 2081 Weight: [2.48424922 1.29365276] Bias: -1.0937498684235456 loss: 0.33170912412905235\n",
            "Round: 2082 Weight: [2.48425984 1.29365787] Bias: -1.0937536443481957 loss: 0.3317091225897376\n",
            "Round: 2083 Weight: [2.48427044 1.29366297] Bias: -1.09375741039935 loss: 0.33170912105845823\n",
            "Round: 2084 Weight: [2.48428101 1.29366806] Bias: -1.093761166602938 loss: 0.33170911953517207\n",
            "Round: 2085 Weight: [2.48429156 1.29367314] Bias: -1.0937649129848215 loss: 0.3317091180198373\n",
            "Round: 2086 Weight: [2.48430207 1.2936782 ] Bias: -1.0937686495707926 loss: 0.33170911651241275\n",
            "Round: 2087 Weight: [2.48431256 1.29368324] Bias: -1.0937723763865757 loss: 0.33170911501285655\n",
            "Round: 2088 Weight: [2.48432302 1.29368828] Bias: -1.093776093457827 loss: 0.3317091135211278\n",
            "Round: 2089 Weight: [2.48433345 1.2936933 ] Bias: -1.0937798008101347 loss: 0.3317091120371855\n",
            "Round: 2090 Weight: [2.48434386 1.29369831] Bias: -1.0937834984690196 loss: 0.331709110560989\n",
            "Round: 2091 Weight: [2.48435424 1.2937033 ] Bias: -1.0937871864599342 loss: 0.33170910909249773\n",
            "Round: 2092 Weight: [2.48436459 1.29370828] Bias: -1.0937908648082642 loss: 0.3317091076316715\n",
            "Round: 2093 Weight: [2.48437492 1.29371325] Bias: -1.0937945335393278 loss: 0.33170910617846994\n",
            "Round: 2094 Weight: [2.48438521 1.29371821] Bias: -1.0937981926783764 loss: 0.33170910473285353\n",
            "Round: 2095 Weight: [2.48439549 1.29372315] Bias: -1.0938018422505944 loss: 0.3317091032947824\n",
            "Round: 2096 Weight: [2.48440573 1.29372808] Bias: -1.0938054822810994 loss: 0.3317091018642171\n",
            "Round: 2097 Weight: [2.48441595 1.293733  ] Bias: -1.0938091127949428 loss: 0.3317091004411185\n",
            "Round: 2098 Weight: [2.48442614 1.2937379 ] Bias: -1.093812733817109 loss: 0.3317090990254475\n",
            "Round: 2099 Weight: [2.4844363  1.29374279] Bias: -1.0938163453725174 loss: 0.33170909761716516\n",
            "Round: 2100 Weight: [2.48444644 1.29374767] Bias: -1.0938199474860204 loss: 0.331709096216233\n",
            "Round: 2101 Weight: [2.48445655 1.29375254] Bias: -1.0938235401824052 loss: 0.33170909482261257\n",
            "Round: 2102 Weight: [2.48446664 1.29375739] Bias: -1.0938271234863932 loss: 0.33170909343626553\n",
            "Round: 2103 Weight: [2.48447669 1.29376223] Bias: -1.0938306974226404 loss: 0.3317090920571539\n",
            "Round: 2104 Weight: [2.48448673 1.29376706] Bias: -1.0938342620157375 loss: 0.33170909068523985\n",
            "Round: 2105 Weight: [2.48449673 1.29377187] Bias: -1.0938378172902103 loss: 0.3317090893204859\n",
            "Round: 2106 Weight: [2.48450671 1.29377668] Bias: -1.0938413632705193 loss: 0.3317090879628544\n",
            "Round: 2107 Weight: [2.48451666 1.29378147] Bias: -1.0938448999810606 loss: 0.3317090866123082\n",
            "Round: 2108 Weight: [2.48452659 1.29378624] Bias: -1.0938484274461657 loss: 0.33170908526881016\n",
            "Round: 2109 Weight: [2.48453649 1.29379101] Bias: -1.0938519456901017 loss: 0.3317090839323237\n",
            "Round: 2110 Weight: [2.48454637 1.29379576] Bias: -1.0938554547370716 loss: 0.33170908260281173\n",
            "Round: 2111 Weight: [2.48455622 1.2938005 ] Bias: -1.0938589546112139 loss: 0.33170908128023824\n",
            "Round: 2112 Weight: [2.48456604 1.29380523] Bias: -1.0938624453366037 loss: 0.3317090799645666\n",
            "Round: 2113 Weight: [2.48457584 1.29380994] Bias: -1.0938659269372524 loss: 0.33170907865576105\n",
            "Round: 2114 Weight: [2.48458561 1.29381465] Bias: -1.0938693994371078 loss: 0.3317090773537855\n",
            "Round: 2115 Weight: [2.48459536 1.29381934] Bias: -1.0938728628600543 loss: 0.3317090760586043\n",
            "Round: 2116 Weight: [2.48460508 1.29382402] Bias: -1.0938763172299129 loss: 0.33170907477018186\n",
            "Round: 2117 Weight: [2.48461478 1.29382868] Bias: -1.093879762570442 loss: 0.3317090734884829\n",
            "Round: 2118 Weight: [2.48462445 1.29383334] Bias: -1.0938831989053368 loss: 0.33170907221347223\n",
            "Round: 2119 Weight: [2.4846341  1.29383798] Bias: -1.0938866262582303 loss: 0.331709070945115\n",
            "Round: 2120 Weight: [2.48464372 1.29384261] Bias: -1.0938900446526925 loss: 0.33170906968337627\n",
            "Round: 2121 Weight: [2.48465331 1.29384723] Bias: -1.0938934541122312 loss: 0.33170906842822157\n",
            "Round: 2122 Weight: [2.48466288 1.29385183] Bias: -1.0938968546602923 loss: 0.33170906717961646\n",
            "Round: 2123 Weight: [2.48467243 1.29385643] Bias: -1.0939002463202594 loss: 0.33170906593752675\n",
            "Round: 2124 Weight: [2.48468195 1.29386101] Bias: -1.0939036291154542 loss: 0.33170906470191824\n",
            "Round: 2125 Weight: [2.48469145 1.29386558] Bias: -1.0939070030691371 loss: 0.33170906347275714\n",
            "Round: 2126 Weight: [2.48470092 1.29387014] Bias: -1.0939103682045066 loss: 0.3317090622500098\n",
            "Round: 2127 Weight: [2.48471036 1.29387468] Bias: -1.0939137245447002 loss: 0.3317090610336426\n",
            "Round: 2128 Weight: [2.48471979 1.29387921] Bias: -1.093917072112794 loss: 0.3317090598236223\n",
            "Round: 2129 Weight: [2.48472918 1.29388374] Bias: -1.093920410931803 loss: 0.3317090586199157\n",
            "Round: 2130 Weight: [2.48473855 1.29388825] Bias: -1.0939237410246818 loss: 0.3317090574224896\n",
            "Round: 2131 Weight: [2.4847479  1.29389275] Bias: -1.0939270624143238 loss: 0.33170905623131147\n",
            "Round: 2132 Weight: [2.48475723 1.29389723] Bias: -1.0939303751235623 loss: 0.33170905504634857\n",
            "Round: 2133 Weight: [2.48476653 1.29390171] Bias: -1.09393367917517 loss: 0.33170905386756816\n",
            "Round: 2134 Weight: [2.4847758  1.29390617] Bias: -1.0939369745918592 loss: 0.33170905269493833\n",
            "Round: 2135 Weight: [2.48478505 1.29391062] Bias: -1.0939402613962828 loss: 0.33170905152842667\n",
            "Round: 2136 Weight: [2.48479428 1.29391506] Bias: -1.093943539611033 loss: 0.3317090503680012\n",
            "Round: 2137 Weight: [2.48480348 1.29391949] Bias: -1.0939468092586433 loss: 0.33170904921363037\n",
            "Round: 2138 Weight: [2.48481266 1.29392391] Bias: -1.0939500703615865 loss: 0.3317090480652823\n",
            "Round: 2139 Weight: [2.48482181 1.29392831] Bias: -1.093953322942277 loss: 0.33170904692292563\n",
            "Round: 2140 Weight: [2.48483094 1.29393271] Bias: -1.0939565670230695 loss: 0.3317090457865289\n",
            "Round: 2141 Weight: [2.48484005 1.29393709] Bias: -1.0939598026262596 loss: 0.33170904465606105\n",
            "Round: 2142 Weight: [2.48484913 1.29394146] Bias: -1.0939630297740839 loss: 0.33170904353149117\n",
            "Round: 2143 Weight: [2.48485819 1.29394582] Bias: -1.0939662484887205 loss: 0.33170904241278837\n",
            "Round: 2144 Weight: [2.48486723 1.29395017] Bias: -1.0939694587922888 loss: 0.331709041299922\n",
            "Round: 2145 Weight: [2.48487624 1.29395451] Bias: -1.0939726607068498 loss: 0.33170904019286157\n",
            "Round: 2146 Weight: [2.48488523 1.29395883] Bias: -1.0939758542544062 loss: 0.33170903909157656\n",
            "Round: 2147 Weight: [2.48489419 1.29396315] Bias: -1.0939790394569027 loss: 0.33170903799603724\n",
            "Round: 2148 Weight: [2.48490313 1.29396745] Bias: -1.0939822163362254 loss: 0.3317090369062132\n",
            "Round: 2149 Weight: [2.48491205 1.29397174] Bias: -1.0939853849142034 loss: 0.33170903582207456\n",
            "Round: 2150 Weight: [2.48492094 1.29397602] Bias: -1.0939885452126077 loss: 0.33170903474359187\n",
            "Round: 2151 Weight: [2.48492982 1.29398029] Bias: -1.0939916972531518 loss: 0.3317090336707354\n",
            "Round: 2152 Weight: [2.48493866 1.29398455] Bias: -1.093994841057492 loss: 0.33170903260347584\n",
            "Round: 2153 Weight: [2.48494749 1.29398879] Bias: -1.0939979766472272 loss: 0.3317090315417838\n",
            "Round: 2154 Weight: [2.48495629 1.29399303] Bias: -1.0940011040438995 loss: 0.3317090304856304\n",
            "Round: 2155 Weight: [2.48496507 1.29399726] Bias: -1.0940042232689937 loss: 0.33170902943498654\n",
            "Round: 2156 Weight: [2.48497383 1.29400147] Bias: -1.0940073343439385 loss: 0.3317090283898235\n",
            "Round: 2157 Weight: [2.48498256 1.29400567] Bias: -1.0940104372901052 loss: 0.33170902735011265\n",
            "Round: 2158 Weight: [2.48499127 1.29400986] Bias: -1.0940135321288094 loss: 0.3317090263158254\n",
            "Round: 2159 Weight: [2.48499996 1.29401404] Bias: -1.0940166188813099 loss: 0.33170902528693363\n",
            "Round: 2160 Weight: [2.48500862 1.29401821] Bias: -1.0940196975688097 loss: 0.33170902426340887\n",
            "Round: 2161 Weight: [2.48501727 1.29402237] Bias: -1.0940227682124555 loss: 0.33170902324522333\n",
            "Round: 2162 Weight: [2.48502589 1.29402652] Bias: -1.0940258308333384 loss: 0.3317090222323489\n",
            "Round: 2163 Weight: [2.48503448 1.29403066] Bias: -1.0940288854524938 loss: 0.3317090212247581\n",
            "Round: 2164 Weight: [2.48504306 1.29403479] Bias: -1.0940319320909015 loss: 0.33170902022242305\n",
            "Round: 2165 Weight: [2.48505161 1.2940389 ] Bias: -1.0940349707694859 loss: 0.3317090192253164\n",
            "Round: 2166 Weight: [2.48506014 1.29404301] Bias: -1.094038001509116 loss: 0.331709018233411\n",
            "Round: 2167 Weight: [2.48506865 1.2940471 ] Bias: -1.094041024330606 loss: 0.33170901724667934\n",
            "Round: 2168 Weight: [2.48507714 1.29405118] Bias: -1.094044039254715 loss: 0.3317090162650947\n",
            "Round: 2169 Weight: [2.4850856  1.29405526] Bias: -1.0940470463021474 loss: 0.33170901528863006\n",
            "Round: 2170 Weight: [2.48509404 1.29405932] Bias: -1.0940500454935527 loss: 0.3317090143172587\n",
            "Round: 2171 Weight: [2.48510246 1.29406337] Bias: -1.094053036849526 loss: 0.33170901335095393\n",
            "Round: 2172 Weight: [2.48511086 1.29406741] Bias: -1.0940560203906085 loss: 0.3317090123896893\n",
            "Round: 2173 Weight: [2.48511923 1.29407144] Bias: -1.0940589961372862 loss: 0.3317090114334386\n",
            "Round: 2174 Weight: [2.48512759 1.29407546] Bias: -1.094061964109992 loss: 0.33170901048217566\n",
            "Round: 2175 Weight: [2.48513592 1.29407947] Bias: -1.0940649243291045 loss: 0.3317090095358743\n",
            "Round: 2176 Weight: [2.48514423 1.29408347] Bias: -1.0940678768149483 loss: 0.3317090085945086\n",
            "Round: 2177 Weight: [2.48515252 1.29408746] Bias: -1.0940708215877946 loss: 0.33170900765805267\n",
            "Round: 2178 Weight: [2.48516078 1.29409144] Bias: -1.094073758667861 loss: 0.3317090067264812\n",
            "Round: 2179 Weight: [2.48516903 1.29409541] Bias: -1.0940766880753119 loss: 0.3317090057997684\n",
            "Round: 2180 Weight: [2.48517725 1.29409936] Bias: -1.0940796098302583 loss: 0.33170900487788907\n",
            "Round: 2181 Weight: [2.48518546 1.29410331] Bias: -1.0940825239527583 loss: 0.3317090039608178\n",
            "Round: 2182 Weight: [2.48519364 1.29410725] Bias: -1.0940854304628171 loss: 0.3317090030485295\n",
            "Round: 2183 Weight: [2.4852018  1.29411118] Bias: -1.094088329380387 loss: 0.3317090021409994\n",
            "Round: 2184 Weight: [2.48520993 1.29411509] Bias: -1.0940912207253672 loss: 0.3317090012382024\n",
            "Round: 2185 Weight: [2.48521805 1.294119  ] Bias: -1.0940941045176056 loss: 0.33170900034011375\n",
            "Round: 2186 Weight: [2.48522615 1.29412289] Bias: -1.0940969807768965 loss: 0.3317089994467091\n",
            "Round: 2187 Weight: [2.48523422 1.29412678] Bias: -1.0940998495229828 loss: 0.3317089985579639\n",
            "Round: 2188 Weight: [2.48524227 1.29413066] Bias: -1.0941027107755548 loss: 0.3317089976738536\n",
            "Round: 2189 Weight: [2.48525031 1.29413452] Bias: -1.094105564554251 loss: 0.3317089967943542\n",
            "Round: 2190 Weight: [2.48525832 1.29413838] Bias: -1.0941084108786583 loss: 0.33170899591944175\n",
            "Round: 2191 Weight: [2.48526631 1.29414222] Bias: -1.0941112497683116 loss: 0.33170899504909196\n",
            "Round: 2192 Weight: [2.48527428 1.29414606] Bias: -1.0941140812426948 loss: 0.33170899418328126\n",
            "Round: 2193 Weight: [2.48528223 1.29414988] Bias: -1.0941169053212398 loss: 0.3317089933219857\n",
            "Round: 2194 Weight: [2.48529016 1.2941537 ] Bias: -1.0941197220233276 loss: 0.33170899246518204\n",
            "Round: 2195 Weight: [2.48529806 1.2941575 ] Bias: -1.094122531368288 loss: 0.33170899161284656\n",
            "Round: 2196 Weight: [2.48530595 1.2941613 ] Bias: -1.0941253333754 loss: 0.3317089907649559\n",
            "Round: 2197 Weight: [2.48531382 1.29416508] Bias: -1.0941281280638913 loss: 0.331708989921487\n",
            "Round: 2198 Weight: [2.48532166 1.29416886] Bias: -1.094130915452939 loss: 0.3317089890824168\n",
            "Round: 2199 Weight: [2.48532949 1.29417262] Bias: -1.0941336955616703 loss: 0.33170898824772216\n",
            "Round: 2200 Weight: [2.48533729 1.29417638] Bias: -1.0941364684091612 loss: 0.33170898741738036\n",
            "Round: 2201 Weight: [2.48534508 1.29418013] Bias: -1.0941392340144376 loss: 0.33170898659136855\n",
            "Round: 2202 Weight: [2.48535284 1.29418386] Bias: -1.0941419923964752 loss: 0.3317089857696642\n",
            "Round: 2203 Weight: [2.48536058 1.29418759] Bias: -1.0941447435742002 loss: 0.3317089849522448\n",
            "Round: 2204 Weight: [2.48536831 1.29419131] Bias: -1.094147487566488 loss: 0.33170898413908806\n",
            "Round: 2205 Weight: [2.48537601 1.29419501] Bias: -1.0941502243921648 loss: 0.33170898333017157\n",
            "Round: 2206 Weight: [2.48538369 1.29419871] Bias: -1.0941529540700072 loss: 0.33170898252547326\n",
            "Round: 2207 Weight: [2.48539136 1.2942024 ] Bias: -1.094155676618742 loss: 0.33170898172497115\n",
            "Round: 2208 Weight: [2.485399   1.29420608] Bias: -1.0941583920570466 loss: 0.3317089809286432\n",
            "Round: 2209 Weight: [2.48540662 1.29420975] Bias: -1.0941611004035496 loss: 0.3317089801364679\n",
            "Round: 2210 Weight: [2.48541423 1.2942134 ] Bias: -1.0941638016768302 loss: 0.3317089793484231\n",
            "Round: 2211 Weight: [2.48542181 1.29421705] Bias: -1.0941664958954187 loss: 0.3317089785644876\n",
            "Round: 2212 Weight: [2.48542937 1.29422069] Bias: -1.0941691830777964 loss: 0.33170897778463976\n",
            "Round: 2213 Weight: [2.48543692 1.29422432] Bias: -1.094171863242396 loss: 0.33170897700885843\n",
            "Round: 2214 Weight: [2.48544444 1.29422795] Bias: -1.0941745364076017 loss: 0.33170897623712214\n",
            "Round: 2215 Weight: [2.48545195 1.29423156] Bias: -1.094177202591749 loss: 0.33170897546941003\n",
            "Round: 2216 Weight: [2.48545943 1.29423516] Bias: -1.0941798618131255 loss: 0.3317089747057008\n",
            "Round: 2217 Weight: [2.4854669  1.29423875] Bias: -1.0941825140899701 loss: 0.3317089739459739\n",
            "Round: 2218 Weight: [2.48547434 1.29424234] Bias: -1.094185159440474 loss: 0.3317089731902082\n",
            "Round: 2219 Weight: [2.48548177 1.29424591] Bias: -1.0941877978827799 loss: 0.3317089724383831\n",
            "Round: 2220 Weight: [2.48548918 1.29424947] Bias: -1.0941904294349836 loss: 0.33170897169047814\n",
            "Round: 2221 Weight: [2.48549656 1.29425303] Bias: -1.0941930541151323 loss: 0.33170897094647284\n",
            "Round: 2222 Weight: [2.48550393 1.29425657] Bias: -1.0941956719412265 loss: 0.3317089702063467\n",
            "Round: 2223 Weight: [2.48551128 1.29426011] Bias: -1.0941982829312185 loss: 0.33170896947007955\n",
            "Round: 2224 Weight: [2.48551861 1.29426364] Bias: -1.0942008871030138 loss: 0.33170896873765143\n",
            "Round: 2225 Weight: [2.48552592 1.29426716] Bias: -1.0942034844744706 loss: 0.331708968009042\n",
            "Round: 2226 Weight: [2.48553322 1.29427067] Bias: -1.0942060750633997 loss: 0.3317089672842313\n",
            "Round: 2227 Weight: [2.48554049 1.29427417] Bias: -1.0942086588875657 loss: 0.33170896656319987\n",
            "Round: 2228 Weight: [2.48554774 1.29427766] Bias: -1.0942112359646856 loss: 0.33170896584592774\n",
            "Round: 2229 Weight: [2.48555498 1.29428114] Bias: -1.0942138063124303 loss: 0.3317089651323952\n",
            "Round: 2230 Weight: [2.48556219 1.29428461] Bias: -1.0942163699484238 loss: 0.33170896442258274\n",
            "Round: 2231 Weight: [2.48556939 1.29428808] Bias: -1.0942189268902438 loss: 0.33170896371647113\n",
            "Round: 2232 Weight: [2.48557657 1.29429153] Bias: -1.0942214771554217 loss: 0.33170896301404096\n",
            "Round: 2233 Weight: [2.48558373 1.29429498] Bias: -1.0942240207614429 loss: 0.331708962315273\n",
            "Round: 2234 Weight: [2.48559087 1.29429841] Bias: -1.0942265577257464 loss: 0.33170896162014807\n",
            "Round: 2235 Weight: [2.48559799 1.29430184] Bias: -1.0942290880657255 loss: 0.33170896092864716\n",
            "Round: 2236 Weight: [2.4856051  1.29430526] Bias: -1.0942316117987274 loss: 0.3317089602407516\n",
            "Round: 2237 Weight: [2.48561218 1.29430867] Bias: -1.094234128942054 loss: 0.3317089595564422\n",
            "Round: 2238 Weight: [2.48561925 1.29431207] Bias: -1.0942366395129615 loss: 0.33170895887570045\n",
            "Round: 2239 Weight: [2.4856263  1.29431546] Bias: -1.0942391435286605 loss: 0.33170895819850776\n",
            "Round: 2240 Weight: [2.48563333 1.29431884] Bias: -1.0942416410063163 loss: 0.33170895752484536\n",
            "Round: 2241 Weight: [2.48564034 1.29432222] Bias: -1.0942441319630491 loss: 0.33170895685469515\n",
            "Round: 2242 Weight: [2.48564733 1.29432558] Bias: -1.0942466164159341 loss: 0.33170895618803853\n",
            "Round: 2243 Weight: [2.48565431 1.29432894] Bias: -1.0942490943820014 loss: 0.3317089555248575\n",
            "Round: 2244 Weight: [2.48566126 1.29433229] Bias: -1.0942515658782361 loss: 0.3317089548651338\n",
            "Round: 2245 Weight: [2.4856682  1.29433563] Bias: -1.094254030921579 loss: 0.33170895420884916\n",
            "Round: 2246 Weight: [2.48567512 1.29433896] Bias: -1.0942564895289257 loss: 0.331708953555986\n",
            "Round: 2247 Weight: [2.48568202 1.29434228] Bias: -1.0942589417171278 loss: 0.3317089529065263\n",
            "Round: 2248 Weight: [2.48568891 1.29434559] Bias: -1.0942613875029923 loss: 0.33170895226045227\n",
            "Round: 2249 Weight: [2.48569578 1.2943489 ] Bias: -1.094263826903282 loss: 0.3317089516177463\n",
            "Round: 2250 Weight: [2.48570262 1.29435219] Bias: -1.094266259934716 loss: 0.3317089509783908\n",
            "Round: 2251 Weight: [2.48570946 1.29435548] Bias: -1.0942686866139684 loss: 0.3317089503423682\n",
            "Round: 2252 Weight: [2.48571627 1.29435876] Bias: -1.09427110695767 loss: 0.3317089497096612\n",
            "Round: 2253 Weight: [2.48572306 1.29436203] Bias: -1.0942735209824082 loss: 0.33170894908025245\n",
            "Round: 2254 Weight: [2.48572984 1.29436529] Bias: -1.094275928704726 loss: 0.33170894845412474\n",
            "Round: 2255 Weight: [2.4857366  1.29436854] Bias: -1.094278330141123 loss: 0.33170894783126104\n",
            "Round: 2256 Weight: [2.48574334 1.29437179] Bias: -1.094280725308056 loss: 0.33170894721164407\n",
            "Round: 2257 Weight: [2.48575007 1.29437502] Bias: -1.0942831142219376 loss: 0.3317089465952571\n",
            "Round: 2258 Weight: [2.48575677 1.29437825] Bias: -1.0942854968991378 loss: 0.3317089459820833\n",
            "Round: 2259 Weight: [2.48576346 1.29438147] Bias: -1.0942878733559833 loss: 0.33170894537210566\n",
            "Round: 2260 Weight: [2.48577014 1.29438468] Bias: -1.0942902436087578 loss: 0.33170894476530777\n",
            "Round: 2261 Weight: [2.48577679 1.29438788] Bias: -1.094292607673702 loss: 0.3317089441616729\n",
            "Round: 2262 Weight: [2.48578343 1.29439108] Bias: -1.0942949655670144 loss: 0.33170894356118463\n",
            "Round: 2263 Weight: [2.48579005 1.29439426] Bias: -1.0942973173048502 loss: 0.33170894296382636\n",
            "Round: 2264 Weight: [2.48579665 1.29439744] Bias: -1.0942996629033226 loss: 0.3317089423695819\n",
            "Round: 2265 Weight: [2.48580323 1.29440061] Bias: -1.094302002378502 loss: 0.33170894177843496\n",
            "Round: 2266 Weight: [2.4858098  1.29440377] Bias: -1.0943043357464166 loss: 0.33170894119036937\n",
            "Round: 2267 Weight: [2.48581635 1.29440692] Bias: -1.0943066630230527 loss: 0.33170894060536904\n",
            "Round: 2268 Weight: [2.48582289 1.29441007] Bias: -1.0943089842243543 loss: 0.33170894002341805\n",
            "Round: 2269 Weight: [2.4858294 1.2944132] Bias: -1.0943112993662234 loss: 0.3317089394445005\n",
            "Round: 2270 Weight: [2.4858359  1.29441633] Bias: -1.0943136084645204 loss: 0.3317089388686003\n",
            "Round: 2271 Weight: [2.48584239 1.29441945] Bias: -1.0943159115350636 loss: 0.3317089382957021\n",
            "Round: 2272 Weight: [2.48584885 1.29442256] Bias: -1.0943182085936298 loss: 0.3317089377257898\n",
            "Round: 2273 Weight: [2.4858553  1.29442567] Bias: -1.0943204996559548 loss: 0.3317089371588482\n",
            "Round: 2274 Weight: [2.48586174 1.29442876] Bias: -1.0943227847377321 loss: 0.33170893659486156\n",
            "Round: 2275 Weight: [2.48586815 1.29443185] Bias: -1.0943250638546147 loss: 0.3317089360338145\n",
            "Round: 2276 Weight: [2.48587455 1.29443493] Bias: -1.0943273370222137 loss: 0.33170893547569197\n",
            "Round: 2277 Weight: [2.48588093 1.294438  ] Bias: -1.0943296042561 loss: 0.33170893492047826\n",
            "Round: 2278 Weight: [2.4858873  1.29444106] Bias: -1.0943318655718026 loss: 0.3317089343681584\n",
            "Round: 2279 Weight: [2.48589365 1.29444412] Bias: -1.0943341209848103 loss: 0.3317089338187173\n",
            "Round: 2280 Weight: [2.48589998 1.29444717] Bias: -1.094336370510571 loss: 0.33170893327214\n",
            "Round: 2281 Weight: [2.48590629 1.2944502 ] Bias: -1.094338614164492 loss: 0.3317089327284115\n",
            "Round: 2282 Weight: [2.48591259 1.29445324] Bias: -1.0943408519619398 loss: 0.3317089321875168\n",
            "Round: 2283 Weight: [2.48591888 1.29445626] Bias: -1.0943430839182406 loss: 0.33170893164944126\n",
            "Round: 2284 Weight: [2.48592514 1.29445928] Bias: -1.0943453100486804 loss: 0.3317089311141702\n",
            "Round: 2285 Weight: [2.48593139 1.29446228] Bias: -1.094347530368505 loss: 0.33170893058168893\n",
            "Round: 2286 Weight: [2.48593763 1.29446528] Bias: -1.0943497448929203 loss: 0.3317089300519829\n",
            "Round: 2287 Weight: [2.48594384 1.29446828] Bias: -1.0943519536370914 loss: 0.3317089295250375\n",
            "Round: 2288 Weight: [2.48595004 1.29447126] Bias: -1.0943541566161443 loss: 0.3317089290008385\n",
            "Round: 2289 Weight: [2.48595623 1.29447424] Bias: -1.094356353845165 loss: 0.33170892847937145\n",
            "Round: 2290 Weight: [2.4859624 1.2944772] Bias: -1.0943585453392 loss: 0.33170892796062235\n",
            "Round: 2291 Weight: [2.48596855 1.29448017] Bias: -1.0943607311132557 loss: 0.3317089274445767\n",
            "Round: 2292 Weight: [2.48597469 1.29448312] Bias: -1.0943629111822997 loss: 0.33170892693122045\n",
            "Round: 2293 Weight: [2.48598081 1.29448606] Bias: -1.0943650855612597 loss: 0.33170892642053984\n",
            "Round: 2294 Weight: [2.48598691 1.294489  ] Bias: -1.0943672542650242 loss: 0.33170892591252055\n",
            "Round: 2295 Weight: [2.485993   1.29449193] Bias: -1.094369417308443 loss: 0.3317089254071489\n",
            "Round: 2296 Weight: [2.48599908 1.29449486] Bias: -1.0943715747063265 loss: 0.3317089249044112\n",
            "Round: 2297 Weight: [2.48600513 1.29449777] Bias: -1.094373726473446 loss: 0.3317089244042934\n",
            "Round: 2298 Weight: [2.48601117 1.29450068] Bias: -1.0943758726245345 loss: 0.33170892390678186\n",
            "Round: 2299 Weight: [2.4860172  1.29450358] Bias: -1.0943780131742855 loss: 0.3317089234118632\n",
            "Round: 2300 Weight: [2.48602321 1.29450647] Bias: -1.0943801481373545 loss: 0.33170892291952386\n",
            "Round: 2301 Weight: [2.4860292  1.29450935] Bias: -1.0943822775283583 loss: 0.33170892242975025\n",
            "Round: 2302 Weight: [2.48603518 1.29451223] Bias: -1.094384401361875 loss: 0.3317089219425291\n",
            "Round: 2303 Weight: [2.48604115 1.2945151 ] Bias: -1.0943865196524452 loss: 0.331708921457847\n",
            "Round: 2304 Weight: [2.48604709 1.29451796] Bias: -1.09438863241457 loss: 0.33170892097569077\n",
            "Round: 2305 Weight: [2.48605303 1.29452082] Bias: -1.0943907396627133 loss: 0.3317089204960471\n",
            "Round: 2306 Weight: [2.48605894 1.29452366] Bias: -1.0943928414113007 loss: 0.3317089200189031\n",
            "Round: 2307 Weight: [2.48606484 1.2945265 ] Bias: -1.09439493767472 loss: 0.33170891954424564\n",
            "Round: 2308 Weight: [2.48607073 1.29452934] Bias: -1.094397028467321 loss: 0.3317089190720617\n",
            "Round: 2309 Weight: [2.4860766  1.29453216] Bias: -1.094399113803416 loss: 0.33170891860233837\n",
            "Round: 2310 Weight: [2.48608245 1.29453498] Bias: -1.0944011936972793 loss: 0.3317089181350628\n",
            "Round: 2311 Weight: [2.48608829 1.29453779] Bias: -1.0944032681631481 loss: 0.3317089176702224\n",
            "Round: 2312 Weight: [2.48609412 1.29454059] Bias: -1.094405337215222 loss: 0.33170891720780427\n",
            "Round: 2313 Weight: [2.48609993 1.29454339] Bias: -1.0944074008676632 loss: 0.33170891674779585\n",
            "Round: 2314 Weight: [2.48610572 1.29454618] Bias: -1.0944094591345968 loss: 0.33170891629018456\n",
            "Round: 2315 Weight: [2.4861115  1.29454896] Bias: -1.0944115120301106 loss: 0.3317089158349579\n",
            "Round: 2316 Weight: [2.48611726 1.29455173] Bias: -1.0944135595682556 loss: 0.33170891538210334\n",
            "Round: 2317 Weight: [2.48612301 1.2945545 ] Bias: -1.0944156017630458 loss: 0.33170891493160876\n",
            "Round: 2318 Weight: [2.48612875 1.29455726] Bias: -1.094417638628458 loss: 0.3317089144834615\n",
            "Round: 2319 Weight: [2.48613446 1.29456001] Bias: -1.0944196701784332 loss: 0.33170891403764974\n",
            "Round: 2320 Weight: [2.48614017 1.29456275] Bias: -1.0944216964268747 loss: 0.3317089135941609\n",
            "Round: 2321 Weight: [2.48614586 1.29456549] Bias: -1.0944237173876499 loss: 0.331708913152983\n",
            "Round: 2322 Weight: [2.48615153 1.29456822] Bias: -1.0944257330745897 loss: 0.331708912714104\n",
            "Round: 2323 Weight: [2.48615719 1.29457095] Bias: -1.0944277435014884 loss: 0.33170891227751204\n",
            "Round: 2324 Weight: [2.48616284 1.29457366] Bias: -1.0944297486821042 loss: 0.3317089118431949\n",
            "Round: 2325 Weight: [2.48616847 1.29457637] Bias: -1.0944317486301591 loss: 0.331708911411141\n",
            "Round: 2326 Weight: [2.48617408 1.29457907] Bias: -1.0944337433593392 loss: 0.33170891098133826\n",
            "Round: 2327 Weight: [2.48617968 1.29458177] Bias: -1.0944357328832945 loss: 0.3317089105537752\n",
            "Round: 2328 Weight: [2.48618527 1.29458446] Bias: -1.0944377172156392 loss: 0.33170891012844006\n",
            "Round: 2329 Weight: [2.48619084 1.29458714] Bias: -1.0944396963699516 loss: 0.3317089097053211\n",
            "Round: 2330 Weight: [2.4861964  1.29458981] Bias: -1.0944416703597744 loss: 0.33170890928440705\n",
            "Round: 2331 Weight: [2.48620194 1.29459248] Bias: -1.0944436391986148 loss: 0.331708908865686\n",
            "Round: 2332 Weight: [2.48620747 1.29459514] Bias: -1.0944456028999443 loss: 0.33170890844914674\n",
            "Round: 2333 Weight: [2.48621298 1.29459779] Bias: -1.0944475614771993 loss: 0.3317089080347779\n",
            "Round: 2334 Weight: [2.48621848 1.29460044] Bias: -1.094449514943781 loss: 0.3317089076225682\n",
            "Round: 2335 Weight: [2.48622396 1.29460308] Bias: -1.0944514633130547 loss: 0.3317089072125063\n",
            "Round: 2336 Weight: [2.48622943 1.29460571] Bias: -1.0944534065983513 loss: 0.33170890680458087\n",
            "Round: 2337 Weight: [2.48623489 1.29460834] Bias: -1.0944553448129664 loss: 0.331708906398781\n",
            "Round: 2338 Weight: [2.48624033 1.29461096] Bias: -1.0944572779701607 loss: 0.3317089059950955\n",
            "Round: 2339 Weight: [2.48624576 1.29461357] Bias: -1.09445920608316 loss: 0.33170890559351335\n",
            "Round: 2340 Weight: [2.48625117 1.29461617] Bias: -1.0944611291651554 loss: 0.33170890519402363\n",
            "Round: 2341 Weight: [2.48625657 1.29461877] Bias: -1.0944630472293035 loss: 0.33170890479661536\n",
            "Round: 2342 Weight: [2.48626196 1.29462136] Bias: -1.0944649602887262 loss: 0.3317089044012777\n",
            "Round: 2343 Weight: [2.48626733 1.29462395] Bias: -1.0944668683565109 loss: 0.33170890400799974\n",
            "Round: 2344 Weight: [2.48627269 1.29462653] Bias: -1.0944687714457106 loss: 0.33170890361677097\n",
            "Round: 2345 Weight: [2.48627803 1.2946291 ] Bias: -1.0944706695693445 loss: 0.33170890322758056\n",
            "Round: 2346 Weight: [2.48628336 1.29463166] Bias: -1.0944725627403966 loss: 0.33170890284041793\n",
            "Round: 2347 Weight: [2.48628868 1.29463422] Bias: -1.0944744509718178 loss: 0.3317089024552724\n",
            "Round: 2348 Weight: [2.48629398 1.29463677] Bias: -1.0944763342765245 loss: 0.33170890207213355\n",
            "Round: 2349 Weight: [2.48629927 1.29463932] Bias: -1.094478212667399 loss: 0.331708901690991\n",
            "Round: 2350 Weight: [2.48630454 1.29464185] Bias: -1.0944800861572905 loss: 0.3317089013118342\n",
            "Round: 2351 Weight: [2.4863098  1.29464439] Bias: -1.0944819547590139 loss: 0.3317089009346528\n",
            "Round: 2352 Weight: [2.48631505 1.29464691] Bias: -1.0944838184853503 loss: 0.33170890055943647\n",
            "Round: 2353 Weight: [2.48632028 1.29464943] Bias: -1.0944856773490474 loss: 0.3317089001861751\n",
            "Round: 2354 Weight: [2.4863255  1.29465194] Bias: -1.09448753136282 loss: 0.3317088998148584\n",
            "Round: 2355 Weight: [2.4863307  1.29465445] Bias: -1.0944893805393485 loss: 0.3317088994454762\n",
            "Round: 2356 Weight: [2.4863359  1.29465694] Bias: -1.0944912248912808 loss: 0.3317088990780185\n",
            "Round: 2357 Weight: [2.48634107 1.29465944] Bias: -1.0944930644312314 loss: 0.3317088987124752\n",
            "Round: 2358 Weight: [2.48634624 1.29466192] Bias: -1.0944948991717813 loss: 0.3317088983488364\n",
            "Round: 2359 Weight: [2.48635139 1.2946644 ] Bias: -1.094496729125479 loss: 0.3317088979870919\n",
            "Round: 2360 Weight: [2.48635653 1.29466687] Bias: -1.0944985543048396 loss: 0.3317088976272322\n",
            "Round: 2361 Weight: [2.48636165 1.29466934] Bias: -1.0945003747223456 loss: 0.3317088972692473\n",
            "Round: 2362 Weight: [2.48636677 1.2946718 ] Bias: -1.0945021903904468 loss: 0.3317088969131274\n",
            "Round: 2363 Weight: [2.48637186 1.29467425] Bias: -1.0945040013215601 loss: 0.3317088965588627\n",
            "Round: 2364 Weight: [2.48637695 1.2946767 ] Bias: -1.09450580752807 loss: 0.3317088962064437\n",
            "Round: 2365 Weight: [2.48638202 1.29467914] Bias: -1.0945076090223282 loss: 0.3317088958558607\n",
            "Round: 2366 Weight: [2.48638708 1.29468157] Bias: -1.0945094058166545 loss: 0.33170889550710425\n",
            "Round: 2367 Weight: [2.48639212 1.294684  ] Bias: -1.0945111979233355 loss: 0.3317088951601645\n",
            "Round: 2368 Weight: [2.48639715 1.29468642] Bias: -1.0945129853546265 loss: 0.33170889481503224\n",
            "Round: 2369 Weight: [2.48640217 1.29468884] Bias: -1.09451476812275 loss: 0.3317088944716981\n",
            "Round: 2370 Weight: [2.48640718 1.29469125] Bias: -1.0945165462398967 loss: 0.3317088941301524\n",
            "Round: 2371 Weight: [2.48641217 1.29469365] Bias: -1.094518319718225 loss: 0.33170889379038615\n",
            "Round: 2372 Weight: [2.48641715 1.29469605] Bias: -1.094520088569862 loss: 0.33170889345238985\n",
            "Round: 2373 Weight: [2.48642212 1.29469844] Bias: -1.0945218528069023 loss: 0.3317088931161543\n",
            "Round: 2374 Weight: [2.48642707 1.29470082] Bias: -1.0945236124414088 loss: 0.3317088927816704\n",
            "Round: 2375 Weight: [2.48643201 1.2947032 ] Bias: -1.0945253674854132 loss: 0.3317088924489291\n",
            "Round: 2376 Weight: [2.48643694 1.29470557] Bias: -1.0945271179509153 loss: 0.33170889211792104\n",
            "Round: 2377 Weight: [2.48644186 1.29470794] Bias: -1.0945288638498836 loss: 0.3317088917886374\n",
            "Round: 2378 Weight: [2.48644676 1.29471029] Bias: -1.094530605194255 loss: 0.3317088914610691\n",
            "Round: 2379 Weight: [2.48645165 1.29471265] Bias: -1.094532341995935 loss: 0.3317088911352072\n",
            "Round: 2380 Weight: [2.48645652 1.29471499] Bias: -1.0945340742667982 loss: 0.3317088908110428\n",
            "Round: 2381 Weight: [2.48646139 1.29471734] Bias: -1.0945358020186877 loss: 0.33170889048856717\n",
            "Round: 2382 Weight: [2.48646624 1.29471967] Bias: -1.0945375252634157 loss: 0.33170889016777144\n",
            "Round: 2383 Weight: [2.48647108 1.294722  ] Bias: -1.0945392440127635 loss: 0.3317088898486467\n",
            "Round: 2384 Weight: [2.4864759  1.29472432] Bias: -1.094540958278481 loss: 0.33170888953118444\n",
            "Round: 2385 Weight: [2.48648072 1.29472664] Bias: -1.094542668072288 loss: 0.3317088892153759\n",
            "Round: 2386 Weight: [2.48648552 1.29472895] Bias: -1.094544373405873 loss: 0.3317088889012123\n",
            "Round: 2387 Weight: [2.48649031 1.29473125] Bias: -1.094546074290894 loss: 0.3317088885886855\n",
            "Round: 2388 Weight: [2.48649508 1.29473355] Bias: -1.0945477707389781 loss: 0.3317088882777865\n",
            "Round: 2389 Weight: [2.48649984 1.29473584] Bias: -1.0945494627617225 loss: 0.3317088879685071\n",
            "Round: 2390 Weight: [2.4865046  1.29473813] Bias: -1.0945511503706935 loss: 0.3317088876608388\n",
            "Round: 2391 Weight: [2.48650933 1.29474041] Bias: -1.0945528335774273 loss: 0.33170888735477305\n",
            "Round: 2392 Weight: [2.48651406 1.29474268] Bias: -1.0945545123934295 loss: 0.33170888705030177\n",
            "Round: 2393 Weight: [2.48651877 1.29474495] Bias: -1.0945561868301759 loss: 0.33170888674741633\n",
            "Round: 2394 Weight: [2.48652348 1.29474721] Bias: -1.0945578568991121 loss: 0.3317088864461088\n",
            "Round: 2395 Weight: [2.48652816 1.29474947] Bias: -1.0945595226116536 loss: 0.3317088861463707\n",
            "Round: 2396 Weight: [2.48653284 1.29475172] Bias: -1.0945611839791858 loss: 0.33170888584819386\n",
            "Round: 2397 Weight: [2.48653751 1.29475397] Bias: -1.0945628410130646 loss: 0.3317088855515702\n",
            "Round: 2398 Weight: [2.48654216 1.29475621] Bias: -1.0945644937246157 loss: 0.3317088852564917\n",
            "Round: 2399 Weight: [2.4865468  1.29475844] Bias: -1.0945661421251354 loss: 0.3317088849629502\n",
            "Round: 2400 Weight: [2.48655143 1.29476067] Bias: -1.09456778622589 loss: 0.3317088846709377\n",
            "Round: 2401 Weight: [2.48655605 1.29476289] Bias: -1.094569426038117 loss: 0.3317088843804463\n",
            "Round: 2402 Weight: [2.48656065 1.2947651 ] Bias: -1.0945710615730233 loss: 0.33170888409146804\n",
            "Round: 2403 Weight: [2.48656524 1.29476731] Bias: -1.0945726928417874 loss: 0.33170888380399505\n",
            "Round: 2404 Weight: [2.48656982 1.29476952] Bias: -1.094574319855558 loss: 0.3317088835180193\n",
            "Round: 2405 Weight: [2.48657439 1.29477172] Bias: -1.0945759426254547 loss: 0.3317088832335332\n",
            "Round: 2406 Weight: [2.48657895 1.29477391] Bias: -1.0945775611625679 loss: 0.3317088829505289\n",
            "Round: 2407 Weight: [2.48658349 1.2947761 ] Bias: -1.0945791754779588 loss: 0.3317088826689987\n",
            "Round: 2408 Weight: [2.48658802 1.29477828] Bias: -1.0945807855826597 loss: 0.33170888238893487\n",
            "Round: 2409 Weight: [2.48659255 1.29478045] Bias: -1.094582391487674 loss: 0.33170888211032984\n",
            "Round: 2410 Weight: [2.48659705 1.29478262] Bias: -1.094583993203976 loss: 0.33170888183317593\n",
            "Round: 2411 Weight: [2.48660155 1.29478479] Bias: -1.0945855907425117 loss: 0.3317088815574657\n",
            "Round: 2412 Weight: [2.48660604 1.29478695] Bias: -1.0945871841141979 loss: 0.33170888128319137\n",
            "Round: 2413 Weight: [2.48661051 1.2947891 ] Bias: -1.0945887733299229 loss: 0.33170888101034585\n",
            "Round: 2414 Weight: [2.48661497 1.29479125] Bias: -1.0945903584005465 loss: 0.33170888073892124\n",
            "Round: 2415 Weight: [2.48661942 1.29479339] Bias: -1.0945919393369001 loss: 0.33170888046891045\n",
            "Round: 2416 Weight: [2.48662386 1.29479552] Bias: -1.0945935161497866 loss: 0.3317088802003061\n",
            "Round: 2417 Weight: [2.48662829 1.29479766] Bias: -1.0945950888499807 loss: 0.3317088799331007\n",
            "Round: 2418 Weight: [2.48663271 1.29479978] Bias: -1.0945966574482284 loss: 0.33170887966728696\n",
            "Round: 2419 Weight: [2.48663711 1.2948019 ] Bias: -1.0945982219552481 loss: 0.3317088794028577\n",
            "Round: 2420 Weight: [2.4866415  1.29480401] Bias: -1.09459978238173 loss: 0.3317088791398058\n",
            "Round: 2421 Weight: [2.48664589 1.29480612] Bias: -1.0946013387383358 loss: 0.331708878878124\n",
            "Round: 2422 Weight: [2.48665026 1.29480823] Bias: -1.0946028910356995 loss: 0.331708878617805\n",
            "Round: 2423 Weight: [2.48665462 1.29481032] Bias: -1.0946044392844274 loss: 0.331708878358842\n",
            "Round: 2424 Weight: [2.48665896 1.29481242] Bias: -1.0946059834950979 loss: 0.3317088781012276\n",
            "Round: 2425 Weight: [2.4866633 1.2948145] Bias: -1.0946075236782615 loss: 0.3317088778449551\n",
            "Round: 2426 Weight: [2.48666762 1.29481658] Bias: -1.0946090598444413 loss: 0.33170887759001727\n",
            "Round: 2427 Weight: [2.48667194 1.29481866] Bias: -1.0946105920041327 loss: 0.3317088773364072\n",
            "Round: 2428 Weight: [2.48667624 1.29482073] Bias: -1.0946121201678032 loss: 0.331708877084118\n",
            "Round: 2429 Weight: [2.48668053 1.29482279] Bias: -1.0946136443458934 loss: 0.3317088768331428\n",
            "Round: 2430 Weight: [2.48668481 1.29482485] Bias: -1.0946151645488165 loss: 0.3317088765834748\n",
            "Round: 2431 Weight: [2.48668908 1.29482691] Bias: -1.094616680786958 loss: 0.33170887633510704\n",
            "Round: 2432 Weight: [2.48669334 1.29482896] Bias: -1.0946181930706762 loss: 0.3317088760880328\n",
            "Round: 2433 Weight: [2.48669758 1.294831  ] Bias: -1.0946197014103027 loss: 0.3317088758422455\n",
            "Round: 2434 Weight: [2.48670182 1.29483304] Bias: -1.0946212058161418 loss: 0.33170887559773815\n",
            "Round: 2435 Weight: [2.48670604 1.29483507] Bias: -1.0946227062984706 loss: 0.3317088753545043\n",
            "Round: 2436 Weight: [2.48671025 1.2948371 ] Bias: -1.0946242028675395 loss: 0.3317088751125372\n",
            "Round: 2437 Weight: [2.48671446 1.29483912] Bias: -1.0946256955335718 loss: 0.3317088748718302\n",
            "Round: 2438 Weight: [2.48671865 1.29484114] Bias: -1.0946271843067643 loss: 0.33170887463237697\n",
            "Round: 2439 Weight: [2.48672283 1.29484315] Bias: -1.0946286691972866 loss: 0.3317088743941708\n",
            "Round: 2440 Weight: [2.486727   1.29484516] Bias: -1.0946301502152822 loss: 0.3317088741572051\n",
            "Round: 2441 Weight: [2.48673116 1.29484716] Bias: -1.0946316273708676 loss: 0.3317088739214736\n",
            "Round: 2442 Weight: [2.4867353  1.29484915] Bias: -1.094633100674133 loss: 0.33170887368696983\n",
            "Round: 2443 Weight: [2.48673944 1.29485114] Bias: -1.0946345701351419 loss: 0.33170887345368716\n",
            "Round: 2444 Weight: [2.48674357 1.29485313] Bias: -1.0946360357639318 loss: 0.33170887322161957\n",
            "Round: 2445 Weight: [2.48674768 1.29485511] Bias: -1.0946374975705135 loss: 0.33170887299076063\n",
            "Round: 2446 Weight: [2.48675179 1.29485709] Bias: -1.094638955564872 loss: 0.3317088727611038\n",
            "Round: 2447 Weight: [2.48675588 1.29485906] Bias: -1.0946404097569655 loss: 0.33170887253264303\n",
            "Round: 2448 Weight: [2.48675997 1.29486102] Bias: -1.0946418601567267 loss: 0.3317088723053721\n",
            "Round: 2449 Weight: [2.48676404 1.29486298] Bias: -1.094643306774062 loss: 0.33170887207928473\n",
            "Round: 2450 Weight: [2.4867681  1.29486494] Bias: -1.0946447496188518 loss: 0.33170887185437475\n",
            "Round: 2451 Weight: [2.48677215 1.29486689] Bias: -1.0946461887009509 loss: 0.3317088716306361\n",
            "Round: 2452 Weight: [2.48677619 1.29486883] Bias: -1.094647624030188 loss: 0.3317088714080627\n",
            "Round: 2453 Weight: [2.48678022 1.29487077] Bias: -1.0946490556163657 loss: 0.3317088711866483\n",
            "Round: 2454 Weight: [2.48678424 1.2948727 ] Bias: -1.0946504834692619 loss: 0.331708870966387\n",
            "Round: 2455 Weight: [2.48678825 1.29487463] Bias: -1.0946519075986278 loss: 0.3317088707472728\n",
            "Round: 2456 Weight: [2.48679225 1.29487656] Bias: -1.09465332801419 loss: 0.33170887052929954\n",
            "Round: 2457 Weight: [2.48679624 1.29487848] Bias: -1.0946547447256485 loss: 0.3317088703124616\n",
            "Round: 2458 Weight: [2.48680022 1.29488039] Bias: -1.094656157742679 loss: 0.33170887009675276\n",
            "Round: 2459 Weight: [2.48680418 1.2948823 ] Bias: -1.0946575670749312 loss: 0.33170886988216725\n",
            "Round: 2460 Weight: [2.48680814 1.29488421] Bias: -1.0946589727320297 loss: 0.3317088696686993\n",
            "Round: 2461 Weight: [2.48681209 1.2948861 ] Bias: -1.094660374723574 loss: 0.3317088694563429\n",
            "Round: 2462 Weight: [2.48681603 1.294888  ] Bias: -1.094661773059138 loss: 0.3317088692450924\n",
            "Round: 2463 Weight: [2.48681995 1.29488989] Bias: -1.0946631677482708 loss: 0.33170886903494207\n",
            "Round: 2464 Weight: [2.48682387 1.29489177] Bias: -1.0946645588004966 loss: 0.331708868825886\n",
            "Round: 2465 Weight: [2.48682777 1.29489365] Bias: -1.0946659462253148 loss: 0.3317088686179186\n",
            "Round: 2466 Weight: [2.48683167 1.29489553] Bias: -1.0946673300321992 loss: 0.33170886841103425\n",
            "Round: 2467 Weight: [2.48683556 1.2948974 ] Bias: -1.0946687102305994 loss: 0.33170886820522727\n",
            "Round: 2468 Weight: [2.48683943 1.29489926] Bias: -1.0946700868299402 loss: 0.33170886800049193\n",
            "Round: 2469 Weight: [2.4868433  1.29490112] Bias: -1.0946714598396214 loss: 0.3317088677968228\n",
            "Round: 2470 Weight: [2.48684715 1.29490298] Bias: -1.0946728292690184 loss: 0.3317088675942142\n",
            "Round: 2471 Weight: [2.486851   1.29490483] Bias: -1.0946741951274819 loss: 0.3317088673926607\n",
            "Round: 2472 Weight: [2.48685483 1.29490667] Bias: -1.094675557424338 loss: 0.3317088671921568\n",
            "Round: 2473 Weight: [2.48685866 1.29490852] Bias: -1.094676916168889 loss: 0.3317088669926971\n",
            "Round: 2474 Weight: [2.48686247 1.29491035] Bias: -1.094678271370412 loss: 0.3317088667942758\n",
            "Round: 2475 Weight: [2.48686628 1.29491218] Bias: -1.0946796230381604 loss: 0.3317088665968879\n",
            "Round: 2476 Weight: [2.48687007 1.29491401] Bias: -1.094680971181363 loss: 0.3317088664005279\n",
            "Round: 2477 Weight: [2.48687386 1.29491583] Bias: -1.0946823158092245 loss: 0.33170886620519024\n",
            "Round: 2478 Weight: [2.48687764 1.29491765] Bias: -1.0946836569309255 loss: 0.3317088660108698\n",
            "Round: 2479 Weight: [2.4868814  1.29491946] Bias: -1.0946849945556227 loss: 0.33170886581756137\n",
            "Round: 2480 Weight: [2.48688516 1.29492127] Bias: -1.0946863286924486 loss: 0.3317088656252594\n",
            "Round: 2481 Weight: [2.4868889  1.29492307] Bias: -1.0946876593505122 loss: 0.331708865433959\n",
            "Round: 2482 Weight: [2.48689264 1.29492487] Bias: -1.0946889865388978 loss: 0.33170886524365445\n",
            "Round: 2483 Weight: [2.48689637 1.29492666] Bias: -1.0946903102666667 loss: 0.331708865054341\n",
            "Round: 2484 Weight: [2.48690008 1.29492845] Bias: -1.0946916305428562 loss: 0.33170886486601336\n",
            "Round: 2485 Weight: [2.48690379 1.29493024] Bias: -1.0946929473764797 loss: 0.33170886467866634\n",
            "Round: 2486 Weight: [2.48690749 1.29493201] Bias: -1.0946942607765273 loss: 0.3317088644922948\n",
            "Round: 2487 Weight: [2.48691118 1.29493379] Bias: -1.0946955707519657 loss: 0.3317088643068938\n",
            "Round: 2488 Weight: [2.48691486 1.29493556] Bias: -1.0946968773117374 loss: 0.3317088641224582\n",
            "Round: 2489 Weight: [2.48691852 1.29493733] Bias: -1.0946981804647622 loss: 0.33170886393898297\n",
            "Round: 2490 Weight: [2.48692218 1.29493909] Bias: -1.0946994802199363 loss: 0.331708863756463\n",
            "Round: 2491 Weight: [2.48692583 1.29494084] Bias: -1.0947007765861325 loss: 0.33170886357489354\n",
            "Round: 2492 Weight: [2.48692947 1.29494259] Bias: -1.0947020695722005 loss: 0.3317088633942694\n",
            "Round: 2493 Weight: [2.4869331  1.29494434] Bias: -1.0947033591869668 loss: 0.3317088632145859\n",
            "Round: 2494 Weight: [2.48693673 1.29494608] Bias: -1.0947046454392346 loss: 0.33170886303583796\n",
            "Round: 2495 Weight: [2.48694034 1.29494782] Bias: -1.0947059283377842 loss: 0.33170886285802076\n",
            "Round: 2496 Weight: [2.48694394 1.29494956] Bias: -1.094707207891373 loss: 0.3317088626811294\n",
            "Round: 2497 Weight: [2.48694753 1.29495128] Bias: -1.0947084841087353 loss: 0.33170886250515913\n",
            "Round: 2498 Weight: [2.48695112 1.29495301] Bias: -1.0947097569985826 loss: 0.3317088623301051\n",
            "Round: 2499 Weight: [2.48695469 1.29495473] Bias: -1.0947110265696036 loss: 0.33170886215596257\n",
            "Round: 2500 Weight: [2.48695826 1.29495645] Bias: -1.094712292830464 loss: 0.3317088619827268\n",
            "Round: 2501 Weight: [2.48696181 1.29495816] Bias: -1.0947135557898073 loss: 0.3317088618103931\n",
            "Round: 2502 Weight: [2.48696536 1.29495986] Bias: -1.094714815456254 loss: 0.3317088616389567\n",
            "Round: 2503 Weight: [2.4869689  1.29496157] Bias: -1.0947160718384021 loss: 0.3317088614684128\n",
            "Round: 2504 Weight: [2.48697242 1.29496326] Bias: -1.094717324944827 loss: 0.3317088612987569\n",
            "Round: 2505 Weight: [2.48697594 1.29496496] Bias: -1.0947185747840817 loss: 0.33170886112998443\n",
            "Round: 2506 Weight: [2.48697945 1.29496665] Bias: -1.0947198213646971 loss: 0.33170886096209073\n",
            "Round: 2507 Weight: [2.48698295 1.29496833] Bias: -1.0947210646951813 loss: 0.3317088607950713\n",
            "Round: 2508 Weight: [2.48698644 1.29497001] Bias: -1.0947223047840204 loss: 0.3317088606289214\n",
            "Round: 2509 Weight: [2.48698993 1.29497169] Bias: -1.094723541639678 loss: 0.33170886046363657\n",
            "Round: 2510 Weight: [2.4869934  1.29497336] Bias: -1.0947247752705962 loss: 0.33170886029921237\n",
            "Round: 2511 Weight: [2.48699686 1.29497502] Bias: -1.0947260056851942 loss: 0.3317088601356442\n",
            "Round: 2512 Weight: [2.48700032 1.29497669] Bias: -1.0947272328918696 loss: 0.33170885997292776\n",
            "Round: 2513 Weight: [2.48700376 1.29497835] Bias: -1.094728456898998 loss: 0.3317088598110585\n",
            "Round: 2514 Weight: [2.4870072 1.29498  ] Bias: -1.0947296777149327 loss: 0.331708859650032\n",
            "Round: 2515 Weight: [2.48701063 1.29498165] Bias: -1.0947308953480055 loss: 0.331708859489844\n",
            "Round: 2516 Weight: [2.48701405 1.29498329] Bias: -1.0947321098065264 loss: 0.33170885933049\n",
            "Round: 2517 Weight: [2.48701746 1.29498494] Bias: -1.0947333210987835 loss: 0.3317088591719657\n",
            "Round: 2518 Weight: [2.48702086 1.29498657] Bias: -1.0947345292330433 loss: 0.3317088590142668\n",
            "Round: 2519 Weight: [2.48702425 1.2949882 ] Bias: -1.0947357342175505 loss: 0.3317088588573889\n",
            "Round: 2520 Weight: [2.48702764 1.29498983] Bias: -1.0947369360605284 loss: 0.33170885870132777\n",
            "Round: 2521 Weight: [2.48703101 1.29499146] Bias: -1.0947381347701786 loss: 0.3317088585460791\n",
            "Round: 2522 Weight: [2.48703438 1.29499308] Bias: -1.0947393303546813 loss: 0.33170885839163894\n",
            "Round: 2523 Weight: [2.48703773 1.29499469] Bias: -1.0947405228221954 loss: 0.3317088582380027\n",
            "Round: 2524 Weight: [2.48704108 1.2949963 ] Bias: -1.0947417121808583 loss: 0.3317088580851664\n",
            "Round: 2525 Weight: [2.48704442 1.29499791] Bias: -1.094742898438786 loss: 0.331708857933126\n",
            "Round: 2526 Weight: [2.48704775 1.29499951] Bias: -1.0947440816040734 loss: 0.33170885778187703\n",
            "Round: 2527 Weight: [2.48705108 1.29500111] Bias: -1.0947452616847946 loss: 0.3317088576314155\n",
            "Round: 2528 Weight: [2.48705439 1.29500271] Bias: -1.0947464386890018 loss: 0.3317088574817374\n",
            "Round: 2529 Weight: [2.4870577 1.2950043] Bias: -1.0947476126247264 loss: 0.3317088573328386\n",
            "Round: 2530 Weight: [2.48706099 1.29500588] Bias: -1.0947487834999792 loss: 0.331708857184715\n",
            "Round: 2531 Weight: [2.48706428 1.29500747] Bias: -1.0947499513227494 loss: 0.3317088570373626\n",
            "Round: 2532 Weight: [2.48706756 1.29500905] Bias: -1.0947511161010057 loss: 0.3317088568907773\n",
            "Round: 2533 Weight: [2.48707083 1.29501062] Bias: -1.094752277842696 loss: 0.3317088567449552\n",
            "Round: 2534 Weight: [2.48707409 1.29501219] Bias: -1.0947534365557468 loss: 0.3317088565998923\n",
            "Round: 2535 Weight: [2.48707735 1.29501376] Bias: -1.0947545922480644 loss: 0.3317088564555847\n",
            "Round: 2536 Weight: [2.48708059 1.29501532] Bias: -1.0947557449275345 loss: 0.3317088563120283\n",
            "Round: 2537 Weight: [2.48708383 1.29501687] Bias: -1.0947568946020219 loss: 0.33170885616921936\n",
            "Round: 2538 Weight: [2.48708706 1.29501843] Bias: -1.0947580412793707 loss: 0.33170885602715394\n",
            "Round: 2539 Weight: [2.48709028 1.29501998] Bias: -1.0947591849674048 loss: 0.3317088558858281\n",
            "Round: 2540 Weight: [2.48709349 1.29502152] Bias: -1.0947603256739271 loss: 0.33170885574523806\n",
            "Round: 2541 Weight: [2.48709669 1.29502306] Bias: -1.0947614634067209 loss: 0.33170885560537994\n",
            "Round: 2542 Weight: [2.48709989 1.2950246 ] Bias: -1.0947625981735483 loss: 0.33170885546624995\n",
            "Round: 2543 Weight: [2.48710307 1.29502614] Bias: -1.0947637299821515 loss: 0.33170885532784433\n",
            "Round: 2544 Weight: [2.48710625 1.29502767] Bias: -1.0947648588402525 loss: 0.33170885519015925\n",
            "Round: 2545 Weight: [2.48710942 1.29502919] Bias: -1.0947659847555529 loss: 0.3317088550531909\n",
            "Round: 2546 Weight: [2.48711258 1.29503071] Bias: -1.094767107735734 loss: 0.33170885491693575\n",
            "Round: 2547 Weight: [2.48711574 1.29503223] Bias: -1.0947682277884574 loss: 0.33170885478138984\n",
            "Round: 2548 Weight: [2.48711888 1.29503374] Bias: -1.0947693449213645 loss: 0.3317088546465496\n",
            "Round: 2549 Weight: [2.48712202 1.29503525] Bias: -1.0947704591420766 loss: 0.3317088545124115\n",
            "Round: 2550 Weight: [2.48712515 1.29503676] Bias: -1.094771570458195 loss: 0.3317088543789716\n",
            "Round: 2551 Weight: [2.48712827 1.29503826] Bias: -1.0947726788773016 loss: 0.33170885424622637\n",
            "Round: 2552 Weight: [2.48713138 1.29503976] Bias: -1.0947737844069576 loss: 0.3317088541141723\n",
            "Round: 2553 Weight: [2.48713448 1.29504125] Bias: -1.0947748870547054 loss: 0.33170885398280564\n",
            "Round: 2554 Weight: [2.48713758 1.29504274] Bias: -1.0947759868280666 loss: 0.3317088538521229\n",
            "Round: 2555 Weight: [2.48714067 1.29504423] Bias: -1.094777083734544 loss: 0.3317088537221205\n",
            "Round: 2556 Weight: [2.48714375 1.29504571] Bias: -1.0947781777816206 loss: 0.3317088535927949\n",
            "Round: 2557 Weight: [2.48714682 1.29504719] Bias: -1.0947792689767595 loss: 0.33170885346414264\n",
            "Round: 2558 Weight: [2.48714989 1.29504866] Bias: -1.0947803573274042 loss: 0.33170885333615996\n",
            "Round: 2559 Weight: [2.48715294 1.29505013] Bias: -1.0947814428409792 loss: 0.3317088532088437\n",
            "Round: 2560 Weight: [2.48715599 1.2950516 ] Bias: -1.0947825255248893 loss: 0.33170885308219006\n",
            "Round: 2561 Weight: [2.48715903 1.29505306] Bias: -1.09478360538652 loss: 0.33170885295619595\n",
            "Round: 2562 Weight: [2.48716206 1.29505452] Bias: -1.0947846824332375 loss: 0.33170885283085777\n",
            "Round: 2563 Weight: [2.48716509 1.29505598] Bias: -1.0947857566723884 loss: 0.3317088527061719\n",
            "Round: 2564 Weight: [2.4871681  1.29505743] Bias: -1.0947868281113007 loss: 0.3317088525821353\n",
            "Round: 2565 Weight: [2.48717111 1.29505888] Bias: -1.0947878967572824 loss: 0.3317088524587444\n",
            "Round: 2566 Weight: [2.48717411 1.29506032] Bias: -1.0947889626176233 loss: 0.33170885233599573\n",
            "Round: 2567 Weight: [2.48717711 1.29506176] Bias: -1.0947900256995933 loss: 0.331708852213886\n",
            "Round: 2568 Weight: [2.48718009 1.2950632 ] Bias: -1.0947910860104437 loss: 0.3317088520924121\n",
            "Round: 2569 Weight: [2.48718307 1.29506463] Bias: -1.094792143557407 loss: 0.3317088519715705\n",
            "Round: 2570 Weight: [2.48718604 1.29506606] Bias: -1.0947931983476966 loss: 0.331708851851358\n",
            "Round: 2571 Weight: [2.487189   1.29506749] Bias: -1.0947942503885066 loss: 0.3317088517317713\n",
            "Round: 2572 Weight: [2.48719196 1.29506891] Bias: -1.0947952996870132 loss: 0.3317088516128072\n",
            "Round: 2573 Weight: [2.4871949  1.29507033] Bias: -1.0947963462503727 loss: 0.33170885149446233\n",
            "Round: 2574 Weight: [2.48719784 1.29507174] Bias: -1.0947973900857237 loss: 0.33170885137673345\n",
            "Round: 2575 Weight: [2.48720077 1.29507315] Bias: -1.0947984312001855 loss: 0.3317088512596175\n",
            "Round: 2576 Weight: [2.4872037  1.29507456] Bias: -1.094799469600859 loss: 0.3317088511431112\n",
            "Round: 2577 Weight: [2.48720661 1.29507596] Bias: -1.0948005052948264 loss: 0.3317088510272115\n",
            "Round: 2578 Weight: [2.48720952 1.29507736] Bias: -1.0948015382891518 loss: 0.33170885091191504\n",
            "Round: 2579 Weight: [2.48721242 1.29507876] Bias: -1.0948025685908802 loss: 0.3317088507972188\n",
            "Round: 2580 Weight: [2.48721531 1.29508015] Bias: -1.0948035962070386 loss: 0.33170885068311956\n",
            "Round: 2581 Weight: [2.4872182  1.29508154] Bias: -1.0948046211446354 loss: 0.3317088505696144\n",
            "Round: 2582 Weight: [2.48722108 1.29508292] Bias: -1.0948056434106606 loss: 0.3317088504567\n",
            "Round: 2583 Weight: [2.48722395 1.29508431] Bias: -1.0948066630120863 loss: 0.33170885034437336\n",
            "Round: 2584 Weight: [2.48722681 1.29508568] Bias: -1.094807679955866 loss: 0.3317088502326314\n",
            "Round: 2585 Weight: [2.48722967 1.29508706] Bias: -1.094808694248935 loss: 0.3317088501214714\n",
            "Round: 2586 Weight: [2.48723252 1.29508843] Bias: -1.094809705898211 loss: 0.3317088500108898\n",
            "Round: 2587 Weight: [2.48723536 1.2950898 ] Bias: -1.0948107149105928 loss: 0.33170884990088384\n",
            "Round: 2588 Weight: [2.48723819 1.29509116] Bias: -1.0948117212929618 loss: 0.3317088497914506\n",
            "Round: 2589 Weight: [2.48724102 1.29509252] Bias: -1.0948127250521809 loss: 0.33170884968258707\n",
            "Round: 2590 Weight: [2.48724384 1.29509388] Bias: -1.0948137261950954 loss: 0.33170884957429003\n",
            "Round: 2591 Weight: [2.48724665 1.29509523] Bias: -1.0948147247285327 loss: 0.3317088494665569\n",
            "Round: 2592 Weight: [2.48724945 1.29509658] Bias: -1.0948157206593023 loss: 0.3317088493593845\n",
            "Round: 2593 Weight: [2.48725225 1.29509792] Bias: -1.0948167139941958 loss: 0.33170884925277005\n",
            "Round: 2594 Weight: [2.48725504 1.29509927] Bias: -1.0948177047399867 loss: 0.3317088491467104\n",
            "Round: 2595 Weight: [2.48725782 1.2951006 ] Bias: -1.0948186929034316 loss: 0.33170884904120296\n",
            "Round: 2596 Weight: [2.48726059 1.29510194] Bias: -1.0948196784912687 loss: 0.33170884893624464\n",
            "Round: 2597 Weight: [2.48726336 1.29510327] Bias: -1.094820661510219 loss: 0.33170884883183277\n",
            "Round: 2598 Weight: [2.48726612 1.2951046 ] Bias: -1.0948216419669858 loss: 0.3317088487279643\n",
            "Round: 2599 Weight: [2.48726888 1.29510593] Bias: -1.094822619868255 loss: 0.3317088486246366\n",
            "Round: 2600 Weight: [2.48727162 1.29510725] Bias: -1.0948235952206944 loss: 0.33170884852184684\n",
            "Round: 2601 Weight: [2.48727436 1.29510856] Bias: -1.0948245680309552 loss: 0.331708848419592\n",
            "Round: 2602 Weight: [2.48727709 1.29510988] Bias: -1.0948255383056706 loss: 0.33170884831786945\n",
            "Round: 2603 Weight: [2.48727982 1.29511119] Bias: -1.0948265060514568 loss: 0.33170884821667634\n",
            "Round: 2604 Weight: [2.48728253 1.2951125 ] Bias: -1.0948274712749126 loss: 0.33170884811601\n",
            "Round: 2605 Weight: [2.48728524 1.2951138 ] Bias: -1.0948284339826195 loss: 0.33170884801586775\n",
            "Round: 2606 Weight: [2.48728795 1.2951151 ] Bias: -1.0948293941811418 loss: 0.3317088479162466\n",
            "Round: 2607 Weight: [2.48729064 1.2951164 ] Bias: -1.0948303518770266 loss: 0.33170884781714416\n",
            "Round: 2608 Weight: [2.48729333 1.2951177 ] Bias: -1.094831307076804 loss: 0.3317088477185575\n",
            "Round: 2609 Weight: [2.48729602 1.29511899] Bias: -1.094832259786987 loss: 0.3317088476204841\n",
            "Round: 2610 Weight: [2.48729869 1.29512027] Bias: -1.0948332100140716 loss: 0.3317088475229211\n",
            "Round: 2611 Weight: [2.48730136 1.29512156] Bias: -1.0948341577645366 loss: 0.33170884742586587\n",
            "Round: 2612 Weight: [2.48730402 1.29512284] Bias: -1.094835103044844 loss: 0.331708847329316\n",
            "Round: 2613 Weight: [2.48730668 1.29512412] Bias: -1.0948360458614388 loss: 0.33170884723326843\n",
            "Round: 2614 Weight: [2.48730932 1.29512539] Bias: -1.0948369862207492 loss: 0.3317088471377211\n",
            "Round: 2615 Weight: [2.48731196 1.29512666] Bias: -1.0948379241291868 loss: 0.33170884704267095\n",
            "Round: 2616 Weight: [2.4873146  1.29512793] Bias: -1.0948388595931462 loss: 0.3317088469481156\n",
            "Round: 2617 Weight: [2.48731723 1.29512919] Bias: -1.0948397926190054 loss: 0.3317088468540524\n",
            "Round: 2618 Weight: [2.48731985 1.29513045] Bias: -1.0948407232131256 loss: 0.33170884676047874\n",
            "Round: 2619 Weight: [2.48732246 1.29513171] Bias: -1.0948416513818515 loss: 0.3317088466673922\n",
            "Round: 2620 Weight: [2.48732507 1.29513297] Bias: -1.0948425771315111 loss: 0.33170884657479016\n",
            "Round: 2621 Weight: [2.48732766 1.29513422] Bias: -1.0948435004684158 loss: 0.3317088464826701\n",
            "Round: 2622 Weight: [2.48733026 1.29513546] Bias: -1.0948444213988608 loss: 0.33170884639102965\n",
            "Round: 2623 Weight: [2.48733284 1.29513671] Bias: -1.0948453399291245 loss: 0.33170884629986613\n",
            "Round: 2624 Weight: [2.48733542 1.29513795] Bias: -1.094846256065469 loss: 0.33170884620917707\n",
            "Round: 2625 Weight: [2.487338   1.29513919] Bias: -1.0948471698141402 loss: 0.33170884611896007\n",
            "Round: 2626 Weight: [2.48734056 1.29514042] Bias: -1.0948480811813674 loss: 0.33170884602921274\n",
            "Round: 2627 Weight: [2.48734312 1.29514165] Bias: -1.0948489901733638 loss: 0.33170884593993244\n",
            "Round: 2628 Weight: [2.48734567 1.29514288] Bias: -1.0948498967963263 loss: 0.3317088458511168\n",
            "Round: 2629 Weight: [2.48734822 1.29514411] Bias: -1.0948508010564355 loss: 0.3317088457627636\n",
            "Round: 2630 Weight: [2.48735076 1.29514533] Bias: -1.0948517029598561 loss: 0.3317088456748702\n",
            "Round: 2631 Weight: [2.48735329 1.29514655] Bias: -1.0948526025127363 loss: 0.33170884558743424\n",
            "Round: 2632 Weight: [2.48735582 1.29514776] Bias: -1.0948534997212085 loss: 0.3317088455004533\n",
            "Round: 2633 Weight: [2.48735834 1.29514898] Bias: -1.0948543945913891 loss: 0.33170884541392526\n",
            "Round: 2634 Weight: [2.48736085 1.29515019] Bias: -1.0948552871293784 loss: 0.33170884532784745\n",
            "Round: 2635 Weight: [2.48736336 1.29515139] Bias: -1.0948561773412608 loss: 0.33170884524221783\n",
            "Round: 2636 Weight: [2.48736586 1.2951526 ] Bias: -1.0948570652331047 loss: 0.3317088451570338\n",
            "Round: 2637 Weight: [2.48736835 1.2951538 ] Bias: -1.0948579508109626 loss: 0.3317088450722932\n",
            "Round: 2638 Weight: [2.48737084 1.29515499] Bias: -1.0948588340808714 loss: 0.33170884498799363\n",
            "Round: 2639 Weight: [2.48737332 1.29515619] Bias: -1.0948597150488522 loss: 0.33170884490413277\n",
            "Round: 2640 Weight: [2.48737579 1.29515738] Bias: -1.0948605937209102 loss: 0.3317088448207084\n",
            "Round: 2641 Weight: [2.48737826 1.29515856] Bias: -1.0948614701030348 loss: 0.3317088447377183\n",
            "Round: 2642 Weight: [2.48738072 1.29515975] Bias: -1.0948623442012 loss: 0.33170884465516015\n",
            "Round: 2643 Weight: [2.48738317 1.29516093] Bias: -1.094863216021364 loss: 0.3317088445730316\n",
            "Round: 2644 Weight: [2.48738562 1.29516211] Bias: -1.0948640855694698 loss: 0.33170884449133053\n",
            "Round: 2645 Weight: [2.48738806 1.29516328] Bias: -1.0948649528514443 loss: 0.33170884441005494\n",
            "Round: 2646 Weight: [2.4873905  1.29516446] Bias: -1.0948658178731991 loss: 0.3317088443292021\n",
            "Round: 2647 Weight: [2.48739293 1.29516562] Bias: -1.0948666806406309 loss: 0.33170884424877006\n",
            "Round: 2648 Weight: [2.48739535 1.29516679] Bias: -1.09486754115962 loss: 0.33170884416875684\n",
            "Round: 2649 Weight: [2.48739777 1.29516795] Bias: -1.0948683994360322 loss: 0.3317088440891599\n",
            "Round: 2650 Weight: [2.48740018 1.29516911] Bias: -1.0948692554757176 loss: 0.33170884400997735\n",
            "Round: 2651 Weight: [2.48740258 1.29517027] Bias: -1.0948701092845108 loss: 0.33170884393120686\n",
            "Round: 2652 Weight: [2.48740498 1.29517142] Bias: -1.0948709608682314 loss: 0.3317088438528464\n",
            "Round: 2653 Weight: [2.48740737 1.29517257] Bias: -1.094871810232684 loss: 0.33170884377489374\n",
            "Round: 2654 Weight: [2.48740976 1.29517372] Bias: -1.0948726573836576 loss: 0.3317088436973468\n",
            "Round: 2655 Weight: [2.48741214 1.29517487] Bias: -1.0948735023269263 loss: 0.3317088436202035\n",
            "Round: 2656 Weight: [2.48741451 1.29517601] Bias: -1.094874345068249 loss: 0.3317088435434616\n",
            "Round: 2657 Weight: [2.48741688 1.29517715] Bias: -1.0948751856133698 loss: 0.33170884346711926\n",
            "Round: 2658 Weight: [2.48741924 1.29517828] Bias: -1.0948760239680175 loss: 0.3317088433911742\n",
            "Round: 2659 Weight: [2.48742159 1.29517942] Bias: -1.094876860137906 loss: 0.3317088433156242\n",
            "Round: 2660 Weight: [2.48742394 1.29518055] Bias: -1.0948776941287344 loss: 0.33170884324046773\n",
            "Round: 2661 Weight: [2.48742628 1.29518167] Bias: -1.0948785259461866 loss: 0.3317088431657022\n",
            "Round: 2662 Weight: [2.48742862 1.2951828 ] Bias: -1.0948793555959322 loss: 0.33170884309132587\n",
            "Round: 2663 Weight: [2.48743095 1.29518392] Bias: -1.0948801830836252 loss: 0.3317088430173367\n",
            "Round: 2664 Weight: [2.48743327 1.29518504] Bias: -1.0948810084149057 loss: 0.33170884294373254\n",
            "Round: 2665 Weight: [2.48743559 1.29518615] Bias: -1.0948818315953983 loss: 0.33170884287051144\n",
            "Round: 2666 Weight: [2.4874379  1.29518727] Bias: -1.0948826526307134 loss: 0.3317088427976715\n",
            "Round: 2667 Weight: [2.48744021 1.29518837] Bias: -1.0948834715264464 loss: 0.3317088427252106\n",
            "Round: 2668 Weight: [2.4874425  1.29518948] Bias: -1.0948842882881782 loss: 0.3317088426531268\n",
            "Round: 2669 Weight: [2.4874448  1.29519059] Bias: -1.0948851029214752 loss: 0.33170884258141814\n",
            "Round: 2670 Weight: [2.48744709 1.29519169] Bias: -1.0948859154318893 loss: 0.3317088425100827\n",
            "Round: 2671 Weight: [2.48744937 1.29519278] Bias: -1.0948867258249577 loss: 0.33170884243911863\n",
            "Round: 2672 Weight: [2.48745164 1.29519388] Bias: -1.0948875341062032 loss: 0.33170884236852377\n",
            "Round: 2673 Weight: [2.48745391 1.29519497] Bias: -1.0948883402811342 loss: 0.33170884229829634\n",
            "Round: 2674 Weight: [2.48745618 1.29519606] Bias: -1.0948891443552449 loss: 0.3317088422284344\n",
            "Round: 2675 Weight: [2.48745844 1.29519715] Bias: -1.0948899463340147 loss: 0.3317088421589362\n",
            "Round: 2676 Weight: [2.48746069 1.29519823] Bias: -1.094890746222909 loss: 0.3317088420897995\n",
            "Round: 2677 Weight: [2.48746293 1.29519931] Bias: -1.0948915440273788 loss: 0.3317088420210227\n",
            "Round: 2678 Weight: [2.48746517 1.29520039] Bias: -1.094892339752861 loss: 0.33170884195260386\n",
            "Round: 2679 Weight: [2.48746741 1.29520147] Bias: -1.0948931334047778 loss: 0.33170884188454103\n",
            "Round: 2680 Weight: [2.48746964 1.29520254] Bias: -1.094893924988538 loss: 0.3317088418168324\n",
            "Round: 2681 Weight: [2.48747186 1.29520361] Bias: -1.094894714509536 loss: 0.33170884174947624\n",
            "Round: 2682 Weight: [2.48747408 1.29520468] Bias: -1.0948955019731517 loss: 0.33170884168247067\n",
            "Round: 2683 Weight: [2.48747629 1.29520574] Bias: -1.0948962873847512 loss: 0.3317088416158137\n",
            "Round: 2684 Weight: [2.4874785 1.2952068] Bias: -1.0948970707496868 loss: 0.3317088415495036\n",
            "Round: 2685 Weight: [2.48748069 1.29520786] Bias: -1.0948978520732964 loss: 0.3317088414835388\n",
            "Round: 2686 Weight: [2.48748289 1.29520892] Bias: -1.0948986313609044 loss: 0.3317088414179171\n",
            "Round: 2687 Weight: [2.48748508 1.29520997] Bias: -1.094899408617821 loss: 0.331708841352637\n",
            "Round: 2688 Weight: [2.48748726 1.29521102] Bias: -1.0949001838493424 loss: 0.3317088412876966\n",
            "Round: 2689 Weight: [2.48748944 1.29521207] Bias: -1.0949009570607513 loss: 0.33170884122309424\n",
            "Round: 2690 Weight: [2.48749161 1.29521311] Bias: -1.0949017282573166 loss: 0.33170884115882804\n",
            "Round: 2691 Weight: [2.48749377 1.29521415] Bias: -1.094902497444293 loss: 0.33170884109489623\n",
            "Round: 2692 Weight: [2.48749593 1.29521519] Bias: -1.094903264626922 loss: 0.3317088410312973\n",
            "Round: 2693 Weight: [2.48749809 1.29521623] Bias: -1.094904029810431 loss: 0.33170884096802933\n",
            "Round: 2694 Weight: [2.48750024 1.29521726] Bias: -1.0949047930000337 loss: 0.3317088409050905\n",
            "Round: 2695 Weight: [2.48750238 1.2952183 ] Bias: -1.094905554200931 loss: 0.3317088408424793\n",
            "Round: 2696 Weight: [2.48750452 1.29521932] Bias: -1.094906313418309 loss: 0.3317088407801939\n",
            "Round: 2697 Weight: [2.48750665 1.29522035] Bias: -1.0949070706573412 loss: 0.33170884071823264\n",
            "Round: 2698 Weight: [2.48750878 1.29522137] Bias: -1.0949078259231868 loss: 0.3317088406565938\n",
            "Round: 2699 Weight: [2.4875109  1.29522239] Bias: -1.0949085792209923 loss: 0.33170884059527583\n",
            "Round: 2700 Weight: [2.48751301 1.29522341] Bias: -1.0949093305558903 loss: 0.33170884053427696\n",
            "Round: 2701 Weight: [2.48751512 1.29522443] Bias: -1.0949100799330003 loss: 0.33170884047359556\n",
            "Round: 2702 Weight: [2.48751723 1.29522544] Bias: -1.0949108273574277 loss: 0.3317088404132299\n",
            "Round: 2703 Weight: [2.48751933 1.29522645] Bias: -1.0949115728342655 loss: 0.3317088403531783\n",
            "Round: 2704 Weight: [2.48752142 1.29522746] Bias: -1.094912316368593 loss: 0.33170884029343933\n",
            "Round: 2705 Weight: [2.48752351 1.29522846] Bias: -1.094913057965476 loss: 0.3317088402340113\n",
            "Round: 2706 Weight: [2.48752559 1.29522947] Bias: -1.0949137976299672 loss: 0.3317088401748925\n",
            "Round: 2707 Weight: [2.48752767 1.29523046] Bias: -1.0949145353671064 loss: 0.3317088401160812\n",
            "Round: 2708 Weight: [2.48752974 1.29523146] Bias: -1.09491527118192 loss: 0.3317088400575761\n",
            "Round: 2709 Weight: [2.48753181 1.29523246] Bias: -1.0949160050794209 loss: 0.3317088399993755\n",
            "Round: 2710 Weight: [2.48753387 1.29523345] Bias: -1.0949167370646098 loss: 0.33170883994147765\n",
            "Round: 2711 Weight: [2.48753592 1.29523444] Bias: -1.0949174671424735 loss: 0.3317088398838812\n",
            "Round: 2712 Weight: [2.48753797 1.29523542] Bias: -1.094918195317986 loss: 0.3317088398265845\n",
            "Round: 2713 Weight: [2.48754002 1.29523641] Bias: -1.0949189215961088 loss: 0.33170883976958593\n",
            "Round: 2714 Weight: [2.48754206 1.29523739] Bias: -1.0949196459817896 loss: 0.331708839712884\n",
            "Round: 2715 Weight: [2.48754409 1.29523837] Bias: -1.0949203684799638 loss: 0.3317088396564771\n",
            "Round: 2716 Weight: [2.48754612 1.29523935] Bias: -1.0949210890955536 loss: 0.33170883960036385\n",
            "Round: 2717 Weight: [2.48754814 1.29524032] Bias: -1.0949218078334686 loss: 0.3317088395445425\n",
            "Round: 2718 Weight: [2.48755016 1.29524129] Bias: -1.0949225246986054 loss: 0.33170883948901175\n",
            "Round: 2719 Weight: [2.48755218 1.29524226] Bias: -1.094923239695848 loss: 0.33170883943376983\n",
            "Round: 2720 Weight: [2.48755418 1.29524323] Bias: -1.0949239528300672 loss: 0.33170883937881557\n",
            "Round: 2721 Weight: [2.48755619 1.29524419] Bias: -1.0949246641061214 loss: 0.3317088393241472\n",
            "Round: 2722 Weight: [2.48755818 1.29524515] Bias: -1.0949253735288564 loss: 0.3317088392697633\n",
            "Round: 2723 Weight: [2.48756018 1.29524611] Bias: -1.0949260811031052 loss: 0.3317088392156624\n",
            "Round: 2724 Weight: [2.48756216 1.29524707] Bias: -1.094926786833688 loss: 0.331708839161843\n",
            "Round: 2725 Weight: [2.48756415 1.29524802] Bias: -1.0949274907254127 loss: 0.33170883910830384\n",
            "Round: 2726 Weight: [2.48756612 1.29524897] Bias: -1.0949281927830747 loss: 0.3317088390550431\n",
            "Round: 2727 Weight: [2.48756809 1.29524992] Bias: -1.0949288930114567 loss: 0.33170883900205966\n",
            "Round: 2728 Weight: [2.48757006 1.29525087] Bias: -1.0949295914153285 loss: 0.3317088389493518\n",
            "Round: 2729 Weight: [2.48757202 1.29525181] Bias: -1.0949302879994485 loss: 0.3317088388969183\n",
            "Round: 2730 Weight: [2.48757398 1.29525275] Bias: -1.0949309827685616 loss: 0.3317088388447577\n",
            "Round: 2731 Weight: [2.48757593 1.29525369] Bias: -1.0949316757274008 loss: 0.3317088387928685\n",
            "Round: 2732 Weight: [2.48757788 1.29525463] Bias: -1.0949323668806867 loss: 0.3317088387412494\n",
            "Round: 2733 Weight: [2.48757982 1.29525556] Bias: -1.0949330562331276 loss: 0.33170883868989876\n",
            "Round: 2734 Weight: [2.48758175 1.29525649] Bias: -1.0949337437894195 loss: 0.3317088386388154\n",
            "Round: 2735 Weight: [2.48758368 1.29525742] Bias: -1.094934429554246 loss: 0.331708838587998\n",
            "Round: 2736 Weight: [2.48758561 1.29525835] Bias: -1.0949351135322787 loss: 0.33170883853744487\n",
            "Round: 2737 Weight: [2.48758753 1.29525927] Bias: -1.0949357957281767 loss: 0.3317088384871549\n",
            "Round: 2738 Weight: [2.48758945 1.29526019] Bias: -1.0949364761465872 loss: 0.33170883843712656\n",
            "Round: 2739 Weight: [2.48759136 1.29526111] Bias: -1.094937154792145 loss: 0.3317088383873587\n",
            "Round: 2740 Weight: [2.48759326 1.29526203] Bias: -1.0949378316694731 loss: 0.3317088383378496\n",
            "Round: 2741 Weight: [2.48759516 1.29526295] Bias: -1.0949385067831823 loss: 0.3317088382885983\n",
            "Round: 2742 Weight: [2.48759706 1.29526386] Bias: -1.0949391801378712 loss: 0.33170883823960323\n",
            "Round: 2743 Weight: [2.48759895 1.29526477] Bias: -1.0949398517381266 loss: 0.33170883819086316\n",
            "Round: 2744 Weight: [2.48760084 1.29526568] Bias: -1.094940521588523 loss: 0.33170883814237667\n",
            "Round: 2745 Weight: [2.48760272 1.29526658] Bias: -1.0949411896936236 loss: 0.3317088380941425\n",
            "Round: 2746 Weight: [2.48760459 1.29526748] Bias: -1.0949418560579791 loss: 0.33170883804615936\n",
            "Round: 2747 Weight: [2.48760646 1.29526838] Bias: -1.0949425206861285 loss: 0.3317088379984259\n",
            "Round: 2748 Weight: [2.48760833 1.29526928] Bias: -1.094943183582599 loss: 0.33170883795094086\n",
            "Round: 2749 Weight: [2.48761019 1.29527018] Bias: -1.0949438447519055 loss: 0.33170883790370276\n",
            "Round: 2750 Weight: [2.48761205 1.29527107] Bias: -1.0949445041985522 loss: 0.33170883785671057\n",
            "Round: 2751 Weight: [2.4876139  1.29527196] Bias: -1.0949451619270303 loss: 0.3317088378099631\n",
            "Round: 2752 Weight: [2.48761575 1.29527285] Bias: -1.09494581794182 loss: 0.33170883776345866\n",
            "Round: 2753 Weight: [2.48761759 1.29527374] Bias: -1.09494647224739 loss: 0.3317088377171962\n",
            "Round: 2754 Weight: [2.48761943 1.29527462] Bias: -1.0949471248481966 loss: 0.3317088376711746\n",
            "Round: 2755 Weight: [2.48762126 1.2952755 ] Bias: -1.094947775748685 loss: 0.33170883762539244\n",
            "Round: 2756 Weight: [2.48762309 1.29527638] Bias: -1.0949484249532884 loss: 0.33170883757984854\n",
            "Round: 2757 Weight: [2.48762491 1.29527726] Bias: -1.0949490724664288 loss: 0.3317088375345415\n",
            "Round: 2758 Weight: [2.48762673 1.29527814] Bias: -1.0949497182925165 loss: 0.3317088374894703\n",
            "Round: 2759 Weight: [2.48762854 1.29527901] Bias: -1.0949503624359502 loss: 0.33170883744463364\n",
            "Round: 2760 Weight: [2.48763035 1.29527988] Bias: -1.0949510049011173 loss: 0.33170883740003027\n",
            "Round: 2761 Weight: [2.48763216 1.29528075] Bias: -1.0949516456923936 loss: 0.33170883735565904\n",
            "Round: 2762 Weight: [2.48763396 1.29528161] Bias: -1.0949522848141435 loss: 0.3317088373115187\n",
            "Round: 2763 Weight: [2.48763575 1.29528248] Bias: -1.0949529222707202 loss: 0.331708837267608\n",
            "Round: 2764 Weight: [2.48763754 1.29528334] Bias: -1.094953558066465 loss: 0.33170883722392586\n",
            "Round: 2765 Weight: [2.48763933 1.2952842 ] Bias: -1.0949541922057087 loss: 0.3317088371804709\n",
            "Round: 2766 Weight: [2.48764111 1.29528506] Bias: -1.0949548246927698 loss: 0.3317088371372421\n",
            "Round: 2767 Weight: [2.48764288 1.29528591] Bias: -1.0949554555319563 loss: 0.3317088370942383\n",
            "Round: 2768 Weight: [2.48764466 1.29528676] Bias: -1.0949560847275646 loss: 0.33170883705145826\n",
            "Round: 2769 Weight: [2.48764642 1.29528761] Bias: -1.09495671228388 loss: 0.33170883700890086\n",
            "Round: 2770 Weight: [2.48764819 1.29528846] Bias: -1.0949573382051765 loss: 0.3317088369665648\n",
            "Round: 2771 Weight: [2.48764994 1.29528931] Bias: -1.094957962495717 loss: 0.33170883692444914\n",
            "Round: 2772 Weight: [2.4876517  1.29529015] Bias: -1.0949585851597536 loss: 0.3317088368825526\n",
            "Round: 2773 Weight: [2.48765345 1.29529099] Bias: -1.0949592062015268 loss: 0.33170883684087404\n",
            "Round: 2774 Weight: [2.48765519 1.29529183] Bias: -1.094959825625266 loss: 0.3317088367994123\n",
            "Round: 2775 Weight: [2.48765693 1.29529267] Bias: -1.0949604434351898 loss: 0.3317088367581664\n",
            "Round: 2776 Weight: [2.48765866 1.2952935 ] Bias: -1.0949610596355062 loss: 0.33170883671713514\n",
            "Round: 2777 Weight: [2.48766039 1.29529434] Bias: -1.0949616742304111 loss: 0.3317088366763173\n",
            "Round: 2778 Weight: [2.48766212 1.29529517] Bias: -1.0949622872240907 loss: 0.33170883663571193\n",
            "Round: 2779 Weight: [2.48766384 1.295296  ] Bias: -1.0949628986207194 loss: 0.33170883659531775\n",
            "Round: 2780 Weight: [2.48766556 1.29529682] Bias: -1.0949635084244609 loss: 0.33170883655513383\n",
            "Round: 2781 Weight: [2.48766727 1.29529765] Bias: -1.0949641166394684 loss: 0.331708836515159\n",
            "Round: 2782 Weight: [2.48766898 1.29529847] Bias: -1.0949647232698836 loss: 0.33170883647539207\n",
            "Round: 2783 Weight: [2.48767068 1.29529929] Bias: -1.0949653283198382 loss: 0.33170883643583227\n",
            "Round: 2784 Weight: [2.48767238 1.29530011] Bias: -1.0949659317934524 loss: 0.33170883639647814\n",
            "Round: 2785 Weight: [2.48767408 1.29530092] Bias: -1.0949665336948358 loss: 0.33170883635732884\n",
            "Round: 2786 Weight: [2.48767577 1.29530173] Bias: -1.0949671340280875 loss: 0.33170883631838327\n",
            "Round: 2787 Weight: [2.48767745 1.29530255] Bias: -1.094967732797296 loss: 0.3317088362796403\n",
            "Round: 2788 Weight: [2.48767913 1.29530336] Bias: -1.0949683300065385 loss: 0.331708836241099\n",
            "Round: 2789 Weight: [2.48768081 1.29530416] Bias: -1.0949689256598822 loss: 0.3317088362027581\n",
            "Round: 2790 Weight: [2.48768248 1.29530497] Bias: -1.0949695197613836 loss: 0.3317088361646169\n",
            "Round: 2791 Weight: [2.48768415 1.29530577] Bias: -1.0949701123150881 loss: 0.331708836126674\n",
            "Round: 2792 Weight: [2.48768582 1.29530657] Bias: -1.094970703325031 loss: 0.3317088360889286\n",
            "Round: 2793 Weight: [2.48768748 1.29530737] Bias: -1.0949712927952373 loss: 0.3317088360513796\n",
            "Round: 2794 Weight: [2.48768913 1.29530817] Bias: -1.0949718807297208 loss: 0.33170883601402595\n",
            "Round: 2795 Weight: [2.48769078 1.29530896] Bias: -1.0949724671324852 loss: 0.3317088359768667\n",
            "Round: 2796 Weight: [2.48769243 1.29530975] Bias: -1.0949730520075238 loss: 0.3317088359399007\n",
            "Round: 2797 Weight: [2.48769407 1.29531054] Bias: -1.0949736353588193 loss: 0.3317088359031271\n",
            "Round: 2798 Weight: [2.48769571 1.29531133] Bias: -1.0949742171903443 loss: 0.33170883586654487\n",
            "Round: 2799 Weight: [2.48769735 1.29531212] Bias: -1.0949747975060606 loss: 0.33170883583015304\n",
            "Round: 2800 Weight: [2.48769897 1.2953129 ] Bias: -1.0949753763099201 loss: 0.3317088357939505\n",
            "Round: 2801 Weight: [2.4877006  1.29531369] Bias: -1.094975953605864 loss: 0.33170883575793636\n",
            "Round: 2802 Weight: [2.48770222 1.29531447] Bias: -1.0949765293978235 loss: 0.3317088357221095\n",
            "Round: 2803 Weight: [2.48770384 1.29531524] Bias: -1.0949771036897193 loss: 0.33170883568646925\n",
            "Round: 2804 Weight: [2.48770545 1.29531602] Bias: -1.0949776764854622 loss: 0.3317088356510143\n",
            "Round: 2805 Weight: [2.48770706 1.29531679] Bias: -1.0949782477889523 loss: 0.3317088356157438\n",
            "Round: 2806 Weight: [2.48770866 1.29531757] Bias: -1.0949788176040798 loss: 0.3317088355806569\n",
            "Round: 2807 Weight: [2.48771026 1.29531834] Bias: -1.094979385934725 loss: 0.3317088355457525\n",
            "Round: 2808 Weight: [2.48771186 1.2953191 ] Bias: -1.0949799527847577 loss: 0.33170883551102986\n",
            "Round: 2809 Weight: [2.48771345 1.29531987] Bias: -1.0949805181580377 loss: 0.33170883547648783\n",
            "Round: 2810 Weight: [2.48771504 1.29532063] Bias: -1.0949810820584145 loss: 0.3317088354421253\n",
            "Round: 2811 Weight: [2.48771662 1.2953214 ] Bias: -1.094981644489728 loss: 0.3317088354079418\n",
            "Round: 2812 Weight: [2.4877182  1.29532216] Bias: -1.094982205455808 loss: 0.33170883537393614\n",
            "Round: 2813 Weight: [2.48771978 1.29532291] Bias: -1.094982764960474 loss: 0.33170883534010737\n",
            "Round: 2814 Weight: [2.48772135 1.29532367] Bias: -1.0949833230075356 loss: 0.3317088353064546\n",
            "Round: 2815 Weight: [2.48772292 1.29532443] Bias: -1.094983879600793 loss: 0.33170883527297707\n",
            "Round: 2816 Weight: [2.48772448 1.29532518] Bias: -1.0949844347440354 loss: 0.3317088352396736\n",
            "Round: 2817 Weight: [2.48772604 1.29532593] Bias: -1.0949849884410432 loss: 0.33170883520654343\n",
            "Round: 2818 Weight: [2.48772759 1.29532668] Bias: -1.0949855406955864 loss: 0.3317088351735856\n",
            "Round: 2819 Weight: [2.48772915 1.29532742] Bias: -1.0949860915114251 loss: 0.3317088351407993\n",
            "Round: 2820 Weight: [2.48773069 1.29532817] Bias: -1.09498664089231 loss: 0.33170883510818355\n",
            "Round: 2821 Weight: [2.48773224 1.29532891] Bias: -1.0949871888419813 loss: 0.33170883507573756\n",
            "Round: 2822 Weight: [2.48773377 1.29532965] Bias: -1.0949877353641702 loss: 0.33170883504346044\n",
            "Round: 2823 Weight: [2.48773531 1.29533039] Bias: -1.0949882804625977 loss: 0.3317088350113512\n",
            "Round: 2824 Weight: [2.48773684 1.29533113] Bias: -1.0949888241409753 loss: 0.331708834979409\n",
            "Round: 2825 Weight: [2.48773837 1.29533186] Bias: -1.0949893664030048 loss: 0.3317088349476329\n",
            "Round: 2826 Weight: [2.48773989 1.29533259] Bias: -1.094989907252378 loss: 0.33170883491602227\n",
            "Round: 2827 Weight: [2.48774141 1.29533332] Bias: -1.0949904466927776 loss: 0.33170883488457614\n",
            "Round: 2828 Weight: [2.48774292 1.29533405] Bias: -1.0949909847278763 loss: 0.3317088348532935\n",
            "Round: 2829 Weight: [2.48774443 1.29533478] Bias: -1.0949915213613373 loss: 0.33170883482217384\n",
            "Round: 2830 Weight: [2.48774594 1.2953355 ] Bias: -1.0949920565968143 loss: 0.3317088347912158\n",
            "Round: 2831 Weight: [2.48774744 1.29533623] Bias: -1.0949925904379516 loss: 0.33170883476041907\n",
            "Round: 2832 Weight: [2.48774894 1.29533695] Bias: -1.0949931228883836 loss: 0.33170883472978246\n",
            "Round: 2833 Weight: [2.48775044 1.29533767] Bias: -1.0949936539517355 loss: 0.3317088346993053\n",
            "Round: 2834 Weight: [2.48775193 1.29533839] Bias: -1.094994183631623 loss: 0.3317088346689867\n",
            "Round: 2835 Weight: [2.48775342 1.2953391 ] Bias: -1.0949947119316525 loss: 0.3317088346388258\n",
            "Round: 2836 Weight: [2.4877549  1.29533982] Bias: -1.0949952388554207 loss: 0.3317088346088219\n",
            "Round: 2837 Weight: [2.48775638 1.29534053] Bias: -1.094995764406515 loss: 0.3317088345789741\n",
            "Round: 2838 Weight: [2.48775786 1.29534124] Bias: -1.0949962885885134 loss: 0.3317088345492815\n",
            "Round: 2839 Weight: [2.48775933 1.29534195] Bias: -1.0949968114049848 loss: 0.33170883451974353\n",
            "Round: 2840 Weight: [2.4877608  1.29534265] Bias: -1.0949973328594889 loss: 0.33170883449035915\n",
            "Round: 2841 Weight: [2.48776226 1.29534336] Bias: -1.0949978529555753 loss: 0.3317088344611277\n",
            "Round: 2842 Weight: [2.48776372 1.29534406] Bias: -1.0949983716967853 loss: 0.33170883443204835\n",
            "Round: 2843 Weight: [2.48776518 1.29534476] Bias: -1.0949988890866502 loss: 0.33170883440312027\n",
            "Round: 2844 Weight: [2.48776663 1.29534546] Bias: -1.0949994051286926 loss: 0.33170883437434273\n",
            "Round: 2845 Weight: [2.48776808 1.29534616] Bias: -1.0949999198264257 loss: 0.33170883434571485\n",
            "Round: 2846 Weight: [2.48776953 1.29534686] Bias: -1.0950004331833536 loss: 0.331708834317236\n",
            "Round: 2847 Weight: [2.48777097 1.29534755] Bias: -1.0950009452029712 loss: 0.33170883428890524\n",
            "Round: 2848 Weight: [2.48777241 1.29534824] Bias: -1.0950014558887644 loss: 0.3317088342607219\n",
            "Round: 2849 Weight: [2.48777384 1.29534893] Bias: -1.0950019652442098 loss: 0.3317088342326852\n",
            "Round: 2850 Weight: [2.48777527 1.29534962] Bias: -1.095002473272775 loss: 0.3317088342047944\n",
            "Round: 2851 Weight: [2.4877767  1.29535031] Bias: -1.0950029799779184 loss: 0.3317088341770488\n",
            "Round: 2852 Weight: [2.48777812 1.29535099] Bias: -1.09500348536309 loss: 0.33170883414944735\n",
            "Round: 2853 Weight: [2.48777954 1.29535167] Bias: -1.0950039894317298 loss: 0.3317088341219896\n",
            "Round: 2854 Weight: [2.48778096 1.29535236] Bias: -1.0950044921872697 loss: 0.33170883409467466\n",
            "Round: 2855 Weight: [2.48778237 1.29535303] Bias: -1.0950049936331323 loss: 0.33170883406750196\n",
            "Round: 2856 Weight: [2.48778378 1.29535371] Bias: -1.0950054937727314 loss: 0.3317088340404706\n",
            "Round: 2857 Weight: [2.48778518 1.29535439] Bias: -1.0950059926094715 loss: 0.33170883401357987\n",
            "Round: 2858 Weight: [2.48778658 1.29535506] Bias: -1.0950064901467487 loss: 0.33170883398682893\n",
            "Round: 2859 Weight: [2.48778798 1.29535574] Bias: -1.09500698638795 loss: 0.3317088339602174\n",
            "Round: 2860 Weight: [2.48778937 1.29535641] Bias: -1.0950074813364532 loss: 0.3317088339337442\n",
            "Round: 2861 Weight: [2.48779076 1.29535707] Bias: -1.0950079749956283 loss: 0.3317088339074087\n",
            "Round: 2862 Weight: [2.48779215 1.29535774] Bias: -1.0950084673688354 loss: 0.3317088338812102\n",
            "Round: 2863 Weight: [2.48779353 1.29535841] Bias: -1.0950089584594265 loss: 0.33170883385514804\n",
            "Round: 2864 Weight: [2.48779491 1.29535907] Bias: -1.0950094482707446 loss: 0.33170883382922156\n",
            "Round: 2865 Weight: [2.48779629 1.29535973] Bias: -1.0950099368061244 loss: 0.33170883380342975\n",
            "Round: 2866 Weight: [2.48779766 1.29536039] Bias: -1.0950104240688912 loss: 0.3317088337777723\n",
            "Round: 2867 Weight: [2.48779903 1.29536105] Bias: -1.095010910062362 loss: 0.3317088337522484\n",
            "Round: 2868 Weight: [2.48780039 1.29536171] Bias: -1.095011394789845 loss: 0.3317088337268572\n",
            "Round: 2869 Weight: [2.48780175 1.29536236] Bias: -1.09501187825464 loss: 0.3317088337015981\n",
            "Round: 2870 Weight: [2.48780311 1.29536302] Bias: -1.0950123604600384 loss: 0.33170883367647047\n",
            "Round: 2871 Weight: [2.48780447 1.29536367] Bias: -1.095012841409322 loss: 0.33170883365147347\n",
            "Round: 2872 Weight: [2.48780582 1.29536432] Bias: -1.0950133211057653 loss: 0.3317088336266066\n",
            "Round: 2873 Weight: [2.48780716 1.29536497] Bias: -1.0950137995526334 loss: 0.33170883360186915\n",
            "Round: 2874 Weight: [2.48780851 1.29536561] Bias: -1.0950142767531832 loss: 0.33170883357726033\n",
            "Round: 2875 Weight: [2.48780985 1.29536626] Bias: -1.095014752710663 loss: 0.3317088335527796\n",
            "Round: 2876 Weight: [2.48781118 1.2953669 ] Bias: -1.095015227428313 loss: 0.33170883352842606\n",
            "Round: 2877 Weight: [2.48781252 1.29536754] Bias: -1.0950157009093642 loss: 0.3317088335041994\n",
            "Round: 2878 Weight: [2.48781385 1.29536818] Bias: -1.0950161731570398 loss: 0.3317088334800987\n",
            "Round: 2879 Weight: [2.48781517 1.29536882] Bias: -1.0950166441745544 loss: 0.33170883345612345\n",
            "Round: 2880 Weight: [2.4878165  1.29536946] Bias: -1.0950171139651141 loss: 0.3317088334322729\n",
            "Round: 2881 Weight: [2.48781782 1.29537009] Bias: -1.0950175825319168 loss: 0.3317088334085465\n",
            "Round: 2882 Weight: [2.48781913 1.29537073] Bias: -1.095018049878152 loss: 0.3317088333849435\n",
            "Round: 2883 Weight: [2.48782044 1.29537136] Bias: -1.095018516007001 loss: 0.3317088333614632\n",
            "Round: 2884 Weight: [2.48782175 1.29537199] Bias: -1.0950189809216362 loss: 0.3317088333381052\n",
            "Round: 2885 Weight: [2.48782306 1.29537262] Bias: -1.0950194446252226 loss: 0.3317088333148686\n",
            "Round: 2886 Weight: [2.48782436 1.29537324] Bias: -1.0950199071209163 loss: 0.331708833291753\n",
            "Round: 2887 Weight: [2.48782566 1.29537387] Bias: -1.0950203684118658 loss: 0.3317088332687576\n",
            "Round: 2888 Weight: [2.48782695 1.29537449] Bias: -1.0950208285012106 loss: 0.33170883324588196\n",
            "Round: 2889 Weight: [2.48782825 1.29537511] Bias: -1.0950212873920826 loss: 0.33170883322312517\n",
            "Round: 2890 Weight: [2.48782954 1.29537573] Bias: -1.0950217450876052 loss: 0.3317088332004868\n",
            "Round: 2891 Weight: [2.48783082 1.29537635] Bias: -1.0950222015908937 loss: 0.3317088331779663\n",
            "Round: 2892 Weight: [2.4878321  1.29537697] Bias: -1.0950226569050554 loss: 0.3317088331555629\n",
            "Round: 2893 Weight: [2.48783338 1.29537758] Bias: -1.0950231110331896 loss: 0.331708833133276\n",
            "Round: 2894 Weight: [2.48783466 1.2953782 ] Bias: -1.0950235639783872 loss: 0.3317088331111052\n",
            "Round: 2895 Weight: [2.48783593 1.29537881] Bias: -1.0950240157437312 loss: 0.3317088330890497\n",
            "Round: 2896 Weight: [2.4878372  1.29537942] Bias: -1.0950244663322966 loss: 0.3317088330671088\n",
            "Round: 2897 Weight: [2.48783846 1.29538003] Bias: -1.09502491574715 loss: 0.3317088330452822\n",
            "Round: 2898 Weight: [2.48783973 1.29538064] Bias: -1.095025363991351 loss: 0.33170883302356907\n",
            "Round: 2899 Weight: [2.48784098 1.29538124] Bias: -1.0950258110679498 loss: 0.331708833001969\n",
            "Round: 2900 Weight: [2.48784224 1.29538185] Bias: -1.0950262569799898 loss: 0.33170883298048126\n",
            "Round: 2901 Weight: [2.48784349 1.29538245] Bias: -1.095026701730506 loss: 0.3317088329591052\n",
            "Round: 2902 Weight: [2.48784474 1.29538305] Bias: -1.0950271453225255 loss: 0.3317088329378404\n",
            "Round: 2903 Weight: [2.48784599 1.29538365] Bias: -1.0950275877590676 loss: 0.3317088329166864\n",
            "Round: 2904 Weight: [2.48784723 1.29538425] Bias: -1.0950280290431436 loss: 0.3317088328956423\n",
            "Round: 2905 Weight: [2.48784847 1.29538484] Bias: -1.0950284691777568 loss: 0.33170883287470776\n",
            "Round: 2906 Weight: [2.48784971 1.29538544] Bias: -1.095028908165903 loss: 0.331708832853882\n",
            "Round: 2907 Weight: [2.48785094 1.29538603] Bias: -1.0950293460105702 loss: 0.3317088328331647\n",
            "Round: 2908 Weight: [2.48785217 1.29538662] Bias: -1.0950297827147382 loss: 0.3317088328125552\n",
            "Round: 2909 Weight: [2.48785339 1.29538721] Bias: -1.0950302182813794 loss: 0.3317088327920529\n",
            "Round: 2910 Weight: [2.48785462 1.2953878 ] Bias: -1.0950306527134581 loss: 0.3317088327716572\n",
            "Round: 2911 Weight: [2.48785584 1.29538839] Bias: -1.0950310860139314 loss: 0.33170883275136764\n",
            "Round: 2912 Weight: [2.48785705 1.29538898] Bias: -1.0950315181857484 loss: 0.3317088327311837\n",
            "Round: 2913 Weight: [2.48785827 1.29538956] Bias: -1.0950319492318503 loss: 0.3317088327111047\n",
            "Round: 2914 Weight: [2.48785948 1.29539014] Bias: -1.0950323791551708 loss: 0.33170883269113016\n",
            "Round: 2915 Weight: [2.48786069 1.29539072] Bias: -1.095032807958636 loss: 0.3317088326712595\n",
            "Round: 2916 Weight: [2.48786189 1.2953913 ] Bias: -1.0950332356451644 loss: 0.3317088326514923\n",
            "Round: 2917 Weight: [2.48786309 1.29539188] Bias: -1.0950336622176666 loss: 0.33170883263182793\n",
            "Round: 2918 Weight: [2.48786429 1.29539246] Bias: -1.095034087679046 loss: 0.33170883261226575\n",
            "Round: 2919 Weight: [2.48786548 1.29539303] Bias: -1.0950345120321983 loss: 0.3317088325928055\n",
            "Round: 2920 Weight: [2.48786668 1.29539361] Bias: -1.0950349352800113 loss: 0.33170883257344635\n",
            "Round: 2921 Weight: [2.48786786 1.29539418] Bias: -1.0950353574253657 loss: 0.331708832554188\n",
            "Round: 2922 Weight: [2.48786905 1.29539475] Bias: -1.0950357784711346 loss: 0.3317088325350298\n",
            "Round: 2923 Weight: [2.48787023 1.29539532] Bias: -1.0950361984201835 loss: 0.3317088325159713\n",
            "Round: 2924 Weight: [2.48787141 1.29539589] Bias: -1.0950366172753705 loss: 0.3317088324970119\n",
            "Round: 2925 Weight: [2.48787259 1.29539645] Bias: -1.0950370350395462 loss: 0.3317088324781512\n",
            "Round: 2926 Weight: [2.48787376 1.29539702] Bias: -1.0950374517155537 loss: 0.33170883245938865\n",
            "Round: 2927 Weight: [2.48787493 1.29539758] Bias: -1.0950378673062289 loss: 0.33170883244072363\n",
            "Round: 2928 Weight: [2.4878761  1.29539814] Bias: -1.0950382818144 loss: 0.3317088324221557\n",
            "Round: 2929 Weight: [2.48787726 1.2953987 ] Bias: -1.095038695242888 loss: 0.33170883240368443\n",
            "Round: 2930 Weight: [2.48787842 1.29539926] Bias: -1.095039107594507 loss: 0.33170883238530924\n",
            "Round: 2931 Weight: [2.48787958 1.29539982] Bias: -1.0950395188720627 loss: 0.3317088323670296\n",
            "Round: 2932 Weight: [2.48788074 1.29540037] Bias: -1.0950399290783543 loss: 0.33170883234884513\n",
            "Round: 2933 Weight: [2.48788189 1.29540093] Bias: -1.0950403382161735 loss: 0.33170883233075527\n",
            "Round: 2934 Weight: [2.48788304 1.29540148] Bias: -1.0950407462883045 loss: 0.33170883231275944\n",
            "Round: 2935 Weight: [2.48788418 1.29540203] Bias: -1.0950411532975246 loss: 0.3317088322948572\n",
            "Round: 2936 Weight: [2.48788533 1.29540258] Bias: -1.0950415592466036 loss: 0.3317088322770481\n",
            "Round: 2937 Weight: [2.48788647 1.29540313] Bias: -1.0950419641383042 loss: 0.3317088322593318\n",
            "Round: 2938 Weight: [2.4878876  1.29540368] Bias: -1.0950423679753818 loss: 0.3317088322417075\n",
            "Round: 2939 Weight: [2.48788874 1.29540422] Bias: -1.0950427707605848 loss: 0.331708832224175\n",
            "Round: 2940 Weight: [2.48788987 1.29540477] Bias: -1.095043172496654 loss: 0.3317088322067337\n",
            "Round: 2941 Weight: [2.487891   1.29540531] Bias: -1.0950435731863237 loss: 0.33170883218938313\n",
            "Round: 2942 Weight: [2.48789212 1.29540585] Bias: -1.0950439728323205 loss: 0.3317088321721227\n",
            "Round: 2943 Weight: [2.48789325 1.29540639] Bias: -1.095044371437364 loss: 0.3317088321549522\n",
            "Round: 2944 Weight: [2.48789437 1.29540693] Bias: -1.0950447690041671 loss: 0.33170883213787095\n",
            "Round: 2945 Weight: [2.48789548 1.29540747] Bias: -1.0950451655354352 loss: 0.3317088321208787\n",
            "Round: 2946 Weight: [2.4878966 1.295408 ] Bias: -1.0950455610338667 loss: 0.33170883210397456\n",
            "Round: 2947 Weight: [2.48789771 1.29540854] Bias: -1.0950459555021532 loss: 0.3317088320871587\n",
            "Round: 2948 Weight: [2.48789881 1.29540907] Bias: -1.0950463489429791 loss: 0.3317088320704301\n",
            "Round: 2949 Weight: [2.48789992 1.2954096 ] Bias: -1.0950467413590217 loss: 0.3317088320537886\n",
            "Round: 2950 Weight: [2.48790102 1.29541013] Bias: -1.0950471327529514 loss: 0.33170883203723367\n",
            "Round: 2951 Weight: [2.48790212 1.29541066] Bias: -1.0950475231274317 loss: 0.3317088320207649\n",
            "Round: 2952 Weight: [2.48790322 1.29541119] Bias: -1.0950479124851191 loss: 0.33170883200438167\n",
            "Round: 2953 Weight: [2.48790431 1.29541172] Bias: -1.0950483008286633 loss: 0.3317088319880839\n",
            "Round: 2954 Weight: [2.4879054  1.29541224] Bias: -1.0950486881607069 loss: 0.33170883197187073\n",
            "Round: 2955 Weight: [2.48790649 1.29541277] Bias: -1.0950490744838857 loss: 0.3317088319557419\n",
            "Round: 2956 Weight: [2.48790757 1.29541329] Bias: -1.0950494598008287 loss: 0.331708831939697\n",
            "Round: 2957 Weight: [2.48790866 1.29541381] Bias: -1.0950498441141578 loss: 0.3317088319237357\n",
            "Round: 2958 Weight: [2.48790974 1.29541433] Bias: -1.0950502274264884 loss: 0.3317088319078573\n",
            "Round: 2959 Weight: [2.48791081 1.29541485] Bias: -1.0950506097404287 loss: 0.33170883189206146\n",
            "Round: 2960 Weight: [2.48791189 1.29541536] Bias: -1.0950509910585804 loss: 0.331708831876348\n",
            "Round: 2961 Weight: [2.48791296 1.29541588] Bias: -1.0950513713835384 loss: 0.33170883186071604\n",
            "Round: 2962 Weight: [2.48791402 1.29541639] Bias: -1.0950517507178905 loss: 0.33170883184516553\n",
            "Round: 2963 Weight: [2.48791509 1.2954169 ] Bias: -1.0950521290642183 loss: 0.3317088318296959\n",
            "Round: 2964 Weight: [2.48791615 1.29541742] Bias: -1.0950525064250962 loss: 0.33170883181430677\n",
            "Round: 2965 Weight: [2.48791721 1.29541793] Bias: -1.0950528828030919 loss: 0.33170883179899757\n",
            "Round: 2966 Weight: [2.48791827 1.29541843] Bias: -1.0950532582007668 loss: 0.33170883178376814\n",
            "Round: 2967 Weight: [2.48791932 1.29541894] Bias: -1.0950536326206752 loss: 0.3317088317686179\n",
            "Round: 2968 Weight: [2.48792037 1.29541945] Bias: -1.095054006065365 loss: 0.33170883175354654\n",
            "Round: 2969 Weight: [2.48792142 1.29541995] Bias: -1.0950543785373774 loss: 0.3317088317385534\n",
            "Round: 2970 Weight: [2.48792247 1.29542046] Bias: -1.0950547500392467 loss: 0.33170883172363846\n",
            "Round: 2971 Weight: [2.48792351 1.29542096] Bias: -1.095055120573501 loss: 0.3317088317088011\n",
            "Round: 2972 Weight: [2.48792455 1.29542146] Bias: -1.0950554901426617 loss: 0.3317088316940408\n",
            "Round: 2973 Weight: [2.48792559 1.29542196] Bias: -1.0950558587492434 loss: 0.3317088316793574\n",
            "Round: 2974 Weight: [2.48792663 1.29542246] Bias: -1.0950562263957544 loss: 0.3317088316647503\n",
            "Round: 2975 Weight: [2.48792766 1.29542295] Bias: -1.0950565930846963 loss: 0.33170883165021925\n",
            "Round: 2976 Weight: [2.48792869 1.29542345] Bias: -1.0950569588185644 loss: 0.33170883163576376\n",
            "Round: 2977 Weight: [2.48792972 1.29542394] Bias: -1.095057323599847 loss: 0.3317088316213835\n",
            "Round: 2978 Weight: [2.48793074 1.29542444] Bias: -1.0950576874310265 loss: 0.33170883160707804\n",
            "Round: 2979 Weight: [2.48793176 1.29542493] Bias: -1.0950580503145786 loss: 0.3317088315928469\n",
            "Round: 2980 Weight: [2.48793278 1.29542542] Bias: -1.0950584122529723 loss: 0.33170883157868986\n",
            "Round: 2981 Weight: [2.4879338  1.29542591] Bias: -1.0950587732486705 loss: 0.3317088315646064\n",
            "Round: 2982 Weight: [2.48793481 1.2954264 ] Bias: -1.0950591333041295 loss: 0.33170883155059633\n",
            "Round: 2983 Weight: [2.48793582 1.29542688] Bias: -1.0950594924217991 loss: 0.3317088315366591\n",
            "Round: 2984 Weight: [2.48793683 1.29542737] Bias: -1.0950598506041231 loss: 0.33170883152279435\n",
            "Round: 2985 Weight: [2.48793784 1.29542785] Bias: -1.0950602078535385 loss: 0.3317088315090018\n",
            "Round: 2986 Weight: [2.48793884 1.29542833] Bias: -1.0950605641724762 loss: 0.3317088314952809\n",
            "Round: 2987 Weight: [2.48793984 1.29542882] Bias: -1.0950609195633607 loss: 0.33170883148163144\n",
            "Round: 2988 Weight: [2.48794084 1.2954293 ] Bias: -1.09506127402861 loss: 0.331708831468053\n",
            "Round: 2989 Weight: [2.48794184 1.29542978] Bias: -1.0950616275706364 loss: 0.33170883145454505\n",
            "Round: 2990 Weight: [2.48794283 1.29543025] Bias: -1.095061980191845 loss: 0.3317088314411076\n",
            "Round: 2991 Weight: [2.48794382 1.29543073] Bias: -1.0950623318946353 loss: 0.3317088314277398\n",
            "Round: 2992 Weight: [2.48794481 1.29543121] Bias: -1.0950626826814003 loss: 0.33170883141444163\n",
            "Round: 2993 Weight: [2.48794579 1.29543168] Bias: -1.0950630325545267 loss: 0.33170883140121266\n",
            "Round: 2994 Weight: [2.48794677 1.29543215] Bias: -1.0950633815163953 loss: 0.3317088313880526\n",
            "Round: 2995 Weight: [2.48794775 1.29543262] Bias: -1.0950637295693801 loss: 0.33170883137496093\n",
            "Round: 2996 Weight: [2.48794873 1.29543309] Bias: -1.0950640767158497 loss: 0.33170883136193735\n",
            "Round: 2997 Weight: [2.48794971 1.29543356] Bias: -1.0950644229581659 loss: 0.3317088313489815\n",
            "Round: 2998 Weight: [2.48795068 1.29543403] Bias: -1.0950647682986843 loss: 0.331708831336093\n",
            "Round: 2999 Weight: [2.48795165 1.2954345 ] Bias: -1.0950651127397548 loss: 0.33170883132327167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKc9SvLVCKUg",
        "outputId": "5731735d-810b-45bd-90a6-843e75ae1a60"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.98334377, -1.1271988 ],\n",
              "       [ 1.23762906, -1.39076827],\n",
              "       [ 0.75480888,  1.36206849],\n",
              "       [ 1.52732117,  1.09849901],\n",
              "       [-0.11426744, -0.01434989],\n",
              "       [-0.40395955,  0.0442211 ],\n",
              "       [ 1.3341931 , -0.95148581],\n",
              "       [ 1.91357732,  0.89350053],\n",
              "       [-0.69365166, -0.13149188],\n",
              "       [ 0.17542467, -0.16077738],\n",
              "       [-1.07990781,  0.51278906],\n",
              "       [ 0.07886063,  0.0735066 ],\n",
              "       [-1.8524201 , -1.33219728],\n",
              "       [-0.50052359, -0.86362932],\n",
              "       [-0.40395955, -0.80505833],\n",
              "       [ 0.94793696, -1.0979133 ],\n",
              "       [-0.30739552, -1.39076827],\n",
              "       [ 0.36855274,  0.27850508],\n",
              "       [-0.11426744,  0.24921958],\n",
              "       [-0.7902157 , -0.62934534],\n",
              "       [ 0.94793696, -1.03934231],\n",
              "       [ 0.85137292, -0.62934534],\n",
              "       [-0.30739552, -0.33649037],\n",
              "       [-0.30739552, -0.95148581],\n",
              "       [ 0.56168081,  2.00634943],\n",
              "       [-1.17647184,  0.30779058],\n",
              "       [-1.56272799,  0.30779058],\n",
              "       [ 2.10670539,  1.09849901],\n",
              "       [ 0.07886063,  0.24921958],\n",
              "       [ 0.65824485,  1.77206545],\n",
              "       [-0.69365166,  0.54207456],\n",
              "       [ 1.72044925,  1.83063645],\n",
              "       [ 0.07886063,  1.85992194],\n",
              "       [ 1.91357732,  2.15277692],\n",
              "       [ 2.01014135, -0.83434382],\n",
              "       [ 0.36855274,  0.0735066 ],\n",
              "       [-1.17647184,  0.27850508],\n",
              "       [ 1.81701328,  0.1027921 ],\n",
              "       [-0.88677973, -0.80505833],\n",
              "       [ 0.94793696,  0.1027921 ],\n",
              "       [-1.07990781, -1.1564843 ],\n",
              "       [ 0.2719887 ,  0.0442211 ],\n",
              "       [ 0.94793696,  1.85992194],\n",
              "       [-1.17647184, -0.54148885],\n",
              "       [ 1.3341931 ,  1.97706393],\n",
              "       [ 0.17542467,  0.13207759],\n",
              "       [-0.11426744,  0.1027921 ],\n",
              "       [ 0.2719887 , -0.74648733],\n",
              "       [-0.21083148, -0.21934838],\n",
              "       [-0.30739552,  0.60064555],\n",
              "       [ 0.75480888,  0.1027921 ],\n",
              "       [-0.88677973,  0.36636157],\n",
              "       [ 0.65824485, -1.1271988 ],\n",
              "       [-0.59708762,  1.36206849],\n",
              "       [-0.50052359,  2.29920441],\n",
              "       [ 0.2719887 ,  0.24921958],\n",
              "       [ 0.36855274,  0.24921958],\n",
              "       [-1.07990781, -1.56648126],\n",
              "       [-1.07990781, -0.48291785],\n",
              "       [-0.59708762,  1.36206849],\n",
              "       [ 0.85137292, -1.33219728],\n",
              "       [ 1.3341931 ,  0.57136006],\n",
              "       [ 1.72044925,  0.98135702],\n",
              "       [-0.01770341, -0.60005984],\n",
              "       [ 1.52732117,  0.98135702],\n",
              "       [-0.30739552, -0.92220032],\n",
              "       [-0.40395955, -0.80505833],\n",
              "       [-1.36959991, -0.45363236],\n",
              "       [-0.69365166, -1.53719576],\n",
              "       [-0.21083148, -0.48291785],\n",
              "       [-0.11426744, -0.51220335],\n",
              "       [-1.27303588,  0.24921958],\n",
              "       [ 1.72044925, -0.30720487],\n",
              "       [ 0.17542467,  2.09420592],\n",
              "       [ 0.17542467, -0.39506136],\n",
              "       [-0.40395955, -1.33219728],\n",
              "       [-1.94898413,  0.33707608],\n",
              "       [-0.11426744,  0.65921655],\n",
              "       [-1.17647184, -1.62505225],\n",
              "       [ 0.85137292, -1.0686278 ],\n",
              "       [-1.65929202,  0.51278906],\n",
              "       [-0.11426744,  2.21134791],\n",
              "       [ 0.65824485, -1.30291178],\n",
              "       [-0.21083148,  0.13207759],\n",
              "       [-0.21083148, -0.30720487],\n",
              "       [ 1.43075714,  0.33707608],\n",
              "       [-0.98334377,  0.39564707],\n",
              "       [ 2.10670539, -0.83434382],\n",
              "       [-1.75585606,  0.33707608],\n",
              "       [ 0.17542467, -0.27791937],\n",
              "       [-1.17647184,  0.27850508],\n",
              "       [-1.36959991, -1.1271988 ],\n",
              "       [-0.30739552, -1.27362628],\n",
              "       [-0.11426744,  0.27850508],\n",
              "       [-1.36959991,  0.39564707],\n",
              "       [ 1.52732117, -1.30291178],\n",
              "       [ 1.62388521,  1.59635247],\n",
              "       [-1.07990781, -0.36577586],\n",
              "       [-0.98334377, -0.77577283],\n",
              "       [-0.11426744,  0.21993409],\n",
              "       [ 0.07886063, -0.27791937],\n",
              "       [ 0.75480888, -1.39076827],\n",
              "       [ 1.43075714,  0.98135702],\n",
              "       [-0.50052359, -0.57077435],\n",
              "       [ 0.17542467, -0.30720487],\n",
              "       [-0.11426744,  0.0149356 ],\n",
              "       [-1.27303588,  0.27850508],\n",
              "       [ 0.17542467,  0.13207759],\n",
              "       [-0.11426744, -0.45363236],\n",
              "       [-0.98334377,  0.42493257],\n",
              "       [ 0.36855274, -0.48291785],\n",
              "       [ 1.81701328, -0.30720487],\n",
              "       [ 0.17542467, -0.68791634],\n",
              "       [-1.17647184, -1.1271988 ],\n",
              "       [-1.17647184, -1.62505225],\n",
              "       [ 0.75480888,  0.51278906],\n",
              "       [-1.8524201 , -1.30291178],\n",
              "       [ 0.65824485,  0.24921958],\n",
              "       [ 0.2719887 , -0.30720487],\n",
              "       [ 0.07886063,  1.03992802],\n",
              "       [ 0.85137292, -0.60005984],\n",
              "       [-0.30739552, -0.36577586],\n",
              "       [-1.17647184,  0.0442211 ],\n",
              "       [-0.88677973,  0.27850508],\n",
              "       [ 0.75480888, -1.42005377],\n",
              "       [ 2.10670539, -0.71720183],\n",
              "       [ 0.65824485, -0.74648733],\n",
              "       [-0.69365166, -1.62505225],\n",
              "       [-1.75585606,  0.1027921 ],\n",
              "       [ 1.04450099,  0.45421807],\n",
              "       [ 0.75480888, -0.33649037],\n",
              "       [ 0.07886063, -0.83434382],\n",
              "       [-1.75585606, -0.62934534],\n",
              "       [-0.30739552,  0.24921958],\n",
              "       [-0.88677973, -0.27791937],\n",
              "       [-0.98334377,  1.53778147],\n",
              "       [-0.7902157 ,  0.54207456],\n",
              "       [ 0.94793696,  0.57136006],\n",
              "       [ 2.01014135,  0.51278906],\n",
              "       [-1.17647184, -1.56648126],\n",
              "       [-0.40395955,  1.215641  ],\n",
              "       [ 1.04450099,  2.06492043],\n",
              "       [-1.17647184, -0.80505833],\n",
              "       [-0.30739552, -1.33219728],\n",
              "       [ 0.94793696,  1.77206545],\n",
              "       [-0.50052359, -0.04363539],\n",
              "       [-0.30739552, -0.45363236],\n",
              "       [-0.01770341, -0.60005984],\n",
              "       [-1.36959991, -1.27362628],\n",
              "       [ 2.01014135,  0.36636157],\n",
              "       [-0.11426744,  1.94777844],\n",
              "       [-0.21083148,  1.39135398],\n",
              "       [-0.01770341,  1.215641  ],\n",
              "       [-0.30739552, -0.60005984],\n",
              "       [-0.59708762, -1.53719576],\n",
              "       [-0.88677973, -1.24434079],\n",
              "       [-0.01770341, -0.16077738],\n",
              "       [-1.17647184, -1.59576676],\n",
              "       [ 0.36855274, -0.16077738],\n",
              "       [-0.01770341,  0.27850508],\n",
              "       [ 1.91357732, -0.68791634],\n",
              "       [-0.01770341, -0.27791937],\n",
              "       [ 0.07886063,  0.13207759],\n",
              "       [-0.11426744,  0.0442211 ],\n",
              "       [-0.98334377, -0.33649037],\n",
              "       [ 1.04450099, -1.24434079],\n",
              "       [-0.21083148,  1.59635247],\n",
              "       [-1.46616395,  0.33707608],\n",
              "       [-0.30739552, -0.68791634],\n",
              "       [-0.7902157 , -1.56648126],\n",
              "       [ 1.81701328, -1.0979133 ],\n",
              "       [-1.36959991, -1.39076827],\n",
              "       [-0.30739552,  0.0442211 ],\n",
              "       [-1.36959991,  0.54207456],\n",
              "       [ 0.85137292, -1.47862477],\n",
              "       [ 1.14106503,  0.51278906],\n",
              "       [-0.30739552, -0.51220335],\n",
              "       [-0.30739552, -0.27791937],\n",
              "       [-0.69365166, -0.36577586],\n",
              "       [ 0.46511677,  1.71349446],\n",
              "       [ 0.07886063,  0.74707304],\n",
              "       [-0.98334377, -0.45363236],\n",
              "       [-1.65929202,  0.0442211 ],\n",
              "       [-0.30739552,  0.19064859],\n",
              "       [-0.11426744, -0.54148885],\n",
              "       [ 0.36855274,  0.98135702],\n",
              "       [ 2.01014135,  0.16136309],\n",
              "       [-1.56272799, -0.21934838],\n",
              "       [ 0.07886063, -0.83434382],\n",
              "       [ 0.17542467,  0.0149356 ],\n",
              "       [-0.98334377, -0.33649037],\n",
              "       [-1.07990781,  0.54207456],\n",
              "       [-0.69365166, -1.0686278 ],\n",
              "       [ 1.81701328,  1.50849597],\n",
              "       [-0.30739552,  0.13207759],\n",
              "       [ 0.85137292,  1.01064252],\n",
              "       [-0.7902157 ,  0.24921958],\n",
              "       [-1.27303588,  0.48350356],\n",
              "       [ 1.14106503, -1.47862477],\n",
              "       [-1.46616395, -1.47862477],\n",
              "       [-1.94898413, -0.54148885],\n",
              "       [ 0.2719887 , -0.57077435],\n",
              "       [-0.40395955,  1.30349749],\n",
              "       [-0.98334377,  0.48350356],\n",
              "       [-0.30739552,  2.24063341],\n",
              "       [ 0.36855274,  0.57136006],\n",
              "       [-0.01770341,  0.0149356 ],\n",
              "       [ 0.75480888, -0.86362932],\n",
              "       [ 0.85137292,  1.2449265 ],\n",
              "       [-1.65929202, -1.59576676],\n",
              "       [ 1.43075714,  0.0442211 ],\n",
              "       [-0.88677973,  0.36636157],\n",
              "       [ 1.04450099,  0.51278906],\n",
              "       [-0.30739552,  0.77635854],\n",
              "       [ 1.3341931 , -1.44933927],\n",
              "       [ 0.17542467, -0.39506136],\n",
              "       [ 0.2719887 , -0.33649037],\n",
              "       [ 0.56168081, -0.92220032],\n",
              "       [ 1.04450099,  0.1027921 ],\n",
              "       [ 0.75480888,  0.74707304],\n",
              "       [ 2.10670539, -0.83434382],\n",
              "       [ 1.04450099, -0.92220032],\n",
              "       [-0.7902157 , -0.24863387],\n",
              "       [ 0.85137292, -0.80505833],\n",
              "       [ 0.85137292, -0.68791634],\n",
              "       [-0.50052359, -0.30720487],\n",
              "       [ 1.62388521,  1.74277995],\n",
              "       [ 1.23762906,  2.21134791],\n",
              "       [ 0.36855274, -0.51220335],\n",
              "       [-1.07990781,  0.57136006],\n",
              "       [-0.01770341, -0.45363236],\n",
              "       [-1.75585606, -1.39076827],\n",
              "       [-0.30739552, -1.47862477],\n",
              "       [ 2.01014135,  1.74277995],\n",
              "       [-0.59708762,  1.44992498],\n",
              "       [ 0.17542467, -0.39506136],\n",
              "       [-0.50052359, -1.24434079],\n",
              "       [-0.30739552,  0.51278906],\n",
              "       [ 0.07886063,  1.50849597],\n",
              "       [-0.98334377,  0.24921958],\n",
              "       [ 1.04450099, -1.01005681],\n",
              "       [-0.30739552,  0.0735066 ],\n",
              "       [-0.11426744,  0.27850508],\n",
              "       [ 1.3341931 ,  2.3284899 ],\n",
              "       [-0.21083148, -0.60005984],\n",
              "       [ 0.07886063,  0.0149356 ],\n",
              "       [-0.21083148, -0.54148885],\n",
              "       [ 1.43075714,  2.12349142],\n",
              "       [ 1.04450099, -0.16077738],\n",
              "       [ 0.75480888,  0.24921958],\n",
              "       [-0.30739552, -0.77577283],\n",
              "       [-0.98334377, -0.98077131],\n",
              "       [ 0.46511677,  1.215641  ],\n",
              "       [ 0.2719887 ,  0.27850508],\n",
              "       [ 0.07886063, -0.33649037],\n",
              "       [-0.7902157 ,  0.27850508],\n",
              "       [-1.17647184,  0.45421807],\n",
              "       [ 2.01014135, -1.21505529],\n",
              "       [-1.07990781,  1.94777844],\n",
              "       [-0.21083148,  1.62563796],\n",
              "       [ 0.85137292, -0.57077435],\n",
              "       [ 1.91357732, -0.95148581],\n",
              "       [-1.07990781, -1.47862477],\n",
              "       [-0.69365166,  0.1027921 ],\n",
              "       [ 0.2719887 ,  0.48350356],\n",
              "       [ 0.94793696,  0.74707304],\n",
              "       [-0.01770341, -0.33649037],\n",
              "       [ 0.07886063,  0.0149356 ],\n",
              "       [-0.30739552, -1.42005377],\n",
              "       [ 2.10670539, -1.0686278 ],\n",
              "       [-0.21083148, -1.0979133 ],\n",
              "       [-0.50052359, -1.1564843 ],\n",
              "       [ 0.94793696, -0.86362932],\n",
              "       [ 0.07886063,  1.85992194],\n",
              "       [-1.75585606,  0.33707608],\n",
              "       [-1.8524201 , -1.44933927],\n",
              "       [ 0.07886063,  0.19064859],\n",
              "       [ 0.46511677,  1.83063645],\n",
              "       [ 1.3341931 ,  1.27421199],\n",
              "       [-1.17647184, -1.18576979],\n",
              "       [-1.27303588, -1.0979133 ],\n",
              "       [ 0.85137292,  1.06921351],\n",
              "       [-0.69365166,  0.0149356 ],\n",
              "       [ 0.36855274, -0.48291785],\n",
              "       [-0.30739552, -0.30720487],\n",
              "       [-0.50052359,  1.2449265 ],\n",
              "       [-0.7902157 ,  1.33278299],\n",
              "       [-1.36959991, -0.45363236],\n",
              "       [-0.01770341, -0.57077435],\n",
              "       [-0.59708762,  1.88920744],\n",
              "       [ 0.94793696, -1.21505529],\n",
              "       [ 0.36855274,  0.27850508],\n",
              "       [ 0.36855274,  0.13207759],\n",
              "       [ 0.85137292,  2.15277692],\n",
              "       [-1.8524201 , -0.01434989],\n",
              "       [ 1.23762906,  1.85992194],\n",
              "       [-1.94898413,  0.45421807],\n",
              "       [-0.59708762,  2.3284899 ],\n",
              "       [ 2.01014135,  2.12349142],\n",
              "       [ 0.2719887 ,  0.0442211 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=predict(X_test)"
      ],
      "metadata": {
        "id": "lWQK2SG9DGKe"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XzdxphhEWCO",
        "outputId": "ebde0573-cc36-44dd-b7a3-d8bc774e186b"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
              "       1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print actual and predicted values in a table\n",
        "print(\"actual Value\\tpredicted values\")\n",
        "for i in range(len(y_test)):\n",
        "    print(y_test[i],\"\\t\\t\",int(y_pred[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epeGBz2GE8bt",
        "outputId": "26d37adb-9284-41e5-fb48-6b7264f8b855"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actual Value\tpredicted values\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 1\n",
            "0 \t\t 1\n",
            "1 \t\t 1\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "1 \t\t 1\n",
            "1 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 1\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "1 \t\t 1\n",
            "1 \t\t 1\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 1\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "1 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=0\n",
        "for i in range(len(y_test)):\n",
        "  if(y_test[i]==y_pred[i]):\n",
        "    x+=1\n",
        "print((x/len(y_test))*100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgvGdLAzFegm",
        "outputId": "5c9d8b0f-229d-4034-f5ac-63e4543320d8"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "LR = LogisticRegression()\n",
        "from sklearn.metrics import  accuracy_score\n",
        "#Fit\n",
        "LR.fit(X_train,y_train)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRBcUufAHDoF",
        "outputId": "c7849c00-d342-46c4-8794-54975104dda3"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting the test label with LR. Predict always takes X as input\n",
        "y_test_pred = LR.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_test_pred)*100\n",
        "print(\"Accuracy: \", accuracy,\"%\")\n",
        "precision = precision_score(y_test, y_test_pred, average=None)\n",
        "recall = recall_score(y_test, y_test_pred, average=None)\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))"
      ],
      "metadata": {
        "id": "JgWqwoSdJA4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13db58a2-d6dd-4888-c691-1241618b3434"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  79.0 %\n",
            "precision: [0.84615385 0.68571429]\n",
            "recall: [0.83333333 0.70588235]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "l1=np.array(l1)"
      ],
      "metadata": {
        "id": "C_RT6zZJS2Ss"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(l1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYkskF6sUA57",
        "outputId": "eed7f126-8406-4564-d321-903f4c60feb4"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRnb60fuUECc",
        "outputId": "fcc1cafa-5ded-41bf-f505-d24c45443daa"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.7254722 , 0.70910929, 0.69366184, ..., 0.33170883, 0.33170883,\n",
              "       0.33170883])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array(range(0,3000))"
      ],
      "metadata": {
        "id": "yPmqD-HNUFrQ"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dT4KzwkdUQIa",
        "outputId": "d542e983-fa1f-4b87-ff89-c909480e833d"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    1,    2, ..., 2997, 2998, 2999])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(x,l1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "2wwMXw5eUQxk",
        "outputId": "982afa1c-1b10-4aa1-d044-ba1ac7f0e410"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f380744ab20>]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbyUlEQVR4nO3dfXBdd53f8ffn3qsnP1uxiI0txw61F0JC86DJpoEFZts4hu7E7EIZB2Y26XZJ08WFlnanztAJ1Bk6y26bbumaBi/rDrtTMDR0Qcy6G9IND11CguXFhNjBseIk2CaJFcuxTWxZT9/+cc+Vj64k68q68pXO/bxm7uic3znn6vvzlT/66XfuPUcRgZmZZVeu1gWYmdnMctCbmWWcg97MLOMc9GZmGeegNzPLuEKtCyi3bNmyWLNmTa3LMDObU/bu3ftqRLSNt23WBf2aNWvo6uqqdRlmZnOKpBcn2uapGzOzjHPQm5llnIPezCzjHPRmZhnnoDczyzgHvZlZxjnozcwyLjNB//r5QR789kH2HXmt1qWYmc0qmQn6voEhPvdYN08dddCbmaVlJugLuWJXBod8IxUzs7TMBH0+LwCGhh30ZmZp2Ql6FYN+0EFvZjZKdoI+Vwz6Yd8D18xslMwEfSEJes/Rm5mNlpmgz+WEBEPDw7UuxcxsVslM0ENxnt5z9GZmo2Ur6HNiyHP0ZmajZCroCzkx5Dl6M7NRKgp6SRslHZTULWnrONv/i6R9yeNZSa+ltt0l6VDyuKuaxZfL5Tx1Y2ZWbtJ7xkrKA9uB24CjwB5JnRFxoLRPRPzr1P7/ErghWW4FPgV0AAHsTY49WdVeJAo5+QNTZmZlKhnR3wx0R8ThiOgHdgGbLrL/ncBXkuXbgUcjojcJ90eBjdMp+GLyuZzn6M3MylQS9CuBI6n1o0nbGJKuAtYCj03lWEn3SOqS1NXT01NJ3ePyHL2Z2VjVPhm7GXg4IoamclBE7IiIjojoaGtru+RvnvccvZnZGJUE/TGgPbW+Kmkbz2YuTNtM9dhpy+fkD0yZmZWpJOj3AOskrZXUSDHMO8t3kvRmYCnww1TzI8AGSUslLQU2JG0zopATnrkxMxtt0nfdRMSgpC0UAzoP7IyI/ZK2AV0RUQr9zcCuiAtnQyOiV9IDFH9ZAGyLiN7qduECj+jNzMaaNOgBImI3sLus7f6y9U9PcOxOYOcl1jcl+Zx8UTMzszKZ+mRsPidfptjMrEymgr7gd92YmY2RqaDP+5OxZmZjZC7oPUdvZjZa5oLel0AwMxstU0FfyOU8dWNmViZTQe9LIJiZjZW5oPcHpszMRstg0Ne6CjOz2SVTQV/wiN7MbIxMBb3n6M3Mxspc0PtdN2ZmoznozcwyLlNB75uDm5mNlamgz+dynqM3MyuTsaDHI3ozszIVBb2kjZIOSuqWtHWCfT4o6YCk/ZK+nGofkrQveYy5BWE1+RIIZmZjTXqHKUl5YDtwG3AU2COpMyIOpPZZB9wHvD0iTkp6Q+opzkXE9VWue1w+GWtmNlYlI/qbge6IOBwR/cAuYFPZPh8BtkfESYCIOF7dMitTfB+9PzBlZpZWSdCvBI6k1o8mbWnrgfWSfiDpCUkbU9uaJXUl7e8b7xtIuifZp6unp2dKHUjziN7MbKyKbg5e4fOsA94NrAK+L+m6iHgNuCoijkm6GnhM0k8j4rn0wRGxA9gB0NHRcclJ7bdXmpmNVcmI/hjQnlpflbSlHQU6I2IgIp4HnqUY/ETEseTrYeC7wA3TrHlCxZuDw7DD3sxsRCVBvwdYJ2mtpEZgM1D+7plvUBzNI2kZxamcw5KWSmpKtb8dOMAMyUsAvsuUmVnKpFM3ETEoaQvwCJAHdkbEfknbgK6I6Ey2bZB0ABgCfj8iTki6FfiCpGGKv1T+IP1unWrL55OgHw4a8jP1XczM5paK5ugjYjewu6zt/tRyAJ9IHul9Hgeum36ZlSnkLgS9mZkVZeyTscXu+DIIZmYXZCvoiwN6j+jNzFKyFfT5Yncc9GZmF2Qq6D1Hb2Y2VqaCPp8E/YDvEG5mNiJTQe8RvZnZWJkK+oZ86V03HtGbmZVkLOiLI/r+QY/ozcxKMhb0HtGbmZXLVNAXkqD3yVgzswsyFfSlqZuBIU/dmJmVZCzoPaI3MyvnoDczy7hMBX0h56kbM7NymQr6xoJH9GZm5TIV9CNvr/SI3sxsREVBL2mjpIOSuiVtnWCfD0o6IGm/pC+n2u+SdCh53FWtwsdTmrrp94jezGzEpHeYkpQHtgO3UbwJ+B5JnelbAkpaB9wHvD0iTkp6Q9LeCnwK6AAC2Jsce7L6XbkwdeMRvZnZBZWM6G8GuiPicET0A7uATWX7fATYXgrwiDietN8OPBoRvcm2R4GN1Sl9rIKvXmlmNkYlQb8SOJJaP5q0pa0H1kv6gaQnJG2cwrFIukdSl6Sunp6eyqsv0+CTsWZmY1TrZGwBWAe8G7gT+FNJSyo9OCJ2RERHRHS0tbVdchENuVLQe+rGzKykkqA/BrSn1lclbWlHgc6IGIiI54FnKQZ/JcdWTekSCIMe0ZuZjagk6PcA6yStldQIbAY6y/b5BsXRPJKWUZzKOQw8AmyQtFTSUmBD0jYjfIcpM7OxJn3XTUQMStpCMaDzwM6I2C9pG9AVEZ1cCPQDwBDw+xFxAkDSAxR/WQBsi4jemehI8r1ozOcY8B2mzMxGTBr0ABGxG9hd1nZ/ajmATySP8mN3AjunV2blCnkxMOgRvZlZSaY+GQvFT8cOekRvZjYig0EvfzLWzCwlg0Gf89SNmVlK5oK+kJenbszMUjIX9A35nKduzMxSMhf0jfmcPzBlZpaSuaAv5OVLIJiZpWQu6BvyOX8y1swsJXtBn3PQm5mlZS/oC/KNR8zMUjIX9AWP6M3MRslc0Bfn6D2iNzMryWDQ+xIIZmZpmQv6poKnbszM0jIX9I2FHOcHHPRmZiWZC/qmQp7zg0O1LsPMbNaoKOglbZR0UFK3pK3jbL9bUo+kfcnjd1PbhlLt5bcgrLqmQo7zvnqlmdmISe8wJSkPbAduo3gT8D2SOiPiQNmuX42ILeM8xbmIuH76pVamqcFBb2aWVsmI/magOyIOR0Q/sAvYNLNlXbqmQp6h4fCFzczMEpUE/UrgSGr9aNJW7v2SnpL0sKT2VHuzpC5JT0h633jfQNI9yT5dPT09lVc/jqZCsUse1ZuZFVXrZOy3gDUR8TbgUeBLqW1XRUQH8CHgjyW9qfzgiNgRER0R0dHW1jatQhz0ZmajVRL0x4D0CH1V0jYiIk5ExPlk9YvATaltx5Kvh4HvAjdMo95JNTXkAfzOGzOzRCVBvwdYJ2mtpEZgMzDq3TOSVqRW7wCeSdqXSmpKlpcBbwfKT+JW1ciI3u+lNzMDKnjXTUQMStoCPALkgZ0RsV/SNqArIjqBj0m6AxgEeoG7k8PfAnxB0jDFXyp/MM67daqqqVAc0fsyCGZmRZMGPUBE7AZ2l7Xdn1q+D7hvnOMeB66bZo1T4hG9mdlo2ftkbEPpZKzn6M3MIItBXyidjPWI3swMMhn0HtGbmaVlL+gbPEdvZpaWvaD31I2Z2SgZDHpP3ZiZpWU46D2iNzODLAZ96RIInqM3MwOyGPSeujEzGyVzQV/IiZw8dWNmVpK5oJdEUyFP34BH9GZmkMGgB2huyHHOQW9mBmQ06Oc1Fjjb76A3M4OMBn1LY55zDnozMyCjQT+vMe8RvZlZIpNB39LgEb2ZWUlFQS9po6SDkrolbR1n+92SeiTtSx6/m9p2l6RDyeOuahY/kflNBc4ODF6Ob2VmNutNeocpSXlgO3AbcBTYI6lznFsCfjUitpQd2wp8CugAAtibHHuyKtVPoMVTN2ZmIyoZ0d8MdEfE4YjoB3YBmyp8/tuBRyOiNwn3R4GNl1Zq5eZ56sbMbEQlQb8SOJJaP5q0lXu/pKckPSypfSrHSrpHUpekrp6engpLn5hPxpqZXVCtk7HfAtZExNsojtq/NJWDI2JHRHREREdbW9u0i2lpLHhEb2aWqCTojwHtqfVVSduIiDgREeeT1S8CN1V67EyY15inf2iYwSFf78bMrJKg3wOsk7RWUiOwGehM7yBpRWr1DuCZZPkRYIOkpZKWAhuSthk1r7F4qeKzvgyCmdnk77qJiEFJWygGdB7YGRH7JW0DuiKiE/iYpDuAQaAXuDs5tlfSAxR/WQBsi4jeGejHKC1J0J/rH2JRc8NMfzszs1lt0qAHiIjdwO6ytvtTy/cB901w7E5g5zRqnLKREb3n6c3MsvrJ2OLvr7P9/tCUmVkmg35eaurGzKzeZTLo5zcVg/51B72ZWTaDfmFyAvZM30CNKzEzq72MBn1xjv5Mn+fozcwyGvQe0ZuZlWQy6Oc35snJI3ozM8ho0EtiQVOB0+c8ojczy2TQQ3H6xiN6M7MMB/2ilgZOO+jNzLIb9AubCz4Za2ZGhoN+UXPBUzdmZmQ46Bc2N3DmvEf0ZmYZDnqP6M3MoA6CPiJqXYqZWU1lOOgbGBoOX5PezOpeRUEvaaOkg5K6JW29yH7vlxSSOpL1NZLOSdqXPB6qVuGTWdJSvAzCKX9oyszq3KR3mJKUB7YDtwFHgT2SOiPiQNl+C4GPA0+WPcVzEXF9leqt2NL5jQD0vt7PG5e0XO5vb2Y2a1Qyor8Z6I6IwxHRD+wCNo2z3wPAZ4G+KtZ3yVpTQW9mVs8qCfqVwJHU+tGkbYSkG4H2iPircY5fK+nHkr4n6dcuvdSpKQX9ybMOejOrbxXdHPxiJOWAB4G7x9n8ErA6Ik5Iugn4hqS3RsTpsue4B7gHYPXq1dMtCYDWeR7Rm5lBZSP6Y0B7an1V0layELgW+K6kF4BbgE5JHRFxPiJOAETEXuA5YH35N4iIHRHREREdbW1tl9aTMotaGsgJTjrozazOVRL0e4B1ktZKagQ2A52ljRFxKiKWRcSaiFgDPAHcERFdktqSk7lIuhpYBxyuei/Gkc+JJfMaOeGgN7M6N+nUTUQMStoCPALkgZ0RsV/SNqArIjovcvg7gW2SBoBh4N6I6K1G4ZVond/oOXozq3sVzdFHxG5gd1nb/RPs++7U8teBr0+jvmlpndfoOXozq3uZ/WQswNL5DZx83R+YMrP6lumgv2JBE6/+8nytyzAzq6lMB/2VC5s58Xo/5wd9vRszq1+ZDvrli5sAOH7ao3ozq1+ZDvorFzUD8MrpWXFVBjOzmsh00C9fXAz6lx30ZlbHsh30yYj+5VMOejOrX5kO+sUtDTQWcp66MbO6lumgl8TyRc287JOxZlbHMh30UJy+ecVTN2ZWxzIf9CuXtnD05Nlal2FmVjOZD/rVrfN46XSfPzRlZnUr80F/1RXziIAjvedqXYqZWU3URdAD/Lz39RpXYmZWG5kP+tWt8wF48YTn6c2sPmU+6JctaGR+Y95Bb2Z1q6Kgl7RR0kFJ3ZK2XmS/90sKSR2ptvuS4w5Kur0aRU+FJFZfMZ8XTnjqxszq06RBn9zzdTvwHuAa4E5J14yz30Lg48CTqbZrKN5j9q3ARuDzpXvIXk7rr1zAsy+fudzf1sxsVqhkRH8z0B0RhyOiH9gFbBpnvweAzwLpTydtAnZFxPmIeB7oTp7vsvqV5Qv5xak+Tp3z3abMrP5UEvQrgSOp9aNJ2whJNwLtEfFXUz32cnjz8oUAPPuKR/VmVn+mfTJWUg54EPg303iOeyR1Serq6emZbklj/MryRQD8zNM3ZlaHKgn6Y0B7an1V0layELgW+K6kF4BbgM7khOxkxwIQETsioiMiOtra2qbWgwq8cXEzC5sLHHz5dNWf28xstqsk6PcA6yStldRI8eRqZ2ljRJyKiGURsSYi1gBPAHdERFey32ZJTZLWAuuAH1W9F5OQxFuWL+LpYw56M6s/kwZ9RAwCW4BHgGeAr0XEfknbJN0xybH7ga8BB4C/Bj4aETW56MwNq5ew/xen6BvwNW/MrL4UKtkpInYDu8va7p9g33eXrX8G+Mwl1lc1N161lC98/zD7f3GKm65qrXU5ZmaXTeY/GVty4+qlAOx98WSNKzEzu7zqJujbFjaxunWeg97M6k7dBD3ALVe38sPnTjA4NFzrUszMLpu6Cvp3rX8Dp/sG2XfktVqXYmZ22dRV0L9j3TLyOfG9Z6v/oSwzs9mqroJ+cUsDN7Qv4TsHj9e6FDOzy6augh7g9rcu5+ljp3n+VV+22MzqQ90F/W/8/RVI8M19Y67EYGaWSXUX9CsWt/Cra1v55r5fEBG1LsfMbMbVXdADfOCmdp5/9XV+0H2i1qWYmc24ugz633jbCpYtaGTnD56vdSlmZjOuLoO+uSHPh3/1Kh772XEO+WYkZpZxdRn0AHfduoYFTQX+6JGDtS7FzGxG1W3Qt85v5N53Xc23D7xC1wu9tS7HzGzG1G3QA/zOO9ayfFEzn/zLp+kf9PVvzCyb6jro5zUW+I+/dS0HXznD5/7mUK3LMTObEXUd9AC//uYr+cBNq9j+3W4e+9krtS7HzKzqKgp6SRslHZTULWnrONvvlfRTSfsk/a2ka5L2NZLOJe37JD1U7Q5UwwObruWaFYv4+Ff28cxLvq+smWXLpEEvKQ9sB94DXAPcWQrylC9HxHURcT3wh8CDqW3PRcT1yePeahVeTS2NeXb8dgcLmgt8+ItPcvBlv+XSzLKjkhH9zUB3RByOiH5gF7ApvUNEpIfB84E5d22BlUta+PJHbqEhL/7JQ4/z/w75UsZmlg2VBP1K4Ehq/WjSNoqkj0p6juKI/mOpTWsl/VjS9yT92njfQNI9krokdfX01C5g1y6bz8P33sqKxS3c/T/28CePHfLdqMxszqvaydiI2B4RbwL+HfDvk+aXgNURcQPwCeDLkhaNc+yOiOiIiI62trZqlXRJ2lvn8fXfu5X3XLuc//TtZ/nNzz/O3/3c95k1s7mrkqA/BrSn1lclbRPZBbwPICLOR8SJZHkv8Byw/tJKvXwWNBX4kw/dyOc/fCMvnerjtz7/OP/8L7p46qhvQWhmc0+hgn32AOskraUY8JuBD6V3kLQuIkpvRP/HwKGkvQ3ojYghSVcD64DD1Sp+pr33uhW8a30bf/a3z7Pj+4d5ZP8r3LB6CXfevJrbr1nO4nkNtS7RzGxSquSa7JLeC/wxkAd2RsRnJG0DuiKiU9J/Bf4RMACcBLZExH5J7we2Je3DwKci4lsX+14dHR3R1dU1rU7NhNN9A3x971H+/Icv8vyrr9OQF2//e8t41/o2bn3TMtZfuQBJtS7TzOqUpL0R0THuttl2843ZGvQlEcFTR0+x+6cv8df7X+bFE2cBuGJ+I29btZhrVy7mrW9cxFtWLGLlkhYK+br/TJqZXQYO+hl0pPcsPzx8gicP9/L0sVN09/ySoeHiv2khJ1YtbWH1FfO5qnUeyxc307awibaFTbwh+do6r9G/DMxs2i4W9JXM0dtFtLfOo711Hh/sKJ6v7hsY4mcvn+Hgy6d58cRZXuw9y89PnGXfz09yum9w3OeY35hnUUsDi5obWNhcSJYLzGsq0FzI09KYo7mQp7khT3NDjqaGPC0NxfWmQo5CThTyOfI50ZAXhVyOQl7F9tJyWXtOQgIhcuLCuqefzDLHQV9lzQ15rm9fwvXtS8ZsO9c/xKu/PM/xM330nDnP8TPnOfn6AKf7Bjh9boAzfYOc7hvg+Jk+uo8PcrZ/kL6BYfoGhhgcvnx/eZUHf67sFwLJ11x6u4SA9O+JYktqvex3iEZtu/gvmFHPO+Z5dJFt5c+jCbehcRftEnjAcGnesmIR/+3OG6r+vA76y6ilMT/yF8BUDQ4N0zc4zLn+IfoGhjg/OETfwDDnB4cYHAoGh4OBoWGGhoOBoWBoOBgcHk6Wi18Hh4YZHC7uGwHDEUQEw8Go9aC4XGov7lM6priNkX1G71dSPiMYZR+WTm8v/xV20WPHbEsfFxNum/x7xoTbbIr8D3jJ2pe2zMjzOujniEI+x4J8jgVNfsnMbGp8FtDMLOMc9GZmGeegNzPLOAe9mVnGOejNzDLOQW9mlnEOejOzjHPQm5ll3Ky7qJmkHuDFaTzFMuDVKpVTS1npB7gvs1VW+pKVfsD0+nJVRIx7i75ZF/TTJalroiu4zSVZ6Qe4L7NVVvqSlX7AzPXFUzdmZhnnoDczy7gsBv2OWhdQJVnpB7gvs1VW+pKVfsAM9SVzc/RmZjZaFkf0ZmaW4qA3M8u4zAS9pI2SDkrqlrS11vVUQtILkn4qaZ+krqStVdKjkg4lX5cm7ZL0uaR/T0m6sca175R0XNLTqbYp1y7prmT/Q5LumiX9+LSkY8nrsk/Se1Pb7kv6cVDS7an2mv/8SWqX9B1JByTtl/TxpH0uvi4T9WVOvTaSmiX9SNJPkn78h6R9raQnk5q+KqkxaW9K1ruT7Wsm619FonT7uDn8APLAc8DVQCPwE+CaWtdVQd0vAMvK2v4Q2JosbwU+myy/F/g/FG9negvwZI1rfydwI/D0pdYOtAKHk69Lk+Wls6Afnwb+7Tj7XpP8bDUBa5Ofufxs+fkDVgA3JssLgWeTmufi6zJRX+bUa5P82y5IlhuAJ5N/668Bm5P2h4B/kSz/HvBQsrwZ+OrF+ldpHVkZ0d8MdEfE4YjoB3YBm2pc06XaBHwpWf4S8L5U+59H0RPAEkkralEgQER8H+gta55q7bcDj0ZEb0ScBB4FNs589RdM0I+JbAJ2RcT5iHge6Kb4szcrfv4i4qWI+Ltk+QzwDLCSufm6TNSXiczK1yb5t/1lstqQPAL4deDhpL38NSm9Vg8D/1CSmLh/FclK0K8EjqTWj3LxH4rZIoBvS9or6Z6k7cqIeClZfhm4MlmeC32cau2zuU9bkumMnaWpDuZQP5I/+W+gOIKc069LWV9gjr02kvKS9gHHKf7SfA54LSIGx6lppN5k+yngCqbZj6wE/Vz1joi4EXgP8FFJ70xvjOLfbHPy/a9zuXbgvwNvAq4HXgL+c23LmRpJC4CvA/8qIk6nt82112Wcvsy51yYihiLiemAVxVH4my93DVkJ+mNAe2p9VdI2q0XEseTrceAvKf4QvFKakkm+Hk92nwt9nGrts7JPEfFK8p9zGPhTLvyJPOv7IamBYjD+z4j430nznHxdxuvLXH5tIuI14DvAP6A4TVYYp6aRepPti4ETTLMfWQn6PcC65Ex2I8WTGJ01rumiJM2XtLC0DGwAnqZYd+ldDncB30yWO4HfTt4pcQtwKvXn+Gwx1dofATZIWpr8Cb4haaupsnMfv0nxdYFiPzYn74xYC6wDfsQs+flL5nL/DHgmIh5MbZpzr8tEfZlrr42kNklLkuUW4DaK5xu+A3wg2a38NSm9Vh8AHkv+Cpuof5W5XGefZ/pB8R0Ez1Kc//pkreupoN6rKZ5F/wmwv1Qzxfm4vwEOAf8XaI0LZ++3J/37KdBR4/q/QvFP5wGK84X/7FJqB36H4omlbuCfzpJ+/EVS51PJf7AVqf0/mfTjIPCe2fTzB7yD4rTMU8C+5PHeOfq6TNSXOfXaAG8DfpzU+zRwf9J+NcWg7gb+F9CUtDcn693J9qsn618lD18Cwcws47IydWNmZhNw0JuZZZyD3sws4xz0ZmYZ56A3M8s4B72ZWcY56M3MMu7/AybPwhZOkGGiAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hello1=np.array([[28,76000]])\n"
      ],
      "metadata": {
        "id": "cm200gpCUzbn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hello1=np.array(hello1)"
      ],
      "metadata": {
        "id": "c8WUz8xgVPeY"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hello1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2MxB_PZVZoX",
        "outputId": "7300b302-f9e2-47dd-b5b2-ce5f19628973"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   28, 76000]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_ask=sc.fit(hello1)"
      ],
      "metadata": {
        "id": "35PJoc6jVuK9"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_ask=x_ask.transform(hello1)"
      ],
      "metadata": {
        "id": "d1gsug0OWCAt"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_ask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lamNFlHRWWqi",
        "outputId": "4f32853a-21b6-4467-9640-bcbf886bb9b1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR.predict(x_ask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtHd1gIXWZmc",
        "outputId": "a2068fbf-01b2-44f6-e433-a369cf5e520d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CymNW0gYXi4w"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}